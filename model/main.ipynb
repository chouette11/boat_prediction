{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c06848a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, tqdm\n",
    "import pandas as pd, psycopg2, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np  \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import joblib\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ba4078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_8038/1313796694.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"\"\"\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\n    SELECT * FROM feat.train_features\n    WHERE race_date <= '2024-12-31'\n': column \"race_date\" does not exist\nLINE 3:     WHERE race_date <= '2024-12-31'\n                  ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedColumn\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/share/virtualenvs/boat_racing-zew2npIb/lib/python3.9/site-packages/pandas/io/sql.py:2664\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2663\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2664\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mUndefinedColumn\u001b[0m: column \"race_date\" does not exist\nLINE 3:     WHERE race_date <= '2024-12-31'\n                  ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m conn \u001b[38;5;241m=\u001b[39m psycopg2\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[1;32m      2\u001b[0m     host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m\"\u001b[39m, dbname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostgres\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     user\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeiichiro\u001b[39m\u001b[38;5;124m\"\u001b[39m, password\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m    SELECT * FROM feat.train_features\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m    WHERE race_date <= \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2024-12-31\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/boat_racing-zew2npIb/lib/python3.9/site-packages/pandas/io/sql.py:708\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m            \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m         _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/boat_racing-zew2npIb/lib/python3.9/site-packages/pandas/io/sql.py:2728\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2717\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2718\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2719\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2726\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2727\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2728\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2729\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/boat_racing-zew2npIb/lib/python3.9/site-packages/pandas/io/sql.py:2676\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2675\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2676\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\n    SELECT * FROM feat.train_features\n    WHERE race_date <= '2024-12-31'\n': column \"race_date\" does not exist\nLINE 3:     WHERE race_date <= '2024-12-31'\n                  ^\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\", dbname=\"postgres\",\n",
    "    user=\"keiichiro\", password=\"\" \n",
    ")\n",
    "df = pd.read_sql(\"\"\"\n",
    "    SELECT * FROM feat.train_features\n",
    "    WHERE race_date <= '2024-12-31'\n",
    "\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0fe484",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COLS = [\"air_temp\", \"wind_speed\", \"wave_height\", \"water_temp\"]\n",
    "scaler = StandardScaler().fit(df[NUM_COLS])\n",
    "df[NUM_COLS] = scaler.transform(df[NUM_COLS])\n",
    "scaler_filename = \"artifacts/wind_scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(col):\n",
    "    uniq = sorted(df[col].dropna().unique())\n",
    "    mapping = {v:i for i,v in enumerate(uniq)}\n",
    "    df[col + \"_id\"] = df[col].map(mapping).fillna(-1).astype(\"int16\")\n",
    "    return mapping\n",
    "venue2id = encode(\"venue\")\n",
    "race_type2id = encode(\"race_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0891f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoatRaceDataset(Dataset):\n",
    "    def __init__(self, frame):\n",
    "        self.f = frame.reset_index(drop=True).astype(\"float32\")\n",
    "\n",
    "    def __len__(self): return len(self.f)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.f.iloc[idx]\n",
    "\n",
    "        # --- context --- #\n",
    "        ctx = torch.tensor([\n",
    "            row[\"venue_id\"], row[\"race_type_id\"],\n",
    "            row[\"air_temp\"], row[\"wind_speed\"],\n",
    "            row[\"wave_height\"], row[\"water_temp\"]\n",
    "        ])\n",
    "\n",
    "        # --- per-boat --- #\n",
    "        boat_feats, ranks = [], []\n",
    "        for lane in range(1, 7):\n",
    "            boat_feats.append(torch.tensor([\n",
    "                row[f\"lane{lane}_weight\"],\n",
    "                row[f\"lane{lane}_exh_time\"],\n",
    "                row[f\"lane{lane}_st\"],\n",
    "                row[f\"lane{lane}_fs_flag\"]\n",
    "            ]))\n",
    "            ranks.append(row[f\"lane{lane}_rank\"])\n",
    "        # stack: [6, feat_dim]\n",
    "        return ctx, torch.stack(boat_feats), torch.tensor(ranks, dtype=torch.int64)\n",
    "\n",
    "ds_train = BoatRaceDataset(df[df[\"race_date\"] < \"2024-07-01\"])\n",
    "ds_val   = BoatRaceDataset(df[df[\"race_date\"] >= \"2024-07-01\"])\n",
    "\n",
    "loader_train = DataLoader(ds_train, batch_size=256, shuffle=True)\n",
    "loader_val   = DataLoader(ds_val,   batch_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCPLNet(nn.Module):\n",
    "    def __init__(self, ctx_in=6, boat_in=4, hidden=64):\n",
    "        super().__init__()\n",
    "        self.ctx_mlp  = nn.Sequential(nn.Linear(ctx_in, hidden), nn.ReLU())\n",
    "        self.boat_mlp = nn.Sequential(nn.Linear(boat_in, hidden),\n",
    "                                      nn.ReLU(), nn.Linear(hidden, hidden))\n",
    "        self.score    = nn.Linear(hidden*2, 1)\n",
    "\n",
    "    def forward(self, ctx, boats):          # ctx:[B,6] boats:[B,6,4]\n",
    "        B = ctx.size(0)\n",
    "        ctx_vec = self.ctx_mlp(ctx)         # [B,H]\n",
    "        ctx_rep = ctx_vec.unsqueeze(1).repeat(1,6,1)   # [B,6,H]\n",
    "\n",
    "        boat_vec = self.boat_mlp(boats)     # [B,6,H]\n",
    "        joint = torch.cat([ctx_rep, boat_vec], dim=-1) # [B,6,2H]\n",
    "        scores = self.score(joint).squeeze(-1)         # [B,6]\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d096b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_nll(scores, ranks):\n",
    "    loss = 0\n",
    "    for r in range(1, 7):\n",
    "        mask = (ranks == r)\n",
    "        s_r  = scores.masked_fill(~mask, -1e9)\n",
    "        loss += (torch.logsumexp(scores, dim=1) - s_r.max(dim=1).values)\n",
    "        scores = scores.masked_fill(mask, -1e9)\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a9377",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SimpleCPLNet().to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    for ctx, boats, ranks in tqdm.tqdm(loader_train):\n",
    "        ctx, boats, ranks = ctx.to(device), boats.to(device), ranks.to(device)\n",
    "        loss = pl_nll(model(ctx, boats), ranks)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "    # --- validation ---\n",
    "    model.eval(); val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for ctx, boats, ranks in loader_val:\n",
    "            ctx, boats, ranks = ctx.to(device), boats.to(device), ranks.to(device)\n",
    "            val_loss += pl_nll(model(ctx, boats), ranks).item() * len(ctx)\n",
    "    val_loss /= len(loader_val.dataset)\n",
    "    print(f\"epoch {epoch}  val_nll {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2e06aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"state_dict\": model.state_dict(),\n",
    "    \"scaler\": scaler_filename,\n",
    "    \"venue2id\": venue2id,\n",
    "    \"race_type2id\": race_type2id\n",
    "}, \"cplnet_checkpoint.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boat_racing-zew2npIb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
