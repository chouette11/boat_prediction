{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f2d9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82465003",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch, tqdm\n",
    "import pandas as pd, psycopg2, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np  \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import joblib\n",
    "import torch.nn as nn\n",
    "import datetime as dt\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43fe6ece",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2076 rows from the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_47918/765559011.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"\"\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DB_CONF = {\n",
    "    \"host\":     os.getenv(\"PGHOST\", \"localhost\"),\n",
    "    \"port\":     int(os.getenv(\"PGPORT\", 5432)),\n",
    "    \"dbname\":   os.getenv(\"PGDATABASE\", \"boatrace\"),\n",
    "    \"user\":     os.getenv(\"PGUSER\", \"br_user\"),\n",
    "    \"password\": os.getenv(\"PGPASSWORD\", \"secret\"),\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# DB 接続\n",
    "# ------------------------------------------------------------------\n",
    "conn = psycopg2.connect(**DB_CONF)\n",
    "df = pd.read_sql(\"\"\"\n",
    "    SELECT * FROM feat.train_features\n",
    "    WHERE race_date <= '2024-12-31'\n",
    "\"\"\", conn)\n",
    "\n",
    "print(f\"Loaded {len(df)} rows from the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f480862",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_47918/4060076584.py:6: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[bool_cols] = df[bool_cols].fillna(False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_key</th>\n",
       "      <th>race_date</th>\n",
       "      <th>venue</th>\n",
       "      <th>air_temp</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wave_height</th>\n",
       "      <th>water_temp</th>\n",
       "      <th>weather_txt</th>\n",
       "      <th>lane1_racer_id</th>\n",
       "      <th>lane1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>lane5_exh_time</th>\n",
       "      <th>lane5_st</th>\n",
       "      <th>lane5_fs_flag</th>\n",
       "      <th>lane5_rank</th>\n",
       "      <th>lane6_racer_id</th>\n",
       "      <th>lane6_weight</th>\n",
       "      <th>lane6_exh_time</th>\n",
       "      <th>lane6_st</th>\n",
       "      <th>lane6_fs_flag</th>\n",
       "      <th>lane6_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>若松_20240101_1</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>若松</td>\n",
       "      <td>-1.464009</td>\n",
       "      <td>-1.163734</td>\n",
       "      <td>-1.205108</td>\n",
       "      <td>-1.263955</td>\n",
       "      <td>晴</td>\n",
       "      <td>5104</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.15</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5271</td>\n",
       "      <td>51.5</td>\n",
       "      <td>6.87</td>\n",
       "      <td>0.05</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>若松_20240101_10</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>若松</td>\n",
       "      <td>-1.338795</td>\n",
       "      <td>-1.163734</td>\n",
       "      <td>-1.205108</td>\n",
       "      <td>-1.263955</td>\n",
       "      <td>晴</td>\n",
       "      <td>4413</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>5192</td>\n",
       "      <td>48.8</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0.07</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>若松_20240101_11</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>若松</td>\n",
       "      <td>-1.464009</td>\n",
       "      <td>-1.811120</td>\n",
       "      <td>-1.205108</td>\n",
       "      <td>-1.263955</td>\n",
       "      <td>晴</td>\n",
       "      <td>4155</td>\n",
       "      <td>53.7</td>\n",
       "      <td>...</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0.08</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>4958</td>\n",
       "      <td>52.9</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0.08</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>若松_20240101_12</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>若松</td>\n",
       "      <td>-1.464009</td>\n",
       "      <td>-0.516349</td>\n",
       "      <td>-0.543049</td>\n",
       "      <td>-1.263955</td>\n",
       "      <td>晴</td>\n",
       "      <td>4349</td>\n",
       "      <td>49.7</td>\n",
       "      <td>...</td>\n",
       "      <td>6.86</td>\n",
       "      <td>0.09</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>5148</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.07</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>若松_20240101_2</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>若松</td>\n",
       "      <td>-1.213581</td>\n",
       "      <td>-1.163734</td>\n",
       "      <td>-1.205108</td>\n",
       "      <td>-1.263955</td>\n",
       "      <td>晴</td>\n",
       "      <td>5155</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.99</td>\n",
       "      <td>0.03</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>4632</td>\n",
       "      <td>52.2</td>\n",
       "      <td>6.88</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         race_key   race_date venue  air_temp  wind_speed  wave_height  \\\n",
       "0   若松_20240101_1  2024-01-01    若松 -1.464009   -1.163734    -1.205108   \n",
       "1  若松_20240101_10  2024-01-01    若松 -1.338795   -1.163734    -1.205108   \n",
       "2  若松_20240101_11  2024-01-01    若松 -1.464009   -1.811120    -1.205108   \n",
       "3  若松_20240101_12  2024-01-01    若松 -1.464009   -0.516349    -0.543049   \n",
       "4   若松_20240101_2  2024-01-01    若松 -1.213581   -1.163734    -1.205108   \n",
       "\n",
       "   water_temp weather_txt  lane1_racer_id  lane1_weight  ...  lane5_exh_time  \\\n",
       "0   -1.263955           晴            5104          52.0  ...            6.90   \n",
       "1   -1.263955           晴            4413          52.0  ...            6.86   \n",
       "2   -1.263955           晴            4155          53.7  ...            6.91   \n",
       "3   -1.263955           晴            4349          49.7  ...            6.86   \n",
       "4   -1.263955           晴            5155          44.0  ...            6.99   \n",
       "\n",
       "   lane5_st  lane5_fs_flag  lane5_rank  lane6_racer_id  lane6_weight  \\\n",
       "0      0.15          False           4            5271          51.5   \n",
       "1      0.01          False           3            5192          48.8   \n",
       "2      0.08          False           2            4958          52.9   \n",
       "3      0.09          False           6            5148          47.0   \n",
       "4      0.03          False           6            4632          52.2   \n",
       "\n",
       "   lane6_exh_time  lane6_st  lane6_fs_flag  lane6_rank  \n",
       "0            6.87      0.05           True           6  \n",
       "1            6.91      0.07          False           5  \n",
       "2            6.91      0.08          False           4  \n",
       "3            6.90      0.07          False           5  \n",
       "4            6.88      0.02          False           3  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データフレーム全体の欠損値の総数: 55\n",
      "各列の欠損値の割合（%）:\n",
      "lane5_st          0.481696\n",
      "lane5_exh_time    0.433526\n",
      "lane1_st          0.240848\n",
      "lane1_exh_time    0.240848\n",
      "lane6_st          0.192678\n",
      "lane6_exh_time    0.192678\n",
      "lane2_exh_time    0.192678\n",
      "lane2_st          0.192678\n",
      "lane5_weight      0.096339\n",
      "wind_speed        0.048170\n",
      "wave_height       0.048170\n",
      "water_temp        0.048170\n",
      "lane1_weight      0.048170\n",
      "air_temp          0.048170\n",
      "lane3_st          0.048170\n",
      "lane4_st          0.048170\n",
      "lane3_exh_time    0.048170\n",
      "lane4_fs_flag     0.000000\n",
      "lane4_rank        0.000000\n",
      "lane5_racer_id    0.000000\n",
      "lane6_racer_id    0.000000\n",
      "lane5_fs_flag     0.000000\n",
      "lane5_rank        0.000000\n",
      "lane4_weight      0.000000\n",
      "lane6_weight      0.000000\n",
      "lane6_fs_flag     0.000000\n",
      "lane4_exh_time    0.000000\n",
      "race_key          0.000000\n",
      "lane4_racer_id    0.000000\n",
      "lane3_rank        0.000000\n",
      "lane3_fs_flag     0.000000\n",
      "race_date         0.000000\n",
      "lane3_weight      0.000000\n",
      "lane3_racer_id    0.000000\n",
      "lane2_rank        0.000000\n",
      "lane2_fs_flag     0.000000\n",
      "lane2_weight      0.000000\n",
      "lane2_racer_id    0.000000\n",
      "lane1_rank        0.000000\n",
      "lane1_fs_flag     0.000000\n",
      "lane1_racer_id    0.000000\n",
      "weather_txt       0.000000\n",
      "venue             0.000000\n",
      "lane6_rank        0.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['artifacts/wind_scaler.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "NUM_COLS = [\"air_temp\", \"wind_speed\", \"wave_height\", \"water_temp\"]\n",
    "scaler = StandardScaler().fit(df[NUM_COLS])\n",
    "df[NUM_COLS] = scaler.transform(df[NUM_COLS])\n",
    "\n",
    "bool_cols = [c for c in df.columns if c.endswith(\"_fs_flag\")]\n",
    "df[bool_cols] = df[bool_cols].fillna(False)\n",
    "\n",
    "rank_cols = [f\"lane{l}_rank\" for l in range(1, 7)]\n",
    "df[rank_cols] = df[rank_cols].fillna(7).astype(\"int32\")\n",
    "df.to_csv(\"artifacts/train_features.csv\", index=False)\n",
    "display(df.head())\n",
    "print(\"データフレーム全体の欠損値の総数:\", df.isnull().sum().sum())\n",
    "\n",
    "# 各列の欠損値の割合を表示（0〜1の値）\n",
    "missing_ratio = df.isnull().mean()\n",
    "\n",
    "# パーセント表示にする場合（見やすさのため）\n",
    "missing_ratio_percent = missing_ratio * 100\n",
    "\n",
    "print(\"各列の欠損値の割合（%）:\")\n",
    "print(missing_ratio_percent.sort_values(ascending=False))\n",
    "\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "scaler_filename = \"artifacts/wind_scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f648f51b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def encode(col):\n",
    "    uniq = sorted(df[col].dropna().unique())\n",
    "    mapping = {v:i for i,v in enumerate(uniq)}\n",
    "    df[col + \"_id\"] = df[col].map(mapping).fillna(-1).astype(\"int16\")\n",
    "    return mapping\n",
    "venue2id = encode(\"venue\")\n",
    "# race_type2id = encode(\"race_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8724821c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BoatRaceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    - 数値列: float32, NaN/±inf → 0.0\n",
    "    - rank ∈ {1,2,3,4,5,6,…}  (重複可) を\n",
    "      *重複しない 1〜6 & 最下位以降* に正規化して返す\n",
    "    \"\"\"\n",
    "    def __init__(self, frame: pd.DataFrame, mode: str = \"diff\"):\n",
    "        self.f = frame.copy()\n",
    "        self.mode = mode\n",
    "\n",
    "        # --- 数値列を float32, 欠損→0.0 -------------------------------\n",
    "        num_cols = self.f.select_dtypes(include=[\"number\", \"bool\"]).columns\n",
    "        self.f[num_cols] = (\n",
    "            self.f[num_cols]\n",
    "            .replace([np.inf, -np.inf], np.nan)\n",
    "            .fillna(0.0)\n",
    "            .astype(\"float32\")\n",
    "        )\n",
    "\n",
    "        if mode == \"zscore\":\n",
    "            self.boat_scaler = StandardScaler()\n",
    "            boat_feats = []\n",
    "            for lane in range(1, 7):\n",
    "                boat_feats.append(self.f[[f\"lane{lane}_exh_time\", f\"lane{lane}_st\", f\"lane{lane}_weight\"]].values)\n",
    "            boat_all = np.stack(boat_feats, axis=1).reshape(-1, 3)  # shape (N*6, 3)\n",
    "            self.boat_scaler.fit(boat_all)\n",
    "\n",
    "        # --- rank を int64 で保存 (欠損→99) ---------------------------\n",
    "        for lane in range(1, 7):\n",
    "            col = f\"lane{lane}_rank\"\n",
    "            if col in self.f.columns:\n",
    "                self.f[col] = (\n",
    "                    self.f[col]\n",
    "                    .fillna(99)          # 欠損は論外扱い\n",
    "                    .astype(\"int64\")\n",
    "                )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.f)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        r = self.f.iloc[idx]\n",
    "\n",
    "        # ❶ 環境特徴量 --------------------------------------------------\n",
    "        ctx = torch.tensor([\n",
    "            r[\"wind_speed\"], r[\"wave_height\"],\n",
    "            r[\"air_temp\"],   r[\"water_temp\"],\n",
    "        ], dtype=torch.float32)\n",
    "\n",
    "        # ❷ 各艇の元特徴量を収集 ---------------------------------------\n",
    "        exh_times = [r[f\"lane{lane}_exh_time\"] for lane in range(1, 7)]\n",
    "        st_times  = [r[f\"lane{lane}_st\"] for lane in range(1, 7)]\n",
    "        fs_flags  = [float(r[f\"lane{lane}_fs_flag\"]) for lane in range(1, 7)]\n",
    "        weights   = [r[f\"lane{lane}_weight\"] for lane in range(1, 7)]\n",
    "        raw_ranks = [int(r[f\"lane{lane}_rank\"]) for lane in range(1, 7)]\n",
    "        lane_ids  = list(range(6))\n",
    "\n",
    "        boats = []\n",
    "        for i in range(6):\n",
    "            if self.mode == \"diff\":\n",
    "                mean_exh = np.mean(exh_times)\n",
    "                mean_st  = np.mean(st_times)\n",
    "                mean_wt  = np.mean(weights)\n",
    "                feat = [\n",
    "                    exh_times[i] - mean_exh,\n",
    "                    st_times[i]  - mean_st,\n",
    "                    fs_flags[i],\n",
    "                    weights[i]   - mean_wt,\n",
    "                ]\n",
    "            elif self.mode == \"raw\":\n",
    "                feat = [\n",
    "                    exh_times[i],\n",
    "                    st_times[i],\n",
    "                    fs_flags[i],\n",
    "                    weights[i],\n",
    "                ]\n",
    "            elif self.mode == \"log\":\n",
    "                feat = [\n",
    "                    np.log1p(exh_times[i]),\n",
    "                    np.log1p(st_times[i]),\n",
    "                    fs_flags[i],\n",
    "                    np.log1p(weights[i]),\n",
    "                ]\n",
    "            elif self.mode == \"zscore\":\n",
    "                inp = np.array([[exh_times[i], st_times[i], weights[i]]])\n",
    "                scaled = self.boat_scaler.transform(inp)[0]\n",
    "                feat = [\n",
    "                    scaled[0],\n",
    "                    scaled[1],\n",
    "                    fs_flags[i],\n",
    "                    scaled[2],\n",
    "                ]\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown mode: {self.mode}\")\n",
    "\n",
    "            boats.append(torch.tensor(feat, dtype=torch.float32))\n",
    "\n",
    "        # ---------- ★ 重複しない順位を付け直す ★ ----------------------\n",
    "        # 例: [1, 2, 6, 3, 6, 6] → [1, 2, 4, 3, 5, 6]\n",
    "        order = np.argsort(raw_ranks)          # 小さい順に艇 index を並べる\n",
    "        new_rank = [0]*6\n",
    "        for new_pos, lane_idx in enumerate(order, start=1):  # new_pos:1..6\n",
    "            new_rank[lane_idx] = new_pos       # 一意な 1..6 を付け直し\n",
    "\n",
    "        return (\n",
    "            ctx,\n",
    "            torch.stack(boats),\n",
    "            torch.tensor(lane_ids, dtype=torch.int64),\n",
    "            torch.tensor(new_rank, dtype=torch.int64)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f779731",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "── sample race ──\n",
      "rank    : [np.int32(1), np.int32(3), np.int32(6), np.int32(2), np.int32(5), np.int32(4)]\n",
      "exh_time: [np.float64(6.93), np.float64(6.94), np.float64(6.95), np.float64(6.93), np.float64(6.95), np.float64(6.89)]\n",
      "st      : [np.float64(0.14), np.float64(0.07), np.float64(0.03), np.float64(0.0), np.float64(0.01), np.float64(0.07)]\n",
      "fs_flag : [np.False_, np.False_, np.False_, np.False_, np.False_, np.False_]\n",
      "weight  : [np.float64(52.9), np.float64(52.3), np.float64(51.0), np.float64(52.0), np.float64(53.2), np.float64(54.5)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0) ── データの“ラベル & 特徴量”を 1 行だけ覗く可視化 Snippet\n",
    "#      ★★ ここは notebook なら「1 セルだけ」実行すれば OK ★★\n",
    "# ------------------------------------------------------------\n",
    "def peek_one(df: pd.DataFrame, seed: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    ランダムに 1 レース（1 行）だけ抜き取り、順位と主要特徴量を一覧表示\n",
    "    \"\"\"\n",
    "    row = df.sample(1, random_state=seed).squeeze()\n",
    "\n",
    "    def lane_list(prefix: str):\n",
    "        return [row[f\"lane{i}_{prefix}\"] for i in range(1, 7)]\n",
    "\n",
    "    print(\"── sample race ──\")\n",
    "    print(\"rank    :\", lane_list(\"rank\"))\n",
    "    print(\"exh_time:\", lane_list(\"exh_time\"))\n",
    "    print(\"st      :\", lane_list(\"st\"))\n",
    "    print(\"fs_flag :\", lane_list(\"fs_flag\"))\n",
    "    print(\"weight  :\", lane_list(\"weight\"))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# ここで一度だけ呼んで目視確認しておくとズレにすぐ気付けます\n",
    "peek_one(df)\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "LANE_DIM = 8\n",
    "class SimpleCPLNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ctx(4) + boat(4) → lane ごとにスコア 1 個\n",
    "    \"\"\"\n",
    "    def __init__(self, ctx_in=4, boat_in=4, hidden=64, lane_dim=LANE_DIM):\n",
    "        super().__init__()\n",
    "        self.lane_emb = nn.Embedding(6, lane_dim)\n",
    "        self.ctx_fc   = nn.Linear(ctx_in, hidden)\n",
    "        self.boat_fc  = nn.Linear(boat_in + lane_dim, hidden)\n",
    "        self.head     = nn.Linear(hidden, 1)\n",
    "\n",
    "        # 重み初期化を対称性ブレイク用に Xavier で揃える\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, ctx, boats, lane_ids):  # boats:(B,6,4) lane_ids:(B,6)\n",
    "        B, L, _ = boats.size()\n",
    "        ctx_emb  = self.ctx_fc(ctx)           # (B,h)\n",
    "        # DataLoader から来る lane_ids が (B,) なら (B,6) へブロードキャスト\n",
    "        # -------- lane_ids の形状を必ず (B,6) にそろえる --------\n",
    "        if lane_ids.dim() == 1:               # (B,) → (B,6)\n",
    "            lane_ids = lane_ids.unsqueeze(1).expand(-1, L)\n",
    "        elif lane_ids.dim() == 2 and lane_ids.size(1) == 1:  # (B,1) → (B,6)\n",
    "            lane_ids = lane_ids.expand(-1, L)\n",
    "        # 以外 (既に (B,6)) はそのままで OK\n",
    "        lane_ids = lane_ids.contiguous()      # Embedding 要求に備え contiguous 化\n",
    "\n",
    "\n",
    "        lane_emb = self.lane_emb(lane_ids)    # (B,6,lane_dim)\n",
    "        boat_inp = torch.cat([boats, lane_emb], dim=-1)\n",
    "        boat_emb = self.boat_fc(boat_inp)     # (B,6,h)\n",
    "\n",
    "        # broadcast ctx → 各 lane\n",
    "        score = self.head(torch.tanh(ctx_emb.unsqueeze(1) + boat_emb))  # (B,6,1)\n",
    "        return score.squeeze(-1)           # (B,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "162fdf61",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl_nll should be ~0 : 2.0691652297973633\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def pl_nll(scores: torch.Tensor, ranks: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    scores : (B, 6) ― lane0 – lane5 のスコア\n",
    "    ranks  : (B, 6) ― **1 が 1 着, … 6 が 6 着**（列番号ではない）\n",
    "   \"\"\"\n",
    "    scores = scores.clamp(-20.0, 20.0)\n",
    "\n",
    "    # 着順 (1 → 6) に並んだ lane index を取得\n",
    "    order = torch.argsort(ranks, dim=1)      # shape (B,6)\n",
    "\n",
    "    nll = torch.zeros(scores.size(0), device=scores.device)\n",
    "    s   = scores.clone()\n",
    "    for pos in range(6):\n",
    "        log_denom = torch.logsumexp(s, dim=1)            # log Σₗ exp\n",
    "        idx       = order[:, pos]                        # (B,)\n",
    "        chosen    = s.gather(1, idx.unsqueeze(1)).squeeze(1)\n",
    "        nll      += log_denom - chosen\n",
    "        s         = s.scatter(1, idx.unsqueeze(1), float('-inf'))\n",
    "\n",
    "    return nll.mean()\n",
    "\n",
    "# ── pl_nll が正しいか 3 秒で判定 ──\n",
    "scores = torch.tensor([[6, 5, 4, 3, 2, 1]], dtype=torch.float32)  # lane0 が最強\n",
    "ranks  = torch.tensor([[1, 2, 3, 4, 5, 6]], dtype=torch.int64)    # lane0 が 1 着\n",
    "print(\"pl_nll should be ~0 :\", pl_nll(scores, ranks).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1f001cb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1819  val: 257\n",
      "[debug] average |grad| = 2.154e+03\n",
      "epoch  0  train_nll 7.2835  val_nll 7.1993\n",
      "Top-1 Acc: 0.125   Trifecta Hit: 0.062\n",
      "epoch  1  train_nll 7.1012  val_nll 6.9972\n",
      "Top-1 Acc: 0.136   Trifecta Hit: 0.074\n",
      "epoch  2  train_nll 6.9117  val_nll 6.8139\n",
      "Top-1 Acc: 0.136   Trifecta Hit: 0.074\n",
      "epoch  3  train_nll 6.7418  val_nll 6.6571\n",
      "Top-1 Acc: 0.152   Trifecta Hit: 0.089\n",
      "epoch  4  train_nll 6.5969  val_nll 6.5274\n",
      "Top-1 Acc: 0.167   Trifecta Hit: 0.128\n",
      "epoch  5  train_nll 6.4811  val_nll 6.4236\n",
      "Top-1 Acc: 0.187   Trifecta Hit: 0.167\n",
      "epoch  6  train_nll 6.3874  val_nll 6.3406\n",
      "Top-1 Acc: 0.268   Trifecta Hit: 0.175\n",
      "epoch  7  train_nll 6.3136  val_nll 6.2749\n",
      "Top-1 Acc: 0.459   Trifecta Hit: 0.175\n",
      "epoch  8  train_nll 6.2557  val_nll 6.2248\n",
      "Top-1 Acc: 0.576   Trifecta Hit: 0.175\n",
      "epoch  9  train_nll 6.2109  val_nll 6.1757\n",
      "Top-1 Acc: 0.611   Trifecta Hit: 0.175\n",
      "epoch 10  train_nll 6.1784  val_nll 6.1275\n",
      "Top-1 Acc: 0.619   Trifecta Hit: 0.179\n",
      "epoch 11  train_nll 6.1549  val_nll 6.0811\n",
      "Top-1 Acc: 0.619   Trifecta Hit: 0.183\n",
      "epoch 12  train_nll 6.1446  val_nll 6.0514\n",
      "Top-1 Acc: 0.623   Trifecta Hit: 0.171\n",
      "epoch 13  train_nll 6.1421  val_nll 6.0344\n",
      "Top-1 Acc: 0.626   Trifecta Hit: 0.148\n",
      "epoch 14  train_nll 6.1409  val_nll 6.0286\n",
      "Top-1 Acc: 0.626   Trifecta Hit: 0.163\n",
      "epoch 15  train_nll 6.1428  val_nll 6.0396\n",
      "Top-1 Acc: 0.626   Trifecta Hit: 0.183\n",
      "epoch 16  train_nll 6.1424  val_nll 6.0520\n",
      "Top-1 Acc: 0.626   Trifecta Hit: 0.191\n",
      "epoch 17  train_nll 6.1310  val_nll 6.0559\n",
      "Top-1 Acc: 0.623   Trifecta Hit: 0.171\n",
      "epoch 18  train_nll 6.1229  val_nll 6.0476\n",
      "Top-1 Acc: 0.623   Trifecta Hit: 0.152\n",
      "epoch 19  train_nll 6.1190  val_nll 6.0287\n",
      "Top-1 Acc: 0.619   Trifecta Hit: 0.171\n",
      "epoch 20  train_nll 6.1244  val_nll 6.0205\n",
      "Top-1 Acc: 0.619   Trifecta Hit: 0.171\n",
      "epoch 21  train_nll 6.1429  val_nll 6.0287\n",
      "Top-1 Acc: 0.623   Trifecta Hit: 0.167\n",
      "epoch 22  train_nll 6.1447  val_nll 6.0280\n",
      "Top-1 Acc: 0.623   Trifecta Hit: 0.179\n",
      "epoch 23  train_nll 6.1215  val_nll 6.0346\n",
      "Top-1 Acc: 0.623   Trifecta Hit: 0.175\n",
      "epoch 24  train_nll 6.1115  val_nll 6.0664\n",
      "Top-1 Acc: 0.623   Trifecta Hit: 0.160\n",
      "epoch 25  train_nll 6.1276  val_nll 6.0919\n",
      "Top-1 Acc: 0.623   Trifecta Hit: 0.117\n",
      "epoch 26  train_nll 6.1381  val_nll 6.0688\n",
      "Top-1 Acc: 0.623   Trifecta Hit: 0.117\n",
      "epoch 27  train_nll 6.1242  val_nll 6.0270\n",
      "Top-1 Acc: 0.623   Trifecta Hit: 0.163\n",
      "epoch 28  train_nll 6.1102  val_nll 6.0028\n",
      "Top-1 Acc: 0.626   Trifecta Hit: 0.175\n",
      "epoch 29  train_nll 6.1153  val_nll 6.0072\n",
      "Top-1 Acc: 0.626   Trifecta Hit: 0.191\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df[\"race_date\"] = pd.to_datetime(df[\"race_date\"]).dt.date\n",
    "cutoff = dt.date(2024, 11, 1)\n",
    "\n",
    "ds_train = BoatRaceDataset(df[df[\"race_date\"] <  cutoff])\n",
    "ds_val   = BoatRaceDataset(df[df[\"race_date\"] >= cutoff])\n",
    "print(f\"train: {len(ds_train)}  val: {len(ds_val)}\")\n",
    "# print(\"train:\", ds_train[0])  # 1 レースの特徴量を確認\n",
    "\n",
    "loader_train = DataLoader(ds_train, batch_size=256, shuffle=True)\n",
    "loader_val   = DataLoader(ds_val,   batch_size=512)\n",
    "\n",
    "# ------------------- ⑤ 学習ループ（LR↓ + Clip） --------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model  = SimpleCPLNet().to(device)\n",
    "opt    = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "EPOCHS = 30\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    if epoch == 0:                  # 1 エポック目だけ試す例\n",
    "        ctx, boats, lane_ids, ranks = next(iter(loader_train))\n",
    "        ctx, boats = ctx.to(device), boats.to(device)\n",
    "        lane_ids = lane_ids.to(device)\n",
    "\n",
    "        scores = model(ctx, boats, lane_ids)\n",
    "        scores.sum().backward()     # ダミー backward\n",
    "        grad_norm = sum(p.grad.abs().mean().item() for p in model.parameters())\n",
    "        print(f\"[debug] average |grad| = {grad_norm:.3e}\")\n",
    "    # ---- train ----\n",
    "    model.train(); tr_sum = 0\n",
    "    for ctx, boats, lane_ids, ranks in loader_train:\n",
    "        ctx, boats = ctx.to(device), boats.to(device)\n",
    "        lane_ids, ranks = lane_ids.to(device), ranks.to(device)\n",
    "\n",
    "        loss = pl_nll(model(ctx, boats, lane_ids), ranks)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)  # ★勾配爆発対策★\n",
    "        opt.step()\n",
    "\n",
    "        tr_sum += loss.item() * len(ctx)\n",
    "\n",
    "    tr_nll = tr_sum / len(loader_train.dataset)\n",
    "\n",
    "    # ---- validation ----\n",
    "    model.eval(); val_sum = 0\n",
    "    with torch.no_grad():\n",
    "        for ctx, boats, lane_ids, ranks in loader_val:\n",
    "            ctx, boats = ctx.to(device), boats.to(device)\n",
    "            lane_ids, ranks = lane_ids.to(device), ranks.to(device)\n",
    "            val_sum += pl_nll(model(ctx, boats, lane_ids), ranks).item() * len(ctx)\n",
    "\n",
    "    val_nll = val_sum / len(loader_val.dataset)\n",
    "\n",
    "    print(f\"epoch {epoch:2d}  train_nll {tr_nll:.4f}  val_nll {val_nll:.4f}\")\n",
    "\n",
    "    # ---- accuracy & 三連単的中率 ----\n",
    "    def top1_accuracy(scores, ranks):\n",
    "        pred_top1 = scores.argmax(dim=1)\n",
    "        true_top1 = (ranks == 1).nonzero(as_tuple=True)[1]\n",
    "        return (pred_top1 == true_top1).float().mean().item()\n",
    "\n",
    "    def trifecta_hit_rate(scores, ranks):\n",
    "        \"\"\"\n",
    "        予測スコア上位3着までと、実際の着順上位3着の組み合わせ一致を見る（順不同）\n",
    "        \"\"\"\n",
    "        pred_top3 = torch.topk(scores, k=3, dim=1).indices\n",
    "        true_top3 = torch.topk(-ranks, k=3, dim=1).indices  # 小さい順に上位3着\n",
    "        hit = [set(p.tolist()) == set(t.tolist()) for p, t in zip(pred_top3, true_top3)]\n",
    "        return sum(hit) / len(hit)\n",
    "\n",
    "    # accuracy 評価\n",
    "    model.eval(); all_scores, all_ranks = [], []\n",
    "    with torch.no_grad():\n",
    "        for ctx, boats, lane_ids, ranks in loader_val:\n",
    "            ctx, boats = ctx.to(device), boats.to(device)\n",
    "            lane_ids = lane_ids.to(device)\n",
    "            scores = model(ctx, boats, lane_ids).cpu()\n",
    "            all_scores.append(scores)\n",
    "            all_ranks.append(ranks)\n",
    "\n",
    "    all_scores = torch.cat(all_scores, dim=0)\n",
    "    all_ranks = torch.cat(all_ranks, dim=0)\n",
    "\n",
    "    acc_top1 = top1_accuracy(all_scores, all_ranks)\n",
    "    acc_tri3 = trifecta_hit_rate(all_scores, all_ranks)\n",
    "\n",
    "    print(f\"Top-1 Acc: {acc_top1:.3f}   Trifecta Hit: {acc_tri3:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7abe4d1b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "► 行間 variance (should be >0):\n",
      "venue_id          0.000000\n",
      "lane1_st          0.002938\n",
      "lane4_st          0.005507\n",
      "lane6_exh_time    0.006196\n",
      "lane6_st          0.006428\n",
      "lane1_exh_time    0.006618\n",
      "lane4_exh_time    0.006890\n",
      "lane5_st          0.008517\n",
      "lane3_exh_time    0.009960\n",
      "lane2_exh_time    0.010849\n",
      "dtype: float64\n",
      "\n",
      "► 6 艇間 variance:\n",
      "[('air_temp', nan), ('wind_speed', nan), ('wave_height', nan), ('water_temp', nan), ('lane1_racer_id', nan), ('lane1_weight', nan), ('lane1_exh_time', nan), ('lane1_st', nan), ('lane1_rank', nan), ('lane2_racer_id', nan)]\n",
      "[tiny] final loss: 0.20566602051258087\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# ④ ── 「勾配が流れているか」を瞬時に確認する Snippet\n",
    "#       （エポック終了後 1 回だけ走らせれば十分）\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# ============================================================\n",
    " \n",
    " # ============================================================\n",
    " # ⑤ ── 超小規模データで「過学習できるか」テスト関数\n",
    " #       必要時に呼び出して 0.1 以下まで loss が落ちるか確認\n",
    " # ------------------------------------------------------------\n",
    "def overfit_tiny(df: pd.DataFrame, device: str = \"cpu\"):\n",
    "    \"\"\"\n",
    "    データセットを 10 行だけに縮小し、500 step で過学習できるか検証\n",
    "    \"\"\"\n",
    "    tiny_df = df.sample(10, random_state=1).reset_index(drop=True)\n",
    "    tiny_ds = BoatRaceDataset(tiny_df)\n",
    "    tiny_loader = DataLoader(tiny_ds, batch_size=10, shuffle=True)\n",
    "\n",
    "    net = SimpleCPLNet().to(device)\n",
    "    opt = torch.optim.AdamW(net.parameters(), lr=3e-3)\n",
    "\n",
    "    for _ in range(500):\n",
    "        ctx, boats, lane_ids, ranks = next(iter(tiny_loader))\n",
    "        ctx, boats = ctx.to(device), boats.to(device)\n",
    "        lane_ids, ranks = lane_ids.to(device), ranks.to(device)\n",
    "\n",
    "        loss = pl_nll(net(ctx, boats, lane_ids), ranks)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "    print(\"[tiny] final loss:\", loss.item())\n",
    "\n",
    "\n",
    "# ---- tiny データで特徴量の分散を確認 -----------------------\n",
    "tiny_df = df.sample(10, random_state=1).reset_index(drop=True)\n",
    "num_cols = tiny_df.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# (1) 行間（=レース間）での分散\n",
    "print(\"► 行間 variance (should be >0):\")\n",
    "print(tiny_df[num_cols].var().nsmallest(10))\n",
    "\n",
    "# (2) 同一レース内（= 6 艇間）での分散\n",
    "def per_race_var(col):\n",
    "    return tiny_df.groupby(\"race_key\")[col].var().mean()\n",
    "\n",
    "per_race = {c: per_race_var(c) for c in num_cols}\n",
    "print(\"\\n► 6 艇間 variance:\")\n",
    "print(sorted(per_race.items(), key=lambda x: x[1])[:10])\n",
    "\n",
    "# ---- 呼び方例 ----\n",
    "overfit_tiny(df, device)\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06b35063",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.save({\n",
    "    \"state_dict\": model.state_dict(),\n",
    "    \"scaler\": scaler_filename,\n",
    "    \"venue2id\": venue2id,\n",
    "    # \"race_type2id\": race_type2id\n",
    "}, \"cplnet_checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2e06690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# .ipynbを.pyに変換しておく\n",
    "if __name__ == \"__main__\":\n",
    "    import nbformat\n",
    "    from nbconvert import PythonExporter\n",
    "\n",
    "    with open(\"main.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "    exporter = PythonExporter()\n",
    "    source, _ = exporter.from_notebook_node(nb)\n",
    "\n",
    "    with open(\"main.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(source)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
