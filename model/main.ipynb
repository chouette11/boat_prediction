{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d0077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d506fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8101b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68840881",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f6ad6275",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch, tqdm\n",
    "import pandas as pd, psycopg2, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np  \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import joblib\n",
    "import torch.nn as nn\n",
    "import datetime as dt\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "49013331",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2076 rows from the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_47918/946689521.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"\"\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "DB_CONF = {\n",
    "    \"host\":     os.getenv(\"PGHOST\", \"localhost\"),\n",
    "    \"port\":     int(os.getenv(\"PGPORT\", 5432)),\n",
    "    \"dbname\":   os.getenv(\"PGDATABASE\", \"boatrace\"),\n",
    "    \"user\":     os.getenv(\"PGUSER\", \"br_user\"),\n",
    "    \"password\": os.getenv(\"PGPASSWORD\", \"secret\"),\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# DB 接続\n",
    "# ------------------------------------------------------------------\n",
    "conn = psycopg2.connect(**DB_CONF)\n",
    "df = pd.read_sql(\"\"\"\n",
    "    SELECT * FROM feat.train_features\n",
    "    WHERE race_date <= '2024-12-31'\n",
    "\"\"\", conn)\n",
    "\n",
    "print(f\"Loaded {len(df)} rows from the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "377b6bb7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_47918/3934270286.py:11: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[bool_cols] = df[bool_cols].fillna(False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_key</th>\n",
       "      <th>race_date</th>\n",
       "      <th>venue</th>\n",
       "      <th>air_temp</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wave_height</th>\n",
       "      <th>water_temp</th>\n",
       "      <th>weather_txt</th>\n",
       "      <th>wind_dir_deg</th>\n",
       "      <th>lane1_racer_id</th>\n",
       "      <th>...</th>\n",
       "      <th>lane5_rank</th>\n",
       "      <th>lane6_racer_id</th>\n",
       "      <th>lane6_weight</th>\n",
       "      <th>lane6_exh_time</th>\n",
       "      <th>lane6_st</th>\n",
       "      <th>lane6_fs_flag</th>\n",
       "      <th>lane6_rank</th>\n",
       "      <th>wind_dir_rad</th>\n",
       "      <th>wind_sin</th>\n",
       "      <th>wind_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>若松_20240101_1</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>若松</td>\n",
       "      <td>-1.464009</td>\n",
       "      <td>-1.163734</td>\n",
       "      <td>-1.205108</td>\n",
       "      <td>-1.263955</td>\n",
       "      <td>晴</td>\n",
       "      <td>67.5</td>\n",
       "      <td>5104</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5271</td>\n",
       "      <td>51.5</td>\n",
       "      <td>6.87</td>\n",
       "      <td>0.05</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>1.178097</td>\n",
       "      <td>0.779280</td>\n",
       "      <td>0.288354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>若松_20240101_10</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>若松</td>\n",
       "      <td>-1.338795</td>\n",
       "      <td>-1.163734</td>\n",
       "      <td>-1.205108</td>\n",
       "      <td>-1.263955</td>\n",
       "      <td>晴</td>\n",
       "      <td>67.5</td>\n",
       "      <td>4413</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5192</td>\n",
       "      <td>48.8</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0.07</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>1.178097</td>\n",
       "      <td>0.779280</td>\n",
       "      <td>0.288354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>若松_20240101_11</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>若松</td>\n",
       "      <td>-1.464009</td>\n",
       "      <td>-1.811120</td>\n",
       "      <td>-1.205108</td>\n",
       "      <td>-1.263955</td>\n",
       "      <td>晴</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4155</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4958</td>\n",
       "      <td>52.9</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0.08</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>若松_20240101_12</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>若松</td>\n",
       "      <td>-1.464009</td>\n",
       "      <td>-0.516349</td>\n",
       "      <td>-0.543049</td>\n",
       "      <td>-1.263955</td>\n",
       "      <td>晴</td>\n",
       "      <td>67.5</td>\n",
       "      <td>4349</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5148</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.07</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>1.178097</td>\n",
       "      <td>0.779280</td>\n",
       "      <td>0.288354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>若松_20240101_2</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>若松</td>\n",
       "      <td>-1.213581</td>\n",
       "      <td>-1.163734</td>\n",
       "      <td>-1.205108</td>\n",
       "      <td>-1.263955</td>\n",
       "      <td>晴</td>\n",
       "      <td>22.5</td>\n",
       "      <td>5155</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4632</td>\n",
       "      <td>52.2</td>\n",
       "      <td>6.88</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.392699</td>\n",
       "      <td>0.028337</td>\n",
       "      <td>1.278569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         race_key   race_date venue  air_temp  wind_speed  wave_height  \\\n",
       "0   若松_20240101_1  2024-01-01    若松 -1.464009   -1.163734    -1.205108   \n",
       "1  若松_20240101_10  2024-01-01    若松 -1.338795   -1.163734    -1.205108   \n",
       "2  若松_20240101_11  2024-01-01    若松 -1.464009   -1.811120    -1.205108   \n",
       "3  若松_20240101_12  2024-01-01    若松 -1.464009   -0.516349    -0.543049   \n",
       "4   若松_20240101_2  2024-01-01    若松 -1.213581   -1.163734    -1.205108   \n",
       "\n",
       "   water_temp weather_txt  wind_dir_deg  lane1_racer_id  ...  lane5_rank  \\\n",
       "0   -1.263955           晴          67.5            5104  ...           4   \n",
       "1   -1.263955           晴          67.5            4413  ...           3   \n",
       "2   -1.263955           晴           NaN            4155  ...           2   \n",
       "3   -1.263955           晴          67.5            4349  ...           6   \n",
       "4   -1.263955           晴          22.5            5155  ...           6   \n",
       "\n",
       "   lane6_racer_id  lane6_weight  lane6_exh_time  lane6_st  lane6_fs_flag  \\\n",
       "0            5271          51.5            6.87      0.05           True   \n",
       "1            5192          48.8            6.91      0.07          False   \n",
       "2            4958          52.9            6.91      0.08          False   \n",
       "3            5148          47.0            6.90      0.07          False   \n",
       "4            4632          52.2            6.88      0.02          False   \n",
       "\n",
       "   lane6_rank  wind_dir_rad  wind_sin  wind_cos  \n",
       "0           6      1.178097  0.779280  0.288354  \n",
       "1           5      1.178097  0.779280  0.288354  \n",
       "2           4           NaN       NaN       NaN  \n",
       "3           5      1.178097  0.779280  0.288354  \n",
       "4           3      0.392699  0.028337  1.278569  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データフレーム全体の欠損値の総数: 247\n",
      "各列の欠損値の割合（%）:\n",
      "wind_cos          2.312139\n",
      "wind_sin          2.312139\n",
      "wind_dir_rad      2.312139\n",
      "wind_dir_deg      2.312139\n",
      "lane5_st          0.481696\n",
      "lane5_exh_time    0.433526\n",
      "lane1_exh_time    0.240848\n",
      "lane1_st          0.240848\n",
      "lane2_exh_time    0.192678\n",
      "lane6_st          0.192678\n",
      "lane6_exh_time    0.192678\n",
      "lane2_st          0.192678\n",
      "lane5_weight      0.096339\n",
      "lane4_st          0.048170\n",
      "lane3_exh_time    0.048170\n",
      "lane3_st          0.048170\n",
      "air_temp          0.048170\n",
      "wind_speed        0.048170\n",
      "wave_height       0.048170\n",
      "water_temp        0.048170\n",
      "lane1_weight      0.048170\n",
      "lane2_weight      0.000000\n",
      "lane5_racer_id    0.000000\n",
      "venue             0.000000\n",
      "lane6_rank        0.000000\n",
      "lane6_fs_flag     0.000000\n",
      "lane6_weight      0.000000\n",
      "lane6_racer_id    0.000000\n",
      "lane5_rank        0.000000\n",
      "lane5_fs_flag     0.000000\n",
      "weather_txt       0.000000\n",
      "lane1_racer_id    0.000000\n",
      "lane4_rank        0.000000\n",
      "lane2_racer_id    0.000000\n",
      "lane4_fs_flag     0.000000\n",
      "lane4_exh_time    0.000000\n",
      "lane4_weight      0.000000\n",
      "lane4_racer_id    0.000000\n",
      "lane3_rank        0.000000\n",
      "lane3_fs_flag     0.000000\n",
      "race_date         0.000000\n",
      "lane1_fs_flag     0.000000\n",
      "lane3_weight      0.000000\n",
      "lane3_racer_id    0.000000\n",
      "lane2_rank        0.000000\n",
      "lane2_fs_flag     0.000000\n",
      "lane1_rank        0.000000\n",
      "race_key          0.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['artifacts/wind_scaler.pkl']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 風向をラジアンに変換し、sin/cos 特徴量を生成\n",
    "df[\"wind_dir_rad\"] = np.deg2rad(df[\"wind_dir_deg\"])\n",
    "df[\"wind_sin\"] = np.sin(df[\"wind_dir_rad\"])\n",
    "df[\"wind_cos\"] = np.cos(df[\"wind_dir_rad\"])\n",
    "\n",
    "NUM_COLS = [\"air_temp\", \"wind_speed\", \"wave_height\", \"water_temp\", \"wind_sin\", \"wind_cos\"]\n",
    "scaler = StandardScaler().fit(df[NUM_COLS])\n",
    "df[NUM_COLS] = scaler.transform(df[NUM_COLS])\n",
    "\n",
    "bool_cols = [c for c in df.columns if c.endswith(\"_fs_flag\")]\n",
    "df[bool_cols] = df[bool_cols].fillna(False)\n",
    "\n",
    "rank_cols = [f\"lane{l}_rank\" for l in range(1, 7)]\n",
    "df[rank_cols] = df[rank_cols].fillna(7).astype(\"int32\")\n",
    "df.to_csv(\"artifacts/train_features.csv\", index=False)\n",
    "display(df.head())\n",
    "print(\"データフレーム全体の欠損値の総数:\", df.isnull().sum().sum())\n",
    "\n",
    "# 各列の欠損値の割合を表示（0〜1の値）\n",
    "missing_ratio = df.isnull().mean()\n",
    "\n",
    "# パーセント表示にする場合（見やすさのため）\n",
    "missing_ratio_percent = missing_ratio * 100\n",
    "\n",
    "print(\"各列の欠損値の割合（%）:\")\n",
    "print(missing_ratio_percent.sort_values(ascending=False))\n",
    "\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "scaler_filename = \"artifacts/wind_scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "15c81bd3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def encode(col):\n",
    "    uniq = sorted(df[col].dropna().unique())\n",
    "    mapping = {v:i for i,v in enumerate(uniq)}\n",
    "    df[col + \"_id\"] = df[col].map(mapping).fillna(-1).astype(\"int16\")\n",
    "    return mapping\n",
    "venue2id = encode(\"venue\")\n",
    "# race_type2id = encode(\"race_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "243463cd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BoatRaceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    - 数値列: float32, NaN/±inf → 0.0\n",
    "    - rank ∈ {1,2,3,4,5,6,…}  (重複可) を\n",
    "      *重複しない 1〜6 & 最下位以降* に正規化して返す\n",
    "    \"\"\"\n",
    "    def __init__(self, frame: pd.DataFrame, mode: str = \"diff\"):\n",
    "        self.f = frame.copy()\n",
    "        self.mode = mode\n",
    "\n",
    "        # --- 数値列を float32, 欠損→0.0 -------------------------------\n",
    "        num_cols = self.f.select_dtypes(include=[\"number\", \"bool\"]).columns\n",
    "        self.f[num_cols] = (\n",
    "            self.f[num_cols]\n",
    "            .replace([np.inf, -np.inf], np.nan)\n",
    "            .fillna(0.0)\n",
    "            .astype(\"float32\")\n",
    "        )\n",
    "\n",
    "        if mode == \"zscore\":\n",
    "            self.boat_scaler = StandardScaler()\n",
    "            boat_feats = []\n",
    "            for lane in range(1, 7):\n",
    "                boat_feats.append(self.f[[f\"lane{lane}_exh_time\", f\"lane{lane}_st\", f\"lane{lane}_weight\"]].values)\n",
    "            boat_all = np.stack(boat_feats, axis=1).reshape(-1, 3)  # shape (N*6, 3)\n",
    "            self.boat_scaler.fit(boat_all)\n",
    "\n",
    "        # --- rank を int64 で保存 (欠損→99) ---------------------------\n",
    "        for lane in range(1, 7):\n",
    "            col = f\"lane{lane}_rank\"\n",
    "            if col in self.f.columns:\n",
    "                self.f[col] = (\n",
    "                    self.f[col]\n",
    "                    .fillna(99)          # 欠損は論外扱い\n",
    "                    .astype(\"int64\")\n",
    "                )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.f)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        r = self.f.iloc[idx]\n",
    "\n",
    "        # ❶ 環境特徴量 --------------------------------------------------\n",
    "        ctx = torch.tensor([\n",
    "            r[\"wind_speed\"], r[\"wave_height\"],\n",
    "            r[\"air_temp\"],   r[\"water_temp\"],\n",
    "            r[\"wind_sin\"],   r[\"wind_cos\"]\n",
    "        ], dtype=torch.float32)\n",
    "\n",
    "        # ❷ 各艇の元特徴量を収集 ---------------------------------------\n",
    "        exh_times = [r[f\"lane{lane}_exh_time\"] for lane in range(1, 7)]\n",
    "        st_times  = [r[f\"lane{lane}_st\"] for lane in range(1, 7)]\n",
    "        fs_flags  = [float(r[f\"lane{lane}_fs_flag\"]) for lane in range(1, 7)]\n",
    "        weights   = [r[f\"lane{lane}_weight\"] for lane in range(1, 7)]\n",
    "        raw_ranks = [int(r[f\"lane{lane}_rank\"]) for lane in range(1, 7)]\n",
    "        lane_ids  = list(range(6))\n",
    "\n",
    "        boats = []\n",
    "        for i in range(6):\n",
    "            if self.mode == \"diff\":\n",
    "                mean_exh = np.mean(exh_times)\n",
    "                mean_st  = np.mean(st_times)\n",
    "                mean_wt  = np.mean(weights)\n",
    "                feat = [\n",
    "                    exh_times[i] - mean_exh,\n",
    "                    st_times[i]  - mean_st,\n",
    "                    fs_flags[i],\n",
    "                    weights[i]   - mean_wt,\n",
    "                ]\n",
    "            elif self.mode == \"raw\":\n",
    "                feat = [\n",
    "                    exh_times[i],\n",
    "                    st_times[i],\n",
    "                    fs_flags[i],\n",
    "                    weights[i],\n",
    "                ]\n",
    "            elif self.mode == \"log\":\n",
    "                feat = [\n",
    "                    np.log1p(exh_times[i]),\n",
    "                    np.log1p(st_times[i]),\n",
    "                    fs_flags[i],\n",
    "                    np.log1p(weights[i]),\n",
    "                ]\n",
    "            elif self.mode == \"zscore\":\n",
    "                inp = np.array([[exh_times[i], st_times[i], weights[i]]])\n",
    "                scaled = self.boat_scaler.transform(inp)[0]\n",
    "                feat = [\n",
    "                    scaled[0],\n",
    "                    scaled[1],\n",
    "                    fs_flags[i],\n",
    "                    scaled[2],\n",
    "                ]\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown mode: {self.mode}\")\n",
    "\n",
    "            boats.append(torch.tensor(feat, dtype=torch.float32))\n",
    "\n",
    "        # ---------- ★ 重複しない順位を付け直す ★ ----------------------\n",
    "        # 例: [1, 2, 6, 3, 6, 6] → [1, 2, 4, 3, 5, 6]\n",
    "        order = np.argsort(raw_ranks)          # 小さい順に艇 index を並べる\n",
    "        new_rank = [0]*6\n",
    "        for new_pos, lane_idx in enumerate(order, start=1):  # new_pos:1..6\n",
    "            new_rank[lane_idx] = new_pos       # 一意な 1..6 を付け直し\n",
    "\n",
    "        return (\n",
    "            ctx,\n",
    "            torch.stack(boats),\n",
    "            torch.tensor(lane_ids, dtype=torch.int64),\n",
    "            torch.tensor(new_rank, dtype=torch.int64)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b7629f62",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "── sample race ──\n",
      "rank    : [np.int32(1), np.int32(3), np.int32(6), np.int32(2), np.int32(5), np.int32(4)]\n",
      "exh_time: [np.float64(6.93), np.float64(6.94), np.float64(6.95), np.float64(6.93), np.float64(6.95), np.float64(6.89)]\n",
      "st      : [np.float64(0.14), np.float64(0.07), np.float64(0.03), np.float64(0.0), np.float64(0.01), np.float64(0.07)]\n",
      "fs_flag : [np.False_, np.False_, np.False_, np.False_, np.False_, np.False_]\n",
      "weight  : [np.float64(52.9), np.float64(52.3), np.float64(51.0), np.float64(52.0), np.float64(53.2), np.float64(54.5)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0) ── データの“ラベル & 特徴量”を 1 行だけ覗く可視化 Snippet\n",
    "#      ★★ ここは notebook なら「1 セルだけ」実行すれば OK ★★\n",
    "# ------------------------------------------------------------\n",
    "def peek_one(df: pd.DataFrame, seed: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    ランダムに 1 レース（1 行）だけ抜き取り、順位と主要特徴量を一覧表示\n",
    "    \"\"\"\n",
    "    row = df.sample(1, random_state=seed).squeeze()\n",
    "\n",
    "    def lane_list(prefix: str):\n",
    "        return [row[f\"lane{i}_{prefix}\"] for i in range(1, 7)]\n",
    "\n",
    "    print(\"── sample race ──\")\n",
    "    print(\"rank    :\", lane_list(\"rank\"))\n",
    "    print(\"exh_time:\", lane_list(\"exh_time\"))\n",
    "    print(\"st      :\", lane_list(\"st\"))\n",
    "    print(\"fs_flag :\", lane_list(\"fs_flag\"))\n",
    "    print(\"weight  :\", lane_list(\"weight\"))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# ここで一度だけ呼んで目視確認しておくとズレにすぐ気付けます\n",
    "peek_one(df)\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "LANE_DIM = 8\n",
    "class SimpleCPLNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ctx(6) + boat(4) → lane ごとにスコア 1 個\n",
    "    \"\"\"\n",
    "    def __init__(self, ctx_in=6, boat_in=4, hidden=64, lane_dim=LANE_DIM):\n",
    "        super().__init__()\n",
    "        self.lane_emb = nn.Embedding(6, lane_dim)\n",
    "        self.ctx_fc   = nn.Linear(ctx_in, hidden)\n",
    "        self.boat_fc  = nn.Linear(boat_in + lane_dim, hidden)\n",
    "        self.head     = nn.Linear(hidden, 1)\n",
    "\n",
    "        # 重み初期化を対称性ブレイク用に Xavier で揃える\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, ctx, boats, lane_ids):  # boats:(B,6,4) lane_ids:(B,6)\n",
    "        B, L, _ = boats.size()\n",
    "        ctx_emb  = self.ctx_fc(ctx)           # (B,h)\n",
    "        # DataLoader から来る lane_ids が (B,) なら (B,6) へブロードキャスト\n",
    "        # -------- lane_ids の形状を必ず (B,6) にそろえる --------\n",
    "        if lane_ids.dim() == 1:               # (B,) → (B,6)\n",
    "            lane_ids = lane_ids.unsqueeze(1).expand(-1, L)\n",
    "        elif lane_ids.dim() == 2 and lane_ids.size(1) == 1:  # (B,1) → (B,6)\n",
    "            lane_ids = lane_ids.expand(-1, L)\n",
    "        # 以外 (既に (B,6)) はそのままで OK\n",
    "        lane_ids = lane_ids.contiguous()      # Embedding 要求に備え contiguous 化\n",
    "\n",
    "        lane_emb = self.lane_emb(lane_ids)    # (B,6,lane_dim)\n",
    "        boat_inp = torch.cat([boats, lane_emb], dim=-1)\n",
    "        boat_emb = self.boat_fc(boat_inp)     # (B,6,h)\n",
    "\n",
    "        # broadcast ctx → 各 lane\n",
    "        score = self.head(torch.tanh(ctx_emb.unsqueeze(1) + boat_emb))  # (B,6,1)\n",
    "        return score.squeeze(-1)           # (B,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7196ce86",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl_nll should be ~0 : 2.0691652297973633\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def pl_nll(scores: torch.Tensor, ranks: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    scores : (B, 6) ― lane0 – lane5 のスコア\n",
    "    ranks  : (B, 6) ― **1 が 1 着, … 6 が 6 着**（列番号ではない）\n",
    "   \"\"\"\n",
    "    scores = scores.clamp(-20.0, 20.0)\n",
    "\n",
    "    # 着順 (1 → 6) に並んだ lane index を取得\n",
    "    order = torch.argsort(ranks, dim=1)      # shape (B,6)\n",
    "\n",
    "    nll = torch.zeros(scores.size(0), device=scores.device)\n",
    "    s   = scores.clone()\n",
    "    for pos in range(6):\n",
    "        log_denom = torch.logsumexp(s, dim=1)            # log Σₗ exp\n",
    "        idx       = order[:, pos]                        # (B,)\n",
    "        chosen    = s.gather(1, idx.unsqueeze(1)).squeeze(1)\n",
    "        nll      += log_denom - chosen\n",
    "        s         = s.scatter(1, idx.unsqueeze(1), float('-inf'))\n",
    "\n",
    "    return nll.mean()\n",
    "\n",
    "# ── pl_nll が正しいか 3 秒で判定 ──\n",
    "scores = torch.tensor([[6, 5, 4, 3, 2, 1]], dtype=torch.float32)  # lane0 が最強\n",
    "ranks  = torch.tensor([[1, 2, 3, 4, 5, 6]], dtype=torch.int64)    # lane0 が 1 着\n",
    "print(\"pl_nll should be ~0 :\", pl_nll(scores, ranks).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f5ac49a3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1819  val: 257\n",
      "[debug] average |grad| = 2.122e+03\n",
      "epoch  0  train_nll 6.5764  val_nll 6.5129\n",
      "epoch  1  train_nll 6.4658  val_nll 6.3931\n",
      "epoch  2  train_nll 6.3698  val_nll 6.2993\n",
      "epoch  3  train_nll 6.2993  val_nll 6.2297\n",
      "epoch  4  train_nll 6.2510  val_nll 6.1757\n",
      "epoch  5  train_nll 6.2134  val_nll 6.1347\n",
      "epoch  6  train_nll 6.1859  val_nll 6.1001\n",
      "epoch  7  train_nll 6.1651  val_nll 6.0729\n",
      "epoch  8  train_nll 6.1550  val_nll 6.0561\n",
      "epoch  9  train_nll 6.1498  val_nll 6.0465\n",
      "epoch 10  train_nll 6.1466  val_nll 6.0426\n",
      "epoch 11  train_nll 6.1465  val_nll 6.0455\n",
      "epoch 12  train_nll 6.1493  val_nll 6.0519\n",
      "epoch 13  train_nll 6.1440  val_nll 6.0551\n",
      "epoch 14  train_nll 6.1374  val_nll 6.0635\n",
      "epoch 15  train_nll 6.1333  val_nll 6.0700\n",
      "epoch 16  train_nll 6.1297  val_nll 6.0648\n",
      "epoch 17  train_nll 6.1263  val_nll 6.0612\n",
      "epoch 18  train_nll 6.1291  val_nll 6.0505\n",
      "epoch 19  train_nll 6.1255  val_nll 6.0351\n",
      "▼ 環境特徴量の重要度（val_nll 増加量）:\n",
      "wind_sin    : 0.0129\n",
      "wind_speed  : 0.0102\n",
      "water_temp  : 0.0057\n",
      "wind_cos    : 0.0051\n",
      "wave_height : 0.0047\n",
      "air_temp    : -0.0015\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df[\"race_date\"] = pd.to_datetime(df[\"race_date\"]).dt.date\n",
    "cutoff = dt.date(2024, 11, 1)\n",
    "\n",
    "mode = \"zscore\"  # \"raw\", \"log\", \"zscore\" も試せる\n",
    "ds_train = BoatRaceDataset(df[df[\"race_date\"] <  cutoff], mode=mode)\n",
    "ds_val   = BoatRaceDataset(df[df[\"race_date\"] >= cutoff], mode=mode)\n",
    "print(f\"train: {len(ds_train)}  val: {len(ds_val)}\")\n",
    "# print(\"train:\", ds_train[0])  # 1 レースの特徴量を確認\n",
    "\n",
    "loader_train = DataLoader(ds_train, batch_size=256, shuffle=True)\n",
    "loader_val   = DataLoader(ds_val,   batch_size=512)\n",
    "\n",
    "# ------------------- ⑤ 学習ループ（LR↓ + Clip） --------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model  = SimpleCPLNet().to(device)\n",
    "opt    = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    if epoch == 0:                  # 1 エポック目だけ試す例\n",
    "        ctx, boats, lane_ids, ranks = next(iter(loader_train))\n",
    "        ctx, boats = ctx.to(device), boats.to(device)\n",
    "        lane_ids = lane_ids.to(device)\n",
    "\n",
    "        scores = model(ctx, boats, lane_ids)\n",
    "        scores.sum().backward()     # ダミー backward\n",
    "        grad_norm = sum(p.grad.abs().mean().item() for p in model.parameters())\n",
    "        print(f\"[debug] average |grad| = {grad_norm:.3e}\")\n",
    "    # ---- train ----\n",
    "    model.train(); tr_sum = 0\n",
    "    for ctx, boats, lane_ids, ranks in loader_train:\n",
    "        ctx, boats = ctx.to(device), boats.to(device)\n",
    "        lane_ids, ranks = lane_ids.to(device), ranks.to(device)\n",
    "\n",
    "        loss = pl_nll(model(ctx, boats, lane_ids), ranks)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)  # ★勾配爆発対策★\n",
    "        opt.step()\n",
    "\n",
    "        tr_sum += loss.item() * len(ctx)\n",
    "\n",
    "    tr_nll = tr_sum / len(loader_train.dataset)\n",
    "\n",
    "    # ---- validation ----\n",
    "    model.eval(); val_sum = 0\n",
    "    with torch.no_grad():\n",
    "        for ctx, boats, lane_ids, ranks in loader_val:\n",
    "            ctx, boats = ctx.to(device), boats.to(device)\n",
    "            lane_ids, ranks = lane_ids.to(device), ranks.to(device)\n",
    "            val_sum += pl_nll(model(ctx, boats, lane_ids), ranks).item() * len(ctx)\n",
    "\n",
    "    val_nll = val_sum / len(loader_val.dataset)\n",
    "\n",
    "    print(f\"epoch {epoch:2d}  train_nll {tr_nll:.4f}  val_nll {val_nll:.4f}\")\n",
    "\n",
    "    # ---- accuracy & 三連単的中率 ----\n",
    "    def top1_accuracy(scores, ranks):\n",
    "        pred_top1 = scores.argmax(dim=1)\n",
    "        true_top1 = (ranks == 1).nonzero(as_tuple=True)[1]\n",
    "        return (pred_top1 == true_top1).float().mean().item()\n",
    "\n",
    "    def trifecta_hit_rate(scores, ranks):\n",
    "        \"\"\"\n",
    "        予測スコア上位3着までと、実際の着順上位3着の組み合わせ一致を見る（順不同）\n",
    "        \"\"\"\n",
    "        pred_top3 = torch.topk(scores, k=3, dim=1).indices\n",
    "        true_top3 = torch.topk(-ranks, k=3, dim=1).indices  # 小さい順に上位3着\n",
    "        hit = [set(p.tolist()) == set(t.tolist()) for p, t in zip(pred_top3, true_top3)]\n",
    "        return sum(hit) / len(hit)\n",
    "\n",
    "    # accuracy 評価\n",
    "    model.eval(); all_scores, all_ranks = [], []\n",
    "    with torch.no_grad():\n",
    "        for ctx, boats, lane_ids, ranks in loader_val:\n",
    "            ctx, boats = ctx.to(device), boats.to(device)\n",
    "            lane_ids = lane_ids.to(device)\n",
    "            scores = model(ctx, boats, lane_ids).cpu()\n",
    "            all_scores.append(scores)\n",
    "            all_ranks.append(ranks)\n",
    "\n",
    "    all_scores = torch.cat(all_scores, dim=0)\n",
    "    all_ranks = torch.cat(all_ranks, dim=0)\n",
    "\n",
    "    acc_top1 = top1_accuracy(all_scores, all_ranks)\n",
    "    acc_tri3 = trifecta_hit_rate(all_scores, all_ranks)\n",
    "\n",
    "    # print(f\"Top-1 Acc: {acc_top1:.3f}   Trifecta Hit: {acc_tri3:.3f}\")\n",
    "\n",
    "    # ---- 学習ログを CSV へ追記保存 ----\n",
    "    import csv\n",
    "    os.makedirs(\"artifacts\", exist_ok=True)\n",
    "    log_path = f\"artifacts/train_{mode}.csv\"\n",
    "    # 1回目だけヘッダーを書き込む\n",
    "    write_header = epoch == 0 and not os.path.exists(log_path)\n",
    "    with open(log_path, mode=\"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        if write_header:\n",
    "            writer.writerow([\"epoch\", \"train_nll\", \"val_nll\", \"top1_acc\", \"trifecta_hit\"])\n",
    "        writer.writerow([epoch, tr_nll, val_nll, acc_top1, acc_tri3])\n",
    "\n",
    "\n",
    "\n",
    "# ---- Permutation Importance ----\n",
    "def evaluate_model(model, dataset, device):\n",
    "    model.eval()\n",
    "    loader = DataLoader(dataset, batch_size=512)\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for ctx, boats, lane_ids, ranks in loader:\n",
    "            ctx, boats = ctx.to(device), boats.to(device)\n",
    "            lane_ids, ranks = lane_ids.to(device), ranks.to(device)\n",
    "            loss = pl_nll(model(ctx, boats, lane_ids), ranks)\n",
    "            total_loss += loss.item() * len(ctx)\n",
    "    return total_loss / len(dataset)\n",
    "\n",
    "def permute_importance(model, dataset, device=\"cpu\", cols=None):\n",
    "    base_loss = evaluate_model(model, dataset, device)\n",
    "\n",
    "    importances = {}\n",
    "    df = dataset.f.copy()\n",
    "\n",
    "    if cols is None:\n",
    "        cols = [\"wind_speed\", \"wave_height\", \"air_temp\", \"water_temp\", \"wind_dir_deg\"]\n",
    "\n",
    "    for col in cols:\n",
    "        shuffled_df = df.copy()\n",
    "        shuffled_df[col] = np.random.permutation(shuffled_df[col].values)\n",
    "        temp_ds = BoatRaceDataset(shuffled_df, mode=dataset.mode)\n",
    "        loss = evaluate_model(model, temp_ds, device)\n",
    "        importances[col] = loss - base_loss  # 悪化分をスコアとする\n",
    "\n",
    "    return importances\n",
    "\n",
    "importance_scores = permute_importance(model, ds_val, device, cols=NUM_COLS)\n",
    "print(\"▼ 環境特徴量の重要度（val_nll 増加量）:\")\n",
    "for k, v in sorted(importance_scores.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{k:12s}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f75595c0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "► 行間 variance (should be >0):\n",
      "venue_id          0.000000\n",
      "lane1_st          0.002938\n",
      "lane4_st          0.005507\n",
      "lane6_exh_time    0.006196\n",
      "lane6_st          0.006428\n",
      "lane1_exh_time    0.006618\n",
      "lane4_exh_time    0.006890\n",
      "lane5_st          0.008517\n",
      "lane3_exh_time    0.009960\n",
      "lane2_exh_time    0.010849\n",
      "dtype: float64\n",
      "\n",
      "► 6 艇間 variance:\n",
      "[('air_temp', nan), ('wind_speed', nan), ('wave_height', nan), ('water_temp', nan), ('wind_dir_deg', nan), ('lane1_racer_id', nan), ('lane1_weight', nan), ('lane1_exh_time', nan), ('lane1_st', nan), ('lane1_rank', nan)]\n",
      "[tiny] final loss: 0.043365754187107086\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# ④ ── 「勾配が流れているか」を瞬時に確認する Snippet\n",
    "#       （エポック終了後 1 回だけ走らせれば十分）\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# ============================================================\n",
    " \n",
    " # ============================================================\n",
    " # ⑤ ── 超小規模データで「過学習できるか」テスト関数\n",
    " #       必要時に呼び出して 0.1 以下まで loss が落ちるか確認\n",
    " # ------------------------------------------------------------\n",
    "def overfit_tiny(df: pd.DataFrame, device: str = \"cpu\"):\n",
    "    \"\"\"\n",
    "    データセットを 10 行だけに縮小し、500 step で過学習できるか検証\n",
    "    \"\"\"\n",
    "    tiny_df = df.sample(10, random_state=1).reset_index(drop=True)\n",
    "    tiny_ds = BoatRaceDataset(tiny_df, mode=mode)\n",
    "    tiny_loader = DataLoader(tiny_ds, batch_size=10, shuffle=True)\n",
    "\n",
    "    net = SimpleCPLNet().to(device)\n",
    "    opt = torch.optim.AdamW(net.parameters(), lr=3e-3)\n",
    "\n",
    "    for _ in range(500):\n",
    "        ctx, boats, lane_ids, ranks = next(iter(tiny_loader))\n",
    "        ctx, boats = ctx.to(device), boats.to(device)\n",
    "        lane_ids, ranks = lane_ids.to(device), ranks.to(device)\n",
    "\n",
    "        loss = pl_nll(net(ctx, boats, lane_ids), ranks)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "    print(\"[tiny] final loss:\", loss.item())\n",
    "\n",
    "\n",
    "# ---- tiny データで特徴量の分散を確認 -----------------------\n",
    "tiny_df = df.sample(10, random_state=1).reset_index(drop=True)\n",
    "num_cols = tiny_df.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# (1) 行間（=レース間）での分散\n",
    "print(\"► 行間 variance (should be >0):\")\n",
    "print(tiny_df[num_cols].var().nsmallest(10))\n",
    "\n",
    "# (2) 同一レース内（= 6 艇間）での分散\n",
    "def per_race_var(col):\n",
    "    return tiny_df.groupby(\"race_key\")[col].var().mean()\n",
    "\n",
    "per_race = {c: per_race_var(c) for c in num_cols}\n",
    "print(\"\\n► 6 艇間 variance:\")\n",
    "print(sorted(per_race.items(), key=lambda x: x[1])[:10])\n",
    "\n",
    "# ---- 呼び方例 ----\n",
    "overfit_tiny(df, device)\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b95757fd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.save({\n",
    "    \"state_dict\": model.state_dict(),\n",
    "    \"scaler\": scaler_filename,\n",
    "    \"venue2id\": venue2id,\n",
    "    # \"race_type2id\": race_type2id\n",
    "}, \"cplnet_checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e00b7834",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# .ipynbを.pyに変換しておく\n",
    "if __name__ == \"__main__\":\n",
    "    import nbformat\n",
    "    from nbconvert import PythonExporter\n",
    "\n",
    "    with open(\"main.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "    exporter = PythonExporter()\n",
    "    source, _ = exporter.from_notebook_node(nb)\n",
    "\n",
    "    with open(\"main.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(source)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
