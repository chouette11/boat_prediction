{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ba6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c49e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ee76fa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import datetime as dt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from BoatRaceDataset_base import BoatRaceDatasetBase\n",
    "from DualHeadRanker import DualHeadRanker\n",
    "import itertools\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, Sequence, Dict\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FeatureDef:\n",
    "    name: str\n",
    "    fn: Callable[[pd.DataFrame], pd.Series]\n",
    "    deps: Sequence[str] = field(default_factory=tuple)\n",
    "    dtype: str = None\n",
    "\n",
    "FEATURE_REGISTRY: Dict[str, FeatureDef] = {}\n",
    "\n",
    "def register_feature(fd: FeatureDef):\n",
    "    FEATURE_REGISTRY[fd.name] = fd\n",
    "\n",
    "def apply_features(\n",
    "    df: pd.DataFrame,\n",
    "    include: Sequence[str] = None,\n",
    "    exclude: Sequence[str] = None,\n",
    "    inplace: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "\n",
    "    names = include if include is not None else list(FEATURE_REGISTRY)\n",
    "    if exclude:\n",
    "        names = [n for n in names if n not in exclude]\n",
    "\n",
    "    for n in names:\n",
    "        fd = FEATURE_REGISTRY[n]\n",
    "        df[n] = fd.fn(df)\n",
    "        if fd.dtype:\n",
    "            df[n] = df[n].astype(fd.dtype)\n",
    "    return df\n",
    "\n",
    "def _wind_sin(df: pd.DataFrame) -> pd.Series:\n",
    "    return np.sin(np.deg2rad(df[\"wind_dir_deg\"]))\n",
    "\n",
    "def _wind_cos(df: pd.DataFrame) -> pd.Series:\n",
    "    return np.cos(np.deg2rad(df[\"wind_dir_deg\"]))\n",
    "\n",
    "\n",
    "register_feature(FeatureDef(\"wind_sin\", _wind_sin, deps=[\"wind_dir_deg\"]))\n",
    "register_feature(FeatureDef(\"wind_cos\", _wind_cos, deps=[\"wind_dir_deg\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1313a26",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import nbformat\n",
    "from nbconvert import PythonExporter\n",
    "\n",
    "if len(sys.argv[1]) < 4:\n",
    "    pass\n",
    "else :\n",
    "    with open(\"main_base_real.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "    exporter = PythonExporter()\n",
    "    source, _ = exporter.from_notebook_node(nb)\n",
    "\n",
    "    with open(\"main_base_real.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec28db3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Venue: 桐 生\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_88123/3478971834.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result_df = pd.read_sql(f\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6835 rows from the database.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "load_dotenv(override=True)\n",
    "venue = '桐 生'\n",
    "if len(sys.argv[1]) < 4:\n",
    "    venue = sys.argv[1]\n",
    "print(f\"Venue: {venue}\")\n",
    "os.makedirs(f\"artifacts/{venue}_real\", exist_ok=True)\n",
    "\n",
    "DB_CONF = {\n",
    "    \"host\":     os.getenv(\"PGHOST\", \"localhost\"),\n",
    "    \"port\":     int(os.getenv(\"PGPORT\", 5432)),\n",
    "    \"dbname\":   os.getenv(\"PGDATABASE\", \"boatrace\"),\n",
    "    \"user\":     os.getenv(\"PGUSER\", \"br_user\"),\n",
    "    \"password\": os.getenv(\"PGPASSWORD\", \"secret\"),\n",
    "}\n",
    "\n",
    "# Use short‑lived connection to avoid leaks\n",
    "with psycopg2.connect(**DB_CONF) as conn:\n",
    "    result_df = pd.read_sql(f\"\"\"\n",
    "        SELECT * FROM feat.train_features_base\n",
    "        WHERE race_date <= '2024-12-31'\n",
    "        AND venue = '{venue}'\n",
    "    \"\"\", conn)\n",
    "\n",
    "print(f\"Loaded {len(result_df)} rows from the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b07d172",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           race_key   race_date venue   win_pattern air_temp  wind_speed  \\\n",
      "0  2022-01-02-01-01  2022-01-02   桐 生          NIGE     None         0.0   \n",
      "1  2022-01-02-02-01  2022-01-02   桐 生          NIGE     None         2.0   \n",
      "2  2022-01-02-03-01  2022-01-02   桐 生        MAKURI     None         2.0   \n",
      "3  2022-01-02-04-01  2022-01-02   桐 生  MAKURI_SASHI     None         1.0   \n",
      "4  2022-01-02-05-01  2022-01-02   桐 生         SASHI     None         0.0   \n",
      "\n",
      "   wave_height water_temp weather_txt  wind_dir_deg  ...  lane5_first_rate  \\\n",
      "0         0.00       None           晴           NaN  ...          0.000000   \n",
      "1         0.01       None           晴         135.0  ...          0.043478   \n",
      "2         0.01       None           晴         135.0  ...          0.058824   \n",
      "3         0.01       None           晴         180.0  ...          0.081633   \n",
      "4         0.00       None           晴           NaN  ...          0.032258   \n",
      "\n",
      "   lane5_two_rate  lane5_three_rate  lane6_starts  lane6_firsts  \\\n",
      "0        0.263158          0.526316          27.0           0.0   \n",
      "1        0.043478          0.391304          29.0           1.0   \n",
      "2        0.088235          0.176471          33.0           0.0   \n",
      "3        0.408163          0.469388          28.0           1.0   \n",
      "4        0.258065          0.483871           4.0           0.0   \n",
      "\n",
      "   lane6_first_rate  lane6_two_rate  lane6_three_rate      wind_sin  wind_cos  \n",
      "0          0.000000        0.111111          0.259259           NaN       NaN  \n",
      "1          0.034483        0.103448          0.379310  7.071068e-01 -0.707107  \n",
      "2          0.000000        0.090909          0.272727  7.071068e-01 -0.707107  \n",
      "3          0.035714        0.071429          0.142857  1.224647e-16 -1.000000  \n",
      "4          0.000000        0.000000          0.250000           NaN       NaN  \n",
      "\n",
      "[5 rows x 78 columns]\n",
      "データフレーム全体の欠損値の総数: 17642\n",
      "各列の欠損値の割合（%）:\n",
      "air_temp         100.000000\n",
      "water_temp       100.000000\n",
      "wind_cos          14.835406\n",
      "wind_dir_deg      14.835406\n",
      "wind_sin          14.835406\n",
      "                    ...    \n",
      "lane6_fs_flag      0.000000\n",
      "race_date          0.000000\n",
      "lane5_fs_flag      0.000000\n",
      "lane3_fs_flag      0.000000\n",
      "race_key           0.000000\n",
      "Length: 78, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_88123/4214365962.py:17: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  result_df[bool_cols] = result_df[bool_cols].fillna(False).astype(bool)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result_df = apply_features(result_df)\n",
    "exclude = []\n",
    "for lane in range(1, 7):\n",
    "      exclude.append(\n",
    "            f\"lane{lane}_bf_course\",\n",
    "      )\n",
    "      exclude.append(f\"lane{lane}_bf_st_time\")\n",
    "      exclude.append(f\"lane{lane}_weight\")\n",
    "\n",
    "result_df.drop(columns=exclude, inplace=True, errors=\"ignore\")\n",
    "\n",
    "BASE_NUM_COLS = [\"air_temp\", \"wind_speed\", \"wave_height\",\n",
    "                 \"water_temp\", \"wind_sin\", \"wind_cos\"]\n",
    "NUM_COLS = BASE_NUM_COLS\n",
    "\n",
    "bool_cols = [c for c in result_df.columns if c.endswith(\"_fs_flag\")]\n",
    "result_df[bool_cols] = result_df[bool_cols].fillna(False).astype(bool)\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "result_df.to_csv(f\"artifacts/{venue}_real/train_features_{venue}.csv\", index=False)\n",
    "print(result_df.head())\n",
    "print(\"データフレーム全体の欠損値の総数:\", result_df.isnull().sum().sum())\n",
    "\n",
    "missing_ratio = result_df.isnull().mean()\n",
    "missing_ratio_percent = missing_ratio * 100\n",
    "\n",
    "print(\"各列の欠損値の割合（%）:\")\n",
    "print(missing_ratio_percent.sort_values(ascending=False))\n",
    "\n",
    "os.makedirs(\"artifacts\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebfdb377",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPK_WEIGHTS: [1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---------------- Loss / Regularization Weights -----------------\n",
    "LAMBDA_ST = 0.1      # weight for ST‑MSE  (was 0.3)\n",
    "L1_ALPHA  = 0.02     # weight for rank‑L1 loss\n",
    "CLIP_NORM = 10.0     # gradient‑clipping threshold (was 5.0)\n",
    "RANKNET_ALPHA = 0.10   # weight for pairwise RankNet loss\n",
    "TEMPERATURE   = 0.80   # logits are divided by T at inference\n",
    "if venue in ['丸 亀']:\n",
    "    LAMBDA_WIN = 0.8        # weight for winner‑BCE loss\n",
    "else:\n",
    "    LAMBDA_WIN = 1.0        # weight for winner‑BCE loss\n",
    "\n",
    "TOPK_K = 3\n",
    "if venue in ['若 松', '芦 屋', '蒲 郡']:\n",
    "    TOPK_WEIGHTS = [3.0, 2.0, 1.0]\n",
    "elif venue in ['丸 亀']:\n",
    "    TOPK_WEIGHTS = [2.0, 2.0, 1.0]\n",
    "elif venue in ['大 村']:\n",
    "    TOPK_WEIGHTS = [1.0, 1.0, 1.0]\n",
    "else:\n",
    "    TOPK_WEIGHTS = [1.0, 1.0, 1.0]\n",
    "\n",
    "print(f\"TOPK_WEIGHTS: {TOPK_WEIGHTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e40ca634",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl_nll should be ~0 : 2.0691652297973633\n",
      "pl_nll_topk (k=3) should be ~0 : 0.44943252205848694\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def pl_nll(scores: torch.Tensor, ranks: torch.Tensor, reduce: bool = True) -> torch.Tensor:\n",
    "    scores = scores.clamp(-20.0, 20.0)\n",
    "\n",
    "    order = torch.argsort(ranks, dim=1)\n",
    "    nll = torch.zeros(scores.size(0), device=scores.device)\n",
    "    s = scores.clone()\n",
    "\n",
    "    for pos in range(6):\n",
    "        log_denom = torch.logsumexp(s, dim=1)\n",
    "        idx = order[:, pos]\n",
    "        chosen = s.gather(1, idx.unsqueeze(1)).squeeze(1)\n",
    "        nll += log_denom - chosen\n",
    "        s = s.scatter(1, idx.unsqueeze(1), float('-inf'))\n",
    "\n",
    "    return nll.mean() if reduce else nll\n",
    "\n",
    "def pl_nll_topk(scores: torch.Tensor,\n",
    "                ranks: torch.Tensor,\n",
    "                k: int = 3,\n",
    "                weights=None,\n",
    "                reduce: bool = True) -> torch.Tensor:\n",
    "    scores = scores.clamp(-20.0, 20.0)\n",
    "    B, C = scores.shape\n",
    "    k = int(min(max(k, 1), C))\n",
    "\n",
    "    if weights is None:\n",
    "        w = torch.ones(k, device=scores.device, dtype=scores.dtype)\n",
    "    else:\n",
    "        w = torch.as_tensor(weights, device=scores.device, dtype=scores.dtype)\n",
    "        if w.numel() != k:\n",
    "            w = torch.ones(k, device=scores.device, dtype=scores.dtype)\n",
    "\n",
    "    order = torch.argsort(ranks, dim=1)   # (B,6) winner→\n",
    "    s = scores.clone()\n",
    "    nll = torch.zeros(B, device=scores.device, dtype=scores.dtype)\n",
    "\n",
    "    for t in range(k):\n",
    "        log_denom = torch.logsumexp(s, dim=1)             # (B,)\n",
    "        idx = order[:, t]                                  # (B,)\n",
    "        chosen = s.gather(1, idx.unsqueeze(1)).squeeze(1)  # (B,)\n",
    "        nll = nll + w[t] * (log_denom - chosen)\n",
    "        s = s.scatter(1, idx.unsqueeze(1), float('-inf'))  # mask the chosen lane\n",
    "\n",
    "    nll = nll / w.sum()\n",
    "    return nll.mean() if reduce else nll\n",
    "\n",
    "# --- Pairwise RankNet loss ---\n",
    "def ranknet_loss(scores: torch.Tensor, ranks: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Pairwise RankNet loss (cross‑entropy on all lane pairs).\n",
    "    ranks : (B,6) with 1=best … 6=worst.\n",
    "    \"\"\"\n",
    "    pair_idx = list(itertools.combinations(range(6), 2))\n",
    "    loss_acc = 0.0\n",
    "    for i, j in pair_idx:\n",
    "        S_ij = torch.sign(ranks[:, j] - ranks[:, i])  # +1 if i<j (i better)\n",
    "        diff = scores[:, i] - scores[:, j]\n",
    "        loss_acc += torch.nn.functional.softplus(-S_ij * diff).mean()\n",
    "    return loss_acc / len(pair_idx)\n",
    "\n",
    "# ── pl_nll が正しいか 3 秒で判定 ──\n",
    "scores = torch.tensor([[6, 5, 4, 3, 2, 1]], dtype=torch.float32)  # lane0 が最強\n",
    "ranks  = torch.tensor([[1, 2, 3, 4, 5, 6]], dtype=torch.int64)    # lane0 が 1 着\n",
    "print(\"pl_nll should be ~0 :\", pl_nll(scores, ranks).item())\n",
    "print(\"pl_nll_topk (k=3) should be ~0 :\", pl_nll_topk(scores, ranks, k=TOPK_K, weights=TOPK_WEIGHTS).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82661b64",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[split] cutoff=2024-07-18  val_ratio≈0.150  N_train=5803  N_val=1032  days=166\n",
      "boat_dim = 5\n",
      "has_motor_rates = None has_boat_rates = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keiichiro/.local/share/virtualenvs/boat_racing-zew2npIb/lib/python3.9/site-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/keiichiro/.local/share/virtualenvs/boat_racing-zew2npIb/lib/python3.9/site-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/keiichiro/.local/share/virtualenvs/boat_racing-zew2npIb/lib/python3.9/site-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def choose_val_cutoff(\n",
    "    date_series: pd.Series,\n",
    "    target_ratio: float = 0.15,   # aim for ~15% as default\n",
    "    min_ratio: float = 0.10,      # don't go below 10%\n",
    "    max_ratio: float = 0.25,      # don't exceed 25%\n",
    "    min_days: int = 120,          # ensure seasonal coverage\n",
    "    min_val_races: int = 1000,    # ensure enough samples\n",
    "):\n",
    "    rd = pd.to_datetime(date_series).dt.date\n",
    "    latest = rd.max()\n",
    "    earliest = rd.min()\n",
    "    total_days = (latest - earliest).days + 1\n",
    "    N = len(rd)\n",
    "\n",
    "    ratio_need_days  = min(max(min_days / max(total_days, 1), target_ratio), max_ratio)\n",
    "    ratio_need_cases = min(max(min_val_races / max(N, 1),    target_ratio), max_ratio)\n",
    "    r = max(min_ratio, min(max_ratio, max(ratio_need_days, ratio_need_cases, target_ratio)))\n",
    "\n",
    "    cutoff_ts = pd.Series(pd.to_datetime(rd)).quantile(1 - r)\n",
    "    cutoff = cutoff_ts.date()\n",
    "\n",
    "    if (latest - cutoff).days < min_days:\n",
    "        cutoff = latest - dt.timedelta(days=min_days)\n",
    "\n",
    "    return cutoff, r\n",
    "\n",
    "\n",
    "result_df[\"race_date\"] = pd.to_datetime(result_df[\"race_date\"]).dt.date\n",
    "latest_date = result_df[\"race_date\"].max()\n",
    "\n",
    "cutoff, val_ratio = choose_val_cutoff(\n",
    "    result_df[\"race_date\"],\n",
    "    target_ratio=0.15,\n",
    "    min_ratio=0.10,\n",
    "    max_ratio=0.25,\n",
    "    min_days=120,\n",
    "    min_val_races=1000,\n",
    ")\n",
    "\n",
    "df_tr = result_df[result_df[\"race_date\"] <  cutoff].copy()\n",
    "df_va = result_df[result_df[\"race_date\"] >= cutoff].copy()\n",
    "\n",
    "scaler = StandardScaler().fit(df_tr[NUM_COLS])\n",
    "df_tr[NUM_COLS] = scaler.transform(df_tr[NUM_COLS])\n",
    "df_va[NUM_COLS] = scaler.transform(df_va[NUM_COLS])\n",
    "# scalerを保存\n",
    "\n",
    "jcd_dict = {\n",
    "    '桐 生': '01', '戸 田': '02', '江戸川': '03', '平和島': '04', '多摩川': '05',\n",
    "    '浜名湖': '06', '蒲 郡': '07', '常 滑': '08', '津': '09',    '三 国': '10',\n",
    "    'びわこ': '11', '住之江': '12', '尼 崎': '13', '鳴 門': '14', '丸 亀': '15',\n",
    "    '児 島': '16',  '宮 島': '17',  '徳 山': '18',  '下 関': '19',  '若 松': '20',\n",
    "    '芦 屋':  '21',  '福 岡':  '22',  '唐 津':  '23',  '大 村':  '24'\n",
    "}\n",
    "now = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "jcd = jcd_dict[venue]\n",
    "os.makedirs(f\"artifacts/real_scalers/{jcd}\", exist_ok=True)\n",
    "joblib.dump(scaler, f\"artifacts/real_scalers/{jcd}/scaler_{now}.joblib\")\n",
    "\n",
    "mode = \"zscore\"  \n",
    "ds_train = BoatRaceDatasetBase(df_tr)\n",
    "ds_val   = BoatRaceDatasetBase(df_va)\n",
    "\n",
    "loader_train = DataLoader(ds_train, batch_size=256, shuffle=True)\n",
    "loader_val   = DataLoader(ds_val,   batch_size=512)\n",
    "\n",
    "print(f\"[split] cutoff={cutoff}  val_ratio≈{val_ratio:.3f}  N_train={len(ds_train)}  N_val={len(ds_val)}  days={(latest_date - cutoff).days}\")\n",
    "\n",
    "# ------------------- ⑤ 学習ループ（LR↓ + Clip） --------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "boat_dim = ds_train.boat_dim\n",
    "print(\"boat_dim =\", ds_train.boat_dim)\n",
    "print(\"has_motor_rates =\", getattr(ds_train, \"has_motor_rates\", None),\n",
    "      \"has_boat_rates =\", getattr(ds_train, \"has_boat_rates\", None))\n",
    "model = DualHeadRanker(boat_in=boat_dim).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1a3fdfc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_model(model, dataset, device):\n",
    "    model.eval()\n",
    "    loader = DataLoader(dataset, batch_size=512)\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        # 6 要素を受け取り、ST は無視\n",
    "        for ctx, boats, lane_ids, ranks, *_ in loader:\n",
    "            ctx, boats = ctx.to(device), boats.to(device)\n",
    "            lane_ids, ranks = lane_ids.to(device), ranks.to(device)\n",
    "\n",
    "            _, scores, _ = model(ctx, boats, lane_ids)   # ST & win logits are ignored\n",
    "            loss = pl_nll_topk(scores, ranks, k=TOPK_K, weights=TOPK_WEIGHTS)\n",
    "            total_loss += loss.item() * len(ctx)\n",
    "    return total_loss / len(dataset)\n",
    "\n",
    "\n",
    "# def run_experiment(data_frac, df_full, mode=\"zscore\", epochs=5, device=\"cpu\"):\n",
    "#     df_frac = df_full.sample(frac=data_frac, random_state=42)\n",
    "#     df_frac[\"race_date\"] = pd.to_datetime(df_frac[\"race_date\"]).dt.date\n",
    "#     latest_date = df_frac[\"race_date\"].max()\n",
    "#     cutoff = latest_date - dt.timedelta(days=90)  # last 3 months used as validation set\n",
    "#     ds_train = BoatRaceDatasetBase(df_frac[df_frac[\"race_date\"] < cutoff])\n",
    "#     ds_val = BoatRaceDatasetBase(df_frac[df_frac[\"race_date\"] >= cutoff])\n",
    "\n",
    "#     loader_train = DataLoader(ds_train, batch_size=256, shuffle=True)\n",
    "#     loader_val = DataLoader(ds_val, batch_size=512)\n",
    "\n",
    "#     boat_dim = ds_train.boat_dim\n",
    "#     model = DualHeadRanker(boat_in=boat_dim).to(device)\n",
    "#     opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=5e-5)\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         for ctx, boats, lane_ids, ranks, *_ in loader_train:\n",
    "#             ctx, boats = ctx.to(device), boats.to(device)\n",
    "#             lane_ids, ranks = lane_ids.to(device), ranks.to(device)\n",
    "\n",
    "#             _, scores, _ = model(ctx, boats, lane_ids)        # discard ST & win head\n",
    "#             loss = (pl_nll(scores, ranks, reduce=False) *\n",
    "#                     torch.where(ranks[:,0]==1,\n",
    "#                                 torch.tensor(1.0, device=ranks.device),\n",
    "#                                 torch.tensor(1.5, device=ranks.device))).mean()\n",
    "#             opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "#     train_loss = evaluate_model(model, ds_train, device)\n",
    "#     val_loss = evaluate_model(model, ds_val, device)\n",
    "#     return train_loss, val_loss\n",
    "\n",
    "# # 学習曲線の描画\n",
    "# def plot_learning_curve(df, device):\n",
    "#     data_fracs = [0.01, 0.05, 0.1, 0.2, 0.5, 1.0]\n",
    "#     results = []\n",
    "\n",
    "#     for frac in data_fracs:\n",
    "#         tr_loss, val_loss = run_experiment(frac, df, device=device)\n",
    "#         print(f\"Data frac {frac:.2f} → Train: {tr_loss:.4f} / Val: {val_loss:.4f}\")\n",
    "#         results.append((frac, tr_loss, val_loss))\n",
    "\n",
    "#     fracs, tr_losses, val_losses = zip(*results)\n",
    "#     plt.plot(fracs, tr_losses, label=\"Train Loss\")\n",
    "#     plt.plot(fracs, val_losses, label=\"Val Loss\")\n",
    "#     plt.xlabel(\"Training Data Fraction\")\n",
    "#     plt.ylabel(\"Loss\")\n",
    "#     plt.title(\"Learning Curve\")\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "# def overfit_tiny(df: pd.DataFrame, device: str = \"cpu\"):\n",
    "#     \"\"\"\n",
    "#     データセットを 10 行だけに縮小し、500 step で過学習できるか検証\n",
    "#     \"\"\"\n",
    "#     tiny_df = df.sample(10, random_state=1).reset_index(drop=True)\n",
    "#     tiny_ds = BoatRaceDatasetBase(tiny_df)\n",
    "#     tiny_loader = DataLoader(tiny_ds, batch_size=10, shuffle=True)\n",
    "\n",
    "#     net = DualHeadRanker().to(device)\n",
    "#     opt = torch.optim.AdamW(net.parameters(), lr=3e-3)\n",
    "\n",
    "#     for _ in range(500):\n",
    "#         ctx, boats, lane_ids, ranks, st_true, st_mask = next(iter(tiny_loader))\n",
    "#         ctx, boats = ctx.to(device), boats.to(device)\n",
    "#         lane_ids, ranks = lane_ids.to(device), ranks.to(device)\n",
    "#         st_true, st_mask = st_true.to(device), st_mask.to(device)\n",
    "#         st_pred, scores, _ = net(ctx, boats, lane_ids)\n",
    "#         pl_loss = (pl_nll(scores, ranks, reduce=False) *\n",
    "#                    torch.where(ranks[:,0]==1,\n",
    "#                                torch.tensor(1.0, device=ranks.device),\n",
    "#                                torch.tensor(1.5, device=ranks.device))).mean()\n",
    "#         mse_st = ((st_pred - st_true) ** 2 * st_mask.float()).sum() / st_mask.float().sum()\n",
    "#         loss = pl_loss + LAMBDA_ST * mse_st\n",
    "#         opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "#     print(\"[tiny] final loss:\", loss.item())\n",
    "\n",
    "# RUN_DIAG = True\n",
    "\n",
    "# if RUN_DIAG:\n",
    "#     print(\"[diag] Running learning‑curve vs. data fraction …\")\n",
    "#     plot_learning_curve(result_df, device)\n",
    "#     print(\"[diag] Running 10‑row overfit_tiny() …\")\n",
    "#     overfit_tiny(result_df, device)\n",
    "#     print(\"[diag]   ► finished quick diagnostics\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518b5ac4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  train_nll 2.4055  val_nll 1.3425  |grad| 1.63e-01\n",
      "ST MSE: 0.0796  ST MAE: 0.2315\n",
      "epoch  1  train_nll 2.0644  val_nll 1.4974  |grad| 1.96e-01\n",
      "ST MSE: 0.3070  ST MAE: 0.4481\n",
      "epoch  2  train_nll 2.0661  val_nll 1.4610  |grad| 1.17e-01\n",
      "ST MSE: 0.3564  ST MAE: 0.4682\n",
      "epoch  3  train_nll 2.0777  val_nll 1.3858  |grad| 8.49e-02\n",
      "ST MSE: 0.2553  ST MAE: 0.4375\n",
      "epoch  4  train_nll 2.0509  val_nll 1.5086  |grad| 1.36e-01\n",
      "ST MSE: 0.3163  ST MAE: 0.4827\n",
      "epoch  5  train_nll 2.1020  val_nll 1.3985  |grad| 9.55e-02\n",
      "ST MSE: 0.3218  ST MAE: 0.4861\n",
      "epoch  6  train_nll 1.9789  val_nll 1.3776  |grad| 1.56e-01\n",
      "ST MSE: 0.0867  ST MAE: 0.2521\n",
      "epoch  7  train_nll 2.0568  val_nll 1.4025  |grad| 1.07e-01\n",
      "ST MSE: 0.1558  ST MAE: 0.3283\n",
      "epoch  8  train_nll 1.9551  val_nll 1.3116  |grad| 1.03e-01\n",
      "ST MSE: 0.0636  ST MAE: 0.2086\n",
      "epoch  9  train_nll 1.9943  val_nll 1.3755  |grad| 1.82e-01\n",
      "ST MSE: 0.1346  ST MAE: 0.2696\n",
      "epoch 10  train_nll 2.0010  val_nll 1.3500  |grad| 9.14e-02\n",
      "ST MSE: 0.0704  ST MAE: 0.1901\n",
      "epoch 11  train_nll 1.9711  val_nll 1.3451  |grad| 1.30e-01\n",
      "ST MSE: 0.0171  ST MAE: 0.1009\n",
      "epoch 12  train_nll 1.9312  val_nll 1.3372  |grad| 1.01e-01\n",
      "ST MSE: 0.0416  ST MAE: 0.1632\n",
      "epoch 13  train_nll 1.9983  val_nll 1.3727  |grad| 1.16e-01\n",
      "ST MSE: 0.0305  ST MAE: 0.1428\n",
      "epoch 14  train_nll 1.9617  val_nll 1.3066  |grad| 1.23e-01\n",
      "ST MSE: 0.0263  ST MAE: 0.1302\n",
      "epoch 15  train_nll 1.9275  val_nll 1.3529  |grad| 7.60e-02\n",
      "ST MSE: 0.0135  ST MAE: 0.0935\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "# --- TensorBoard setup ---\n",
    "log_dir = os.path.join(\"artifacts\", \"tb\", time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "for epoch in range(EPOCHS):\n",
    "    # ---- train ----\n",
    "    model.train(); tr_sum = 0\n",
    "    grad_sum, grad_steps = 0.0, 0\n",
    "    for ctx, boats, lane_ids, ranks, st_true, st_mask in loader_train:\n",
    "        ctx, boats = ctx.to(device), boats.to(device)\n",
    "        lane_ids, ranks = lane_ids.to(device), ranks.to(device)\n",
    "        st_true, st_mask = st_true.to(device), st_mask.to(device)\n",
    "\n",
    "        st_pred, scores, win_logits = model(ctx, boats, lane_ids)\n",
    "        loss_each = pl_nll_topk(scores, ranks, k=TOPK_K, weights=TOPK_WEIGHTS, reduce=False)  # (B,)\n",
    "        sample_weight = torch.where(ranks[:, 0] == 1,               # lane1 winner?\n",
    "                                    torch.tensor(1.0, device=ranks.device),\n",
    "                                    torch.tensor(1.5, device=ranks.device))\n",
    "        pl_loss = (loss_each * sample_weight).mean()\n",
    "        mse_st = ((st_pred - st_true) ** 2 * st_mask.float()).sum() / st_mask.float().sum()\n",
    "        pred_rank = scores.argsort(dim=1, descending=True).argsort(dim=1) + 1  # 1〜6 着になるよう変換\n",
    "        l1_loss = nn.L1Loss()(pred_rank.float(), ranks.float())\n",
    "        rn_loss = ranknet_loss(scores, ranks)\n",
    "        winner_true = (ranks == 1).float()            # one‑hot (B,6)\n",
    "        bce_win = nn.BCEWithLogitsLoss()(win_logits, winner_true)\n",
    "        loss = pl_loss + LAMBDA_ST * mse_st + L1_ALPHA * l1_loss + \\\n",
    "               RANKNET_ALPHA * rn_loss + LAMBDA_WIN * bce_win\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)  # ★勾配爆発対策★\n",
    "        opt.step()\n",
    "\n",
    "        # ---- gradient magnitude tracking ----\n",
    "        g_tot, g_cnt = 0.0, 0\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                g_tot += p.grad.detach().abs().mean().item()\n",
    "                g_cnt += 1\n",
    "        grad_sum += g_tot / max(g_cnt, 1)\n",
    "        grad_steps += 1\n",
    "\n",
    "        tr_sum += loss.item() * len(ctx)\n",
    "\n",
    "    tr_nll = tr_sum / len(loader_train.dataset)\n",
    "\n",
    "    # ---- validation ----\n",
    "    model.eval(); val_sum = 0\n",
    "    # --- validation: also compute st MSE/MAE\n",
    "    mse_st_accum, mae_st_accum, n_st = 0.0, 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for ctx, boats, lane_ids, ranks, st_true, st_mask in loader_val:\n",
    "            ctx, boats = ctx.to(device), boats.to(device)\n",
    "            lane_ids, ranks = lane_ids.to(device), ranks.to(device)\n",
    "            st_true, st_mask = st_true.to(device), st_mask.to(device)\n",
    "            st_pred, scores, _ = model(ctx, boats, lane_ids)\n",
    "            pl_loss = pl_nll_topk(scores, ranks, k=TOPK_K, weights=TOPK_WEIGHTS)\n",
    "            # ST MSE\n",
    "            mse_st = ((st_pred - st_true) ** 2 * st_mask.float()).sum() / st_mask.float().sum()\n",
    "            # ST MAE\n",
    "            abs_err = (st_pred - st_true).abs() * st_mask.float()\n",
    "            mae_st = abs_err.sum() / st_mask.float().sum()\n",
    "            # accumulate for epoch\n",
    "            mse_st_accum += ( ((st_pred - st_true) ** 2) * st_mask.float() ).sum().item()\n",
    "            mae_st_accum += abs_err.sum().item()\n",
    "            n_st += st_mask.float().sum().item()\n",
    "            pred_rank = scores.argsort(dim=1, descending=True).argsort(dim=1) + 1\n",
    "            l1_loss = nn.L1Loss()(pred_rank.float(), ranks.float())\n",
    "            rn_loss = ranknet_loss(scores, ranks)\n",
    "            total = pl_loss + LAMBDA_ST * mse_st + L1_ALPHA * l1_loss + RANKNET_ALPHA * rn_loss\n",
    "            val_sum += total.item() * len(ctx)\n",
    "\n",
    "    val_nll = val_sum / len(loader_val.dataset)\n",
    "    # epoch-wise st metrics\n",
    "    st_mse_val = mse_st_accum / n_st if n_st > 0 else float('nan')\n",
    "    st_mae_val = mae_st_accum / n_st if n_st > 0 else float('nan')\n",
    "\n",
    "    avg_grad = grad_sum / max(grad_steps, 1)\n",
    "    writer.add_scalar(\"diag/avg_grad\", avg_grad, epoch)\n",
    "    print(f\"epoch {epoch:2d}  train_nll {tr_nll:.4f}  val_nll {val_nll:.4f}  |grad| {avg_grad:.2e}\")\n",
    "    print(f\"ST MSE: {st_mse_val:.4f}  ST MAE: {st_mae_val:.4f}\")\n",
    "\n",
    "# --- Close TensorBoard writer after training ---\n",
    "writer.close()\n",
    "\n",
    "# modelの保存\n",
    "jcd_dict = {\n",
    "    '桐 生': '01', '戸 田': '02', '江戸川': '03', '平和島': '04', '多摩川': '05',\n",
    "    '浜名湖': '06', '蒲 郡': '07', '常 滑': '08', '津': '09',    '三 国': '10',\n",
    "    'びわこ': '11', '住之江': '12', '尼 崎': '13', '鳴 門': '14', '丸 亀': '15',\n",
    "    '児 島': '16',  '宮 島': '17',  '徳 山': '18',  '下 関': '19',  '若 松': '20',\n",
    "    '芦 屋':  '21',  '福 岡':  '22',  '唐 津':  '23',  '大 村':  '24'\n",
    "}\n",
    "now = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "jcd = jcd_dict[venue]\n",
    "os.makedirs(f\"artifacts/real_models/{jcd}\", exist_ok=True)\n",
    "model_path = f\"artifacts/real_models/{jcd}/model_{now}.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5280c822",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/1643540370.py:29: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_recent = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              race_key   race_date venue win_pattern air_temp  wind_speed  \\\n",
      "0     2025-01-01-04-20  2025-01-01   若 松      MAKURI     None         2.0   \n",
      "1     2025-01-02-01-20  2025-01-02   若 松        NIGE     None         2.0   \n",
      "2     2025-01-02-02-20  2025-01-02   若 松        NIGE     None         2.0   \n",
      "3     2025-01-01-05-20  2025-01-01   若 松        NIGE     None         1.0   \n",
      "4     2025-01-01-06-20  2025-01-01   若 松      MAKURI     None         1.0   \n",
      "...                ...         ...   ...         ...      ...         ...   \n",
      "1697  2025-08-30-02-20  2025-08-30   若 松        NIGE     None         1.0   \n",
      "1698  2025-08-30-05-20  2025-08-30   若 松        NIGE     None         1.0   \n",
      "1699  2025-08-30-07-20  2025-08-30   若 松        NIGE     None         1.0   \n",
      "1700  2025-08-30-08-20  2025-08-30   若 松        NIGE     None         1.0   \n",
      "1701  2025-08-30-11-20  2025-08-30   若 松        NIGE     None         1.0   \n",
      "\n",
      "      wave_height water_temp weather_txt  wind_dir_deg  ...  lane6_first_rate  \\\n",
      "0            0.02       None           晴         315.0  ...          0.000000   \n",
      "1            0.02       None           晴         315.0  ...          0.000000   \n",
      "2            0.02       None           晴         315.0  ...          0.000000   \n",
      "3            0.01       None           晴           0.0  ...          0.000000   \n",
      "4            0.01       None           晴           0.0  ...          0.076923   \n",
      "...           ...        ...         ...           ...  ...               ...   \n",
      "1697         0.01       None           晴           0.0  ...          0.153846   \n",
      "1698         0.01       None          曇り         315.0  ...          0.000000   \n",
      "1699         0.01       None          曇り           0.0  ...          0.000000   \n",
      "1700         0.01       None          曇り           0.0  ...          0.000000   \n",
      "1701         0.01       None          曇り           0.0  ...          0.000000   \n",
      "\n",
      "     lane6_two_rate  lane6_three_rate first_lane second_lane  third_lane  \\\n",
      "0          0.000000          0.000000          5           4           2   \n",
      "1          0.000000          0.062500          1           5           2   \n",
      "2          0.033333          0.233333          1           5           2   \n",
      "3          0.000000          0.000000          1           2           4   \n",
      "4          0.230769          0.461538          6           2           3   \n",
      "...             ...               ...        ...         ...         ...   \n",
      "1697       0.461538          0.615385          1           6           3   \n",
      "1698       0.000000          0.000000          1           3           5   \n",
      "1699       0.000000          0.333333          1           4           6   \n",
      "1700       0.000000          0.666667          1           2           6   \n",
      "1701       0.250000          0.500000          1           2           6   \n",
      "\n",
      "      trifecta_odds trifecta_popularity_rank  trio_odds  trio_popularity_rank  \n",
      "0              15.4                      3.0        3.7                   2.0  \n",
      "1              69.1                     25.0       20.6                   9.0  \n",
      "2              13.8                      3.0        4.0                   1.0  \n",
      "3               2.6                      1.0        1.1                   1.0  \n",
      "4              78.2                     23.0       24.7                   9.0  \n",
      "...             ...                      ...        ...                   ...  \n",
      "1697          191.1                     43.0       24.1                   9.0  \n",
      "1698           12.0                      5.0        8.6                   4.0  \n",
      "1699           24.3                     10.0       14.2                   7.0  \n",
      "1700           31.3                     12.0       11.1                   7.0  \n",
      "1701           21.6                      8.0       11.7                   6.0  \n",
      "\n",
      "[1702 rows x 101 columns]\n",
      "[simulate] Loaded 1702 rows (2025-01-01 – 2025-10-24).\n",
      "columns: race_key, race_date, venue, win_pattern, air_temp, wind_speed, wave_height, water_temp, weather_txt, wind_dir_deg, lane1_racer_id, lane1_exh_time, lane1_st, lane1_course, lane1_fs_flag, lane1_rank, lane2_racer_id, lane2_exh_time, lane2_st, lane2_course, lane2_fs_flag, lane2_rank, lane3_racer_id, lane3_exh_time, lane3_st, lane3_course, lane3_fs_flag, lane3_rank, lane4_racer_id, lane4_exh_time, lane4_st, lane4_course, lane4_fs_flag, lane4_rank, lane5_racer_id, lane5_exh_time, lane5_st, lane5_course, lane5_fs_flag, lane5_rank, lane6_racer_id, lane6_exh_time, lane6_st, lane6_course, lane6_fs_flag, lane6_rank, lane1_starts, lane1_firsts, lane1_first_rate, lane1_two_rate, lane1_three_rate, lane2_starts, lane2_firsts, lane2_first_rate, lane2_two_rate, lane2_three_rate, lane3_starts, lane3_firsts, lane3_first_rate, lane3_two_rate, lane3_three_rate, lane4_starts, lane4_firsts, lane4_first_rate, lane4_two_rate, lane4_three_rate, lane5_starts, lane5_firsts, lane5_first_rate, lane5_two_rate, lane5_three_rate, lane6_starts, lane6_firsts, lane6_first_rate, lane6_two_rate, lane6_three_rate, first_lane, second_lane, third_lane, trifecta_odds, trifecta_popularity_rank, trio_odds, trio_popularity_rank\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---- Monkey‑patch ROIAnalyzer so it uses BoatRaceDataset2 (MTL) ----------\n",
    "from types import MethodType\n",
    "from BoatRaceDataset_base import BoatRaceDatasetBase \n",
    "from torch.utils.data import DataLoader\n",
    "from roi_util import ROIAnalyzer\n",
    "\n",
    "\n",
    "#  # 最新のモデルを取得\n",
    "# model_list = os.listdir(\"artifacts/models\")\n",
    "# model_list = [f for f in model_list if f.endswith(\".pth\")]\n",
    "# if model_list:\n",
    "#     latest_model = sorted(model_list)[-1]  # 最新のモデルを選択\n",
    "#     model_path = os.path.join(\"artifacts\", \"models\", latest_model)\n",
    "#     print(f\"Using latest model: {model_path}\")\n",
    "#     # モデルをロード\n",
    "#     model = DualHeadRanker(boat_in=boat_dim)\n",
    "#     model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "today = dt.date.today()\n",
    "start_date = dt.date(2025, 1, 1)\n",
    "end = dt.date(2025, 8, 16)\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT * FROM feat.eval_features_base\n",
    "    WHERE race_date BETWEEN '{start_date}' AND '{today}'\n",
    "    AND venue = '{venue}'\n",
    "\"\"\"\n",
    "with psycopg2.connect(**DB_CONF) as conn:\n",
    "    df_recent = pd.read_sql(query, conn)\n",
    "print(df_recent)\n",
    "\n",
    "df_recent.drop(columns=exclude, inplace=True, errors=\"ignore\")\n",
    "df_recent.to_csv(f\"artifacts/{venue}_real/eval_features_recent_{venue}.csv\", index=False)\n",
    "print(f\"[simulate] Loaded {len(df_recent)} rows ({start_date} – {today}).\")\n",
    "print(f\"columns: {', '.join(df_recent.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e79e4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[predict] Evaluating confidence & trifecta rank on recent predictions…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keiichiro/workspace/boat_racing/model/roi_util.py:63: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[bool_cols] = df[bool_cols].fillna(False).astype(bool)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class _RankOnly(nn.Module):\n",
    "    \"\"\"Adapter: forward() returns rank_pred tensor only, temperature-scaled.\"\"\"\n",
    "    def __init__(self, base):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "    def forward(self, *args, **kwargs):\n",
    "        _, rank_pred, _ = self.base(*args, **kwargs)\n",
    "        return rank_pred / TEMPERATURE\n",
    "rank_model = _RankOnly(model).to(device)\n",
    "\n",
    "analyzer = ROIAnalyzer(model=rank_model, scaler=scaler,\n",
    "                       num_cols=NUM_COLS, device=device)\n",
    "\n",
    "print(\"[predict] Evaluating confidence & trifecta rank on recent predictions…\")\n",
    "\n",
    "loader_eval, _df_eval_proc, _df_odds = analyzer._create_loader(df_recent)\n",
    "# --- alignment sanity checks (DataLoader order vs. preprocessed DF) ---\n",
    "assert len(_df_eval_proc) == len(loader_eval.dataset), \\\n",
    "       \"[predict] Mismatch between eval frame and dataset length; race_key alignment may break.\"\n",
    "try:\n",
    "    from torch.utils.data import SequentialSampler\n",
    "    if not isinstance(loader_eval.sampler, SequentialSampler):\n",
    "        print(\"[warn] loader_eval sampler is not SequentialSampler; race_key alignment may be invalid.\")\n",
    "except Exception:\n",
    "    # older PyTorch/DataLoader variants may not expose .sampler cleanly\n",
    "    pass\n",
    "model.eval(); rank_model.eval()\n",
    "all_scores, all_ranks, all_keys = [], [], []\n",
    "row_ptr = 0\n",
    "with torch.inference_mode():\n",
    "    for ctx, boats, lane_ids, ranks, _, __ in loader_eval:\n",
    "        ctx, boats, lane_ids = ctx.to(device), boats.to(device), lane_ids.to(device)\n",
    "        scores = rank_model(ctx, boats, lane_ids)\n",
    "        B = scores.size(0)\n",
    "\n",
    "        all_scores.append(scores.cpu())\n",
    "        all_ranks.append(ranks.cpu())\n",
    "        all_keys.extend(_df_eval_proc[\"race_key\"].iloc[row_ptr : row_ptr + B].tolist())\n",
    "        row_ptr += B\n",
    "\n",
    "# --- handle empty eval loader to avoid cat() errors ---\n",
    "if len(all_scores) == 0:\n",
    "    # Produce empty tensors to keep downstream code from crashing\n",
    "    all_scores = torch.empty((0, 6), dtype=torch.float32)\n",
    "    all_ranks  = torch.empty((0, 6), dtype=torch.int64)\n",
    "    all_keys   = []\n",
    "    print(\"[predict] loader_eval produced no batches; continuing with empty outputs.\")\n",
    "else:\n",
    "    all_scores = torch.cat(all_scores, dim=0)   # (N,6)\n",
    "    all_ranks  = torch.cat(all_ranks,  dim=0)   # (N,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b84b5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # --------------------------------------------------------------------------\n",
    "# #  グループ Ablation: 重要列を 5～6 個まとめてドロップして val_nll を比較\n",
    "# # --------------------------------------------------------------------------\n",
    "# def permute_importance(model, dataset, device=\"cpu\", cols=None):\n",
    "#     \"\"\"\n",
    "#     Permutation importance: 各特徴量列をランダムに permute して val_nll の悪化量を調べる\n",
    "#     \"\"\"\n",
    "#     base_loss = evaluate_model(model, dataset, device)\n",
    "\n",
    "#     # ----- 列リストを決める --------------------------------------------------\n",
    "#     # cols=None なら「データフレームに存在する “使えそうな” 全列」を対象にする\n",
    "#     if cols is None:\n",
    "#         # 予測ターゲットやキー列は除外\n",
    "#         skip = {\"race_key\", \"race_date\"}\n",
    "#         # rank 列（教師信号）や欠損だらけの列も除外\n",
    "#         skip |= {c for c in dataset.f.columns if c.endswith(\"_rank\")}\n",
    "#         cols = [c for c in dataset.f.columns if c not in skip]\n",
    "\n",
    "#     importances: dict[str, float] = {}\n",
    "#     df_full = dataset.f\n",
    "\n",
    "#     for col in cols:\n",
    "#         # --- その列だけランダムに permute ---\n",
    "#         shuffled = df_full.copy()\n",
    "#         shuffled[col] = np.random.permutation(shuffled[col].values)\n",
    "#         tmp_ds = BoatRaceDatasetBase(shuffled)\n",
    "#         loss = evaluate_model(model, tmp_ds, device)\n",
    "#         importances[col] = loss - base_loss   # 悪化分 (大 → 重要)\n",
    "#     return importances\n",
    "\n",
    "# def run_ablation_groups(\n",
    "#     df_full: pd.DataFrame,\n",
    "#     group_size: int = 6,\n",
    "#     epochs: int = 5,\n",
    "#     seed: int = 42,\n",
    "#     device: str = \"cpu\",\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     全特徴量をランダムに group_size 個ずつ束ね、\n",
    "#     そのグループを丸ごと削除して再学習 → val_nll を返す。\n",
    "\n",
    "#     戻り値: list[tuple[list[str], float]]\n",
    "#         (ドロップした列リスト, val_nll) を val_nll 昇順で並べたもの\n",
    "#     \"\"\"\n",
    "#     random.seed(seed)\n",
    "\n",
    "#     essential_cols = set(NUM_COLS)          # ctx 用の連続値\n",
    "#     for l in range(1, 7):\n",
    "#         essential_cols.update({\n",
    "#             f\"lane{l}_exh_time\",\n",
    "#             f\"lane{l}_st\",\n",
    "#             f\"lane{l}_weight\",\n",
    "#             f\"lane{l}_bf_course\",\n",
    "#             f\"lane{l}_fs_flag\",\n",
    "#             f\"lane{l}_racer_id\",\n",
    "#             f\"lane{l}_racer_name\",\n",
    "#             f\"lane{l}_racer_age\",\n",
    "#             f\"lane{l}_racer_weight\",\n",
    "#         })\n",
    "#     # --- 対象列を決める（ターゲット & キー列は除外） ---\n",
    "#     skip = {\"race_key\", \"race_date\"}\n",
    "#     skip |= {c for c in df_full.columns if c.endswith(\"_rank\")}\n",
    "#     skip |= essential_cols  \n",
    "#     skip |= {c for c in df_full.columns if c.endswith(\"_rank\")}\n",
    "#     cols = [c for c in df_full.columns if c not in skip]\n",
    "#     random.shuffle(cols)\n",
    "\n",
    "#     groups = [cols[i : i + group_size] for i in range(0, len(cols), group_size)]\n",
    "#     results = []\n",
    "\n",
    "#     latest_date = pd.to_datetime(df_full[\"race_date\"]).dt.date.max()\n",
    "#     cutoff = latest_date - dt.timedelta(days=90)\n",
    "\n",
    "#     for g in groups:\n",
    "#         df_drop = df_full.drop(columns=g)\n",
    "\n",
    "#         ds_tr = BoatRaceDatasetBase(df_drop[df_drop[\"race_date\"] < cutoff])\n",
    "#         ds_va = BoatRaceDatasetBase(df_drop[df_drop[\"race_date\"] >= cutoff])\n",
    "\n",
    "#         ld_tr = DataLoader(ds_tr, batch_size=256, shuffle=True)\n",
    "#         ld_va = DataLoader(ds_va, batch_size=512)\n",
    "\n",
    "#         model = DualHeadRanker(boat_in=ds_tr.boat_dim).to(device)\n",
    "#         opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=5e-5)\n",
    "\n",
    "#         for _ in range(epochs):\n",
    "#             model.train()\n",
    "#             for ctx, boats, lane_ids, ranks, st_true, st_mask in ld_tr:\n",
    "#                 ctx, boats = ctx.to(device), boats.to(device)\n",
    "#                 lane_ids, ranks = lane_ids.to(device), ranks.to(device)\n",
    "                \n",
    "#                 st_true, st_mask = st_true.to(device), st_mask.to(device)\n",
    "#                 st_pred, scores, _ = model(ctx, boats, lane_ids)\n",
    "#                 pl_loss = pl_nll_topk(scores, ranks, k=TOPK_K, weights=TOPK_WEIGHTS)\n",
    "#                 mse_st = ((st_pred - st_true) ** 2 * st_mask.float()).sum() / st_mask.float().sum()\n",
    "#                 loss = pl_loss + LAMBDA_ST * mse_st\n",
    "#                 opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "#         val_loss = evaluate_model(model, ds_va, device)\n",
    "#         results.append((g, val_loss))\n",
    "\n",
    "#     return sorted(results, key=lambda x: x[1])  # 小さい順に重要\n",
    "\n",
    "# print(\"▼ Permutation importance (ALL features)\")\n",
    "# all_imp = permute_importance(model, ds_val, device)\n",
    "# imp_path = f\"artifacts/{venue}/perm_importance_all_{venue}.csv\"\n",
    "# pd.Series(all_imp).sort_values(ascending=False).to_csv(imp_path)\n",
    "# print(f\"[saved] {imp_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f1a088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 1\n",
      "total_submit : 170200.00 JPY\n",
      "total_benefit: 149430.00 JPY\n",
      "roi : 87.80%\n",
      "n = 2\n",
      "total_submit : 340400.00 JPY\n",
      "total_benefit: 267820.00 JPY\n",
      "roi : 78.68%\n",
      "n = 3\n",
      "total_submit : 510600.00 JPY\n",
      "total_benefit: 357640.00 JPY\n",
      "roi : 70.04%\n",
      "n = 4\n",
      "total_submit : 680800.00 JPY\n",
      "total_benefit: 480090.00 JPY\n",
      "roi : 70.52%\n",
      "n = 5\n",
      "total_submit : 851000.00 JPY\n",
      "total_benefit: 589720.00 JPY\n",
      "roi : 69.30%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_scores = pd.DataFrame(all_scores.numpy(), columns=[f\"lane{i}_score\" for i in range(1, 7)])\n",
    "df_ranks  = pd.DataFrame(all_ranks.numpy(),  columns=[f\"lane{i}_rank\"  for i in range(1, 7)])\n",
    "df_score_ranks = pd.concat([df_scores, df_ranks], axis=1)   \n",
    "df_score_ranks[\"race_key\"] = all_keys\n",
    "\n",
    "df_score_ranks = df_score_ranks.drop_duplicates()\n",
    "df_score_ranks = df_score_ranks.merge(_df_odds[[\"race_key\",\"trifecta_odds\", \"trio_odds\"]], on=\"race_key\", how=\"left\")\n",
    "\n",
    "score_cols = [f\"lane{i}_score\" for i in range(1, 7)]\n",
    "rank_cols  = [f\"lane{i}_rank\"  for i in range(1, 7)]\n",
    "\n",
    "df_score_ranks[\"scores\"] = df_score_ranks[score_cols].apply(\n",
    "    lambda r: [float(x) for x in r.values.tolist()], axis=1\n",
    ")\n",
    "df_score_ranks[\"ranks\"] = df_score_ranks[rank_cols].apply(\n",
    "    lambda r: [int(x) for x in r.values.tolist()], axis=1\n",
    ")\n",
    "df_score_ranks = df_score_ranks.drop(columns=score_cols + rank_cols)\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "def pl_true_order_prob(scores, ranks):\n",
    "    \"\"\"\n",
    "    Plackett–Luce で '真の完全着順(1→6位)' の確率を計算。\n",
    "    scores: 長さ6のスコア配列, ranks: 長さ6の真の順位 (1=最上位)\n",
    "    \"\"\"\n",
    "    w = np.exp(np.array(scores, dtype=float))\n",
    "    # 真の順序（1→2→…→6）に並んだインデックス\n",
    "    order = [i for i, _ in sorted(enumerate(ranks), key=lambda t: t[1])]\n",
    "    denom = float(w.sum())\n",
    "    p = 1.0\n",
    "    for idx in order:\n",
    "        if denom <= 0:\n",
    "            return 0.0\n",
    "        p *= float(w[idx] / denom)\n",
    "        denom -= float(w[idx])\n",
    "    return float(p)\n",
    "\n",
    "def true_trio_prob(scores, ranks):\n",
    "    \"\"\"\n",
    "    3連複（着順不問）で '真の3着以内' の確率を計算。\n",
    "    scores: 長さ6のスコア配列, ranks: 長さ6の真の順位 (1=最上位)\n",
    "    \"\"\"\n",
    "    w = np.exp(np.array(scores, dtype=float))\n",
    "    trio_indices = [i for i, r in enumerate(ranks) if r <= 3]  # 真の3着以内のインデックス\n",
    "    total_prob = 0.0\n",
    "\n",
    "    for perm in permutations(trio_indices, 3):\n",
    "        denom = float(w.sum())\n",
    "        p = 1.0\n",
    "        for idx in perm:\n",
    "            if denom <= 0:\n",
    "                p = 0.0\n",
    "                break\n",
    "            p *= float(w[idx] / denom)\n",
    "            denom -= float(w[idx])\n",
    "        total_prob += p\n",
    "\n",
    "    return float(total_prob)\n",
    "\n",
    "# 6! (=720) 通りの全順位\n",
    "ALL_PERMS = list(permutations(range(6), 6))\n",
    "\n",
    "def true_order_rank(scores, ranks):\n",
    "    \"\"\"\n",
    "    全 6! 通りの PL 確率で並べたとき、真の完全順位が何番目か（1始まり）。\n",
    "    \"\"\"\n",
    "    w = np.exp(np.array(scores, dtype=float))\n",
    "    denom0 = float(w.sum())\n",
    "    true_perm = tuple(i for i, _ in sorted(enumerate(ranks), key=lambda t: t[1]))\n",
    "\n",
    "    def prob_of_perm(perm):\n",
    "        denom = denom0\n",
    "        p = 1.0\n",
    "        for idx in perm:\n",
    "            if denom <= 0:\n",
    "                return 0.0\n",
    "            p *= float(w[idx] / denom)\n",
    "            denom -= float(w[idx])\n",
    "        return p\n",
    "\n",
    "    probs = [(perm, prob_of_perm(perm)) for perm in ALL_PERMS]\n",
    "    probs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for k, (perm, _) in enumerate(probs, start=1):\n",
    "        if perm == true_perm:\n",
    "            return k\n",
    "    return len(probs) + 1  # 通常は到達しない\n",
    "\n",
    "def true_trio_rank(scores, ranks):\n",
    "    \"\"\"\n",
    "    全 6! 通りの PL 確率で並べたとき、真の3着以内が何番目か（1始まり）。\n",
    "    \"\"\"\n",
    "    w = np.exp(np.array(scores, dtype=float))\n",
    "    denom0 = float(w.sum())\n",
    "    trio_indices = [i for i, r in enumerate(ranks) if r <= 3]  # 真の3着以内のインデックス\n",
    "\n",
    "    def prob_of_perm(perm):\n",
    "        denom = denom0\n",
    "        p = 1.0\n",
    "        for idx in perm:\n",
    "            if denom <= 0:\n",
    "                return 0.0\n",
    "            p *= float(w[idx] / denom)\n",
    "            denom -= float(w[idx])\n",
    "        return p\n",
    "\n",
    "    trio_perms = list(permutations(trio_indices, 3))\n",
    "    all_perms = list(permutations(range(6), 6))\n",
    "    probs = []\n",
    "\n",
    "    for perm in all_perms:\n",
    "        p = prob_of_perm(perm)\n",
    "        probs.append((perm, p))\n",
    "\n",
    "    probs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for k, (perm, _) in enumerate(probs, start=1):\n",
    "        if any(perm[:3] == trio_perm for trio_perm in trio_perms):\n",
    "            return k\n",
    "    return len(probs) + 1  # 通常は到達しない\n",
    "\n",
    "# 列の追加\n",
    "df_score_ranks[\"true_order_prob\"] = df_score_ranks.apply(\n",
    "    lambda row: pl_true_order_prob(row[\"scores\"], row[\"ranks\"]), axis=1\n",
    ")\n",
    "df_score_ranks[\"true_trio_prob\"] = df_score_ranks.apply(\n",
    "    lambda row: true_trio_prob(row[\"scores\"], row[\"ranks\"]), axis=1\n",
    ")\n",
    "df_score_ranks[\"true_order_rank\"] = df_score_ranks.apply(\n",
    "    lambda row: true_order_rank(row[\"scores\"], row[\"ranks\"]), axis=1\n",
    ")\n",
    "df_score_ranks[\"true_trio_rank\"] = df_score_ranks.apply(\n",
    "    lambda row: true_trio_rank(row[\"scores\"], row[\"ranks\"]), axis=1\n",
    ")\n",
    "\n",
    "def _order_str_from_scores(scores_list):\n",
    "    arr = np.array(scores_list, dtype=float)\n",
    "    order = list(np.argsort(-arr))  # インデックス 0..5（スコア降順）\n",
    "    return \"-\".join(str(i+1) for i in order)  # 1始まりの艇番号に変換\n",
    "\n",
    "def _order_str_from_ranks(ranks_list):\n",
    "    arr = np.array(ranks_list, dtype=int)\n",
    "    order = [i for i, _ in sorted(enumerate(arr), key=lambda t: t[1])]\n",
    "    return \"-\".join(str(i+1) for i in order)  # 1始まり\n",
    "\n",
    "def _is_hit_trifecta(pred_scores, true_ranks):\n",
    "    pred_top3 = torch.topk(torch.tensor(pred_scores), k=3).indices.tolist()\n",
    "    true_top3 = torch.topk(-torch.tensor(true_ranks), k=3).indices.tolist()\n",
    "    return pred_top3 == true_top3\n",
    "\n",
    "def _is_hit_trio(pred_scores, true_ranks):\n",
    "    pred_top3 = set(torch.topk(torch.tensor(pred_scores), k=3).indices.tolist())\n",
    "    true_top3 = set(torch.topk(-torch.tensor(true_ranks), k=3).indices.tolist())\n",
    "    return pred_top3 == true_top3\n",
    "\n",
    "# 列追加（CSVにも出る）\n",
    "df_score_ranks[\"pred_order_str\"] = df_score_ranks[\"scores\"].apply(_order_str_from_scores)\n",
    "df_score_ranks[\"true_order_str\"] = df_score_ranks[\"ranks\"].apply(_order_str_from_ranks)\n",
    "df_score_ranks[\"is_hit_trifecta\"] = df_score_ranks.apply(\n",
    "    lambda row: _is_hit_trifecta(row[\"scores\"], row[\"ranks\"]), axis=1\n",
    ")\n",
    "df_score_ranks[\"is_hit_trio\"] = df_score_ranks.apply(\n",
    "    lambda row: _is_hit_trio(row[\"scores\"], row[\"ranks\"]), axis=1\n",
    ")\n",
    "\n",
    "df_score_ranks.to_csv(f\"artifacts/{venue}_real/merged_scores_ranks_{venue}.csv\", index=False)\n",
    "total_benefit = 0.0\n",
    "total_submit = 0.0\n",
    "\n",
    "for n in range(1, 6):\n",
    "    total_submit = 0.0\n",
    "    total_benefit = 0.0\n",
    "\n",
    "    for _, row in df_score_ranks.iterrows():\n",
    "        total_submit += 100 * n\n",
    "        odds = row.get(\"trifecta_odds\", None)\n",
    "        true_rank = row.get(\"true_order_rank\", None)\n",
    "\n",
    "        if true_rank is not None and true_rank <= n:\n",
    "            if pd.isna(odds):\n",
    "                odds = 0.0\n",
    "            total_benefit += float(odds) * 100\n",
    "\n",
    "    roi = ((total_benefit / total_submit) * 100) if total_submit > 0 else float(\"nan\")\n",
    "    print(f\"n = {n}\")\n",
    "    print(f\"total_submit : {total_submit:.2f} JPY\")\n",
    "    print(f\"total_benefit: {total_benefit:.2f} JPY\")\n",
    "    print(f\"roi : {roi:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b76686",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[predict] N=1702\n",
      "  • Top‑1 Acc              : 0.648   (baseline 0.561)\n",
      "  • Pos1/2/3 Acc           : 0.648/0.350/0.295 (baseline 0.561/0.233/0.210)\n",
      "  • Top‑3 unordered Hit    : 0.335   (baseline 0.170)\n",
      "  • Trifecta Hit           : 0.147   (baseline 0.073)\n",
      "  • Winner MRR             : 0.792\n",
      "  • Spearman ρ             : 0.620\n",
      "  • Score variance (mean/median): 1.8088 / 1.7294\n",
      "  • Avg rank of true trifecta (unordered) : 3.58\n",
      "  • Avg rank of true trifecta (strict)    : 14.63\n",
      "gain: pop_rank − model_rank\n",
      "  • Pop vs Model (ordered true trifecta rank): mean pop 18.69, avg gain 4.05, median gain 1.00, beat-rate 0.542\n",
      "  • TopN cover (ordered): N=1 model 0.147 vs pop 0.099 (Δ0.048); N=3 model 0.333 vs pop 0.248 (Δ0.085)\n",
      "[saved] artifacts/若 松_real/predict_metrics_recent_若 松.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def top1_accuracy(scores: torch.Tensor, ranks: torch.Tensor) -> float:\n",
    "    \"\"\"Top‑1 accuracy: predicted winner vs true winner (ranks: 1 is best).\"\"\"\n",
    "    pred_top1 = scores.argmax(dim=1)        # (B,)\n",
    "    true_top1 = ranks.argmin(dim=1)         # (B,)\n",
    "    return (pred_top1 == true_top1).float().mean().item()\n",
    "\n",
    "def trifecta_hit_rate(scores: torch.Tensor, ranks: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    予測スコア上位3艇の順番が、実際の1〜3着と完全一致する割合。\n",
    "    \"\"\"\n",
    "    pred_top3 = torch.topk(scores, k=3, dim=1).indices\n",
    "    true_top3 = torch.topk(-ranks, k=3, dim=1).indices  # 小さい順に 1→3 着\n",
    "    hit = [p.tolist() == t.tolist() for p, t in zip(pred_top3, true_top3)]\n",
    "    return float(sum(hit) / len(hit)) if len(hit) else float(\"nan\")\n",
    "\n",
    "def constant_123_trifecta_hit(ranks: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    Hit‑rate when always predicting trifecta 1‑2‑3 in order.\n",
    "    \"\"\"\n",
    "    true_top3 = torch.topk(-ranks, k=3, dim=1).indices   # (B,3)\n",
    "    baseline  = torch.tensor([0, 1, 2], dtype=torch.long, device=ranks.device)\n",
    "    return (true_top3 == baseline).all(dim=1).float().mean().item()\n",
    "\n",
    "def baseline123_position_accuracy(ranks: torch.Tensor, pos: int) -> float:\n",
    "    \"\"\"\n",
    "    Baseline per‑position accuracy when assuming boat pos finishes pos‑th.\n",
    "    pos ∈ {1,2,3}\n",
    "    \"\"\"\n",
    "    true_idx = (ranks == pos).float().argmax(dim=1)          # (B,)\n",
    "    baseline_idx = torch.tensor(pos - 1, dtype=torch.long, device=ranks.device)\n",
    "    return (true_idx == baseline_idx).float().mean().item()\n",
    "\n",
    "def baseline123_top3_unordered_hit(ranks: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    Order‑agnostic hit‑rate when always predicting the set {1,2,3}.\n",
    "    \"\"\"\n",
    "    true_top3 = torch.topk(-ranks, k=3, dim=1).indices\n",
    "    hit = [set(t.tolist()) == {0,1,2} for t in true_top3]\n",
    "    return float(sum(hit) / len(hit)) if len(hit) else float(\"nan\")\n",
    "\n",
    "def get_trifecta_rank_unordered(scores: torch.Tensor, true_ranks: torch.Tensor) -> list[int]:\n",
    "    \"\"\"真の三連複（順序なし）集合が、全20集合の中で何番目か（1始まり）\"\"\"\n",
    "    from itertools import combinations\n",
    "    combos = list(combinations(range(6), 3))\n",
    "    res: list[int] = []\n",
    "    for sc, tr in zip(scores, true_ranks):\n",
    "        true_set = {i for i, r in enumerate(tr.tolist()) if r <= 3}\n",
    "        combo_scores = [(c, sc[list(c)].sum().item()) for c in combos]\n",
    "        combo_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        for idx, (c, _) in enumerate(combo_scores, start=1):\n",
    "            if set(c) == true_set:\n",
    "                res.append(idx)\n",
    "                break\n",
    "        else:\n",
    "            res.append(len(combos) + 1)\n",
    "    return res\n",
    "\n",
    "def get_trifecta_rank_ordered(scores: torch.Tensor, true_ranks: torch.Tensor) -> list[int]:\n",
    "    \"\"\"真の三連単（順序あり）が、PL確率で並べた全120順列の中で何番目か（1始まり）。\"\"\"\n",
    "    import itertools\n",
    "    perms = list(itertools.permutations(range(6), 3))\n",
    "    res: list[int] = []\n",
    "    for sc, tr in zip(scores, true_ranks):\n",
    "        # 数値安定化: 行内の最大を引いてから exp\n",
    "        es = torch.exp(sc - sc.max())\n",
    "        ordered_true = sorted(range(6), key=lambda i: tr[i].item())[:3]\n",
    "\n",
    "        denom0 = es.sum().item()\n",
    "        perm_probs = []\n",
    "        for p0, p1, p2 in perms:\n",
    "            d1 = denom0\n",
    "            d2 = d1 - es[p0].item()\n",
    "            d3 = d2 - es[p1].item()\n",
    "            if d2 <= 0 or d3 <= 0:\n",
    "                prob = 0.0\n",
    "            else:\n",
    "                prob = (es[p0] / d1) * (es[p1] / d2) * (es[p2] / d3)\n",
    "            perm_probs.append(((p0, p1, p2), float(prob)))\n",
    "\n",
    "        perm_probs.sort(key=lambda x: x[1], reverse=True)\n",
    "        for idx, (p, _) in enumerate(perm_probs, start=1):\n",
    "            if list(p) == ordered_true:\n",
    "                res.append(idx)\n",
    "                break\n",
    "        else:\n",
    "            res.append(len(perms) + 1)\n",
    "    return res\n",
    "\n",
    "def top3_unordered_hit_rate(scores: torch.Tensor, ranks: torch.Tensor) -> float:\n",
    "    pred_top3 = torch.topk(scores, k=3, dim=1).indices\n",
    "    true_top3 = torch.topk(-ranks, k=3, dim=1).indices\n",
    "    hit = [(set(p.tolist()) == set(t.tolist())) for p, t in zip(pred_top3, true_top3)]\n",
    "    return float(sum(hit) / len(hit)) if len(hit) else float(\"nan\")\n",
    "\n",
    "def mean_reciprocal_rank(scores: torch.Tensor, ranks: torch.Tensor) -> float:\n",
    "    order = scores.argsort(dim=1, descending=True)          # (B,6)\n",
    "    true_winner_idx = ranks.argmin(dim=1)                   # (B,)\n",
    "    # position of true winner in each row (1-based)\n",
    "    pos = (order == true_winner_idx[:, None]).float().argmax(dim=1) + 1\n",
    "    return (1.0 / pos.float()).mean().item()\n",
    "\n",
    "def spearman_corr(scores: torch.Tensor, ranks: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    Average per‑race Spearman rank correlation between predicted and true rank orders.\n",
    "    \"\"\"\n",
    "    pred_rank = scores.argsort(dim=1, descending=True).argsort(dim=1).float() + 1  # 1..6\n",
    "    true_rank = ranks.float()\n",
    "    d = pred_rank - true_rank\n",
    "    rho = 1 - 6 * (d ** 2).sum(dim=1) / (6 * (6**2 - 1))\n",
    "    return rho.mean().item()\n",
    "\n",
    "score_vars = all_scores.var(dim=1)\n",
    "tri_ranks  = get_trifecta_rank_unordered(all_scores, all_ranks)\n",
    "tri_ranks_order = get_trifecta_rank_ordered(all_scores, all_ranks)\n",
    "mean_tri_order  = float(np.mean(tri_ranks_order)) if len(tri_ranks_order) else float(\"nan\")\n",
    "\n",
    "# ---- Popularity vs Model comparison (ordered trifecta) ----\n",
    "# We expect df_recent to carry 'trifecta_popularity_rank' per race_key (ordered).\n",
    "pop_col = None\n",
    "for c in [\"trifecta_popularity_rank\"]:\n",
    "    if c in df_recent.columns:\n",
    "        pop_col = c; break\n",
    "\n",
    "if pop_col is not None:\n",
    "    _model_rank_df = pd.DataFrame({\n",
    "        \"race_key\": np.array(all_keys),\n",
    "        \"model_trifecta_rank_ordered\": tri_ranks_order\n",
    "    })\n",
    "    _pop_df = df_recent[[\"race_key\", pop_col]].drop_duplicates(\"race_key\").rename(columns={pop_col: \"pop_trifecta_rank_ordered\"})\n",
    "    _cmp_df = _model_rank_df.merge(_pop_df, on=\"race_key\", how=\"inner\")\n",
    "    _cmp_df[\"pop_trifecta_rank_ordered\"] = pd.to_numeric(_cmp_df[\"pop_trifecta_rank_ordered\"], errors=\"coerce\")\n",
    "    _cmp_df = _cmp_df.dropna(subset=[\"pop_trifecta_rank_ordered\"])  # keep valid rows only\n",
    "\n",
    "    # Gains: positive if model ranks the true trifecta higher (smaller rank) than popularity\n",
    "    _cmp_df[\"gain\"] = _cmp_df[\"pop_trifecta_rank_ordered\"] - _cmp_df[\"model_trifecta_rank_ordered\"]\n",
    "\n",
    "    pop_tri_rank_mean = float(_cmp_df[\"pop_trifecta_rank_ordered\"].mean()) if len(_cmp_df) else float(\"nan\")\n",
    "    model_vs_pop_avg_gain = float(_cmp_df[\"gain\"].mean()) if len(_cmp_df) else float(\"nan\")\n",
    "    model_vs_pop_median_gain = float(_cmp_df[\"gain\"].median()) if len(_cmp_df) else float(\"nan\")\n",
    "    model_beats_pop_rate = float((_cmp_df[\"gain\"] > 0).mean()) if len(_cmp_df) else float(\"nan\")\n",
    "\n",
    "    def _cov(N: int):\n",
    "        if len(_cmp_df) == 0:\n",
    "            return float(\"nan\"), float(\"nan\"), float(\"nan\")\n",
    "        pop_hit = float((_cmp_df[\"pop_trifecta_rank_ordered\"] <= N).mean())\n",
    "        model_hit = float((_cmp_df[\"model_trifecta_rank_ordered\"] <= N).mean())\n",
    "        return pop_hit, model_hit, model_hit - pop_hit\n",
    "\n",
    "    pop_top1, model_top1_ord, diff_top1 = _cov(1)\n",
    "    pop_top3, model_top3_ord, diff_top3 = _cov(3)\n",
    "else:\n",
    "    pop_tri_rank_mean = model_vs_pop_avg_gain = model_vs_pop_median_gain = model_beats_pop_rate = float(\"nan\")\n",
    "    pop_top1 = model_top1_ord = diff_top1 = pop_top3 = model_top3_ord = diff_top3 = float(\"nan\")\n",
    "    print(\"[pop] Column 'trifecta_popularity_rank' not found; skipping pop vs model comparison.\")\n",
    "\n",
    "acc_top1   = top1_accuracy(all_scores, all_ranks)\n",
    "acc_tri3   = trifecta_hit_rate(all_scores, all_ranks)\n",
    "mean_var   = score_vars.mean().item()\n",
    "median_var = score_vars.median().item()\n",
    "mean_tri   = float(np.mean(tri_ranks)) if len(tri_ranks) else float(\"nan\")\n",
    "\n",
    "# ---- compute new metrics ----\n",
    "hit_top3_unordered = top3_unordered_hit_rate(all_scores, all_ranks)\n",
    "mrr_winner        = mean_reciprocal_rank(all_scores, all_ranks)\n",
    "rho_spearman      = spearman_corr(all_scores, all_ranks)\n",
    "\n",
    "# ---- baseline metrics (constant 1‑2‑3) ----\n",
    "tri123_hit      = constant_123_trifecta_hit(all_ranks)\n",
    "base_pos1       = baseline123_position_accuracy(all_ranks, 1)\n",
    "base_pos2       = baseline123_position_accuracy(all_ranks, 2)\n",
    "base_pos3       = baseline123_position_accuracy(all_ranks, 3)\n",
    "base_top1       = base_pos1                                   # same as pos1\n",
    "base_top3_unord = baseline123_top3_unordered_hit(all_ranks)\n",
    "\n",
    "# --- per-position accuracy (model) ---\n",
    "def position_accuracy(ranks: torch.Tensor, scores: torch.Tensor, pos: int) -> float:\n",
    "    \"\"\"\n",
    "    Accuracy for predicting which boat finishes pos‑th.\n",
    "    \"\"\"\n",
    "    # Model's prediction: which boat is pos-th in predicted ranking\n",
    "    pred_rank = scores.argsort(dim=1, descending=True).argsort(dim=1) + 1\n",
    "    pred_idx = (pred_rank == pos).float().argmax(dim=1)\n",
    "    true_idx = (ranks == pos).float().argmax(dim=1)\n",
    "    return (pred_idx == true_idx).float().mean().item()\n",
    "\n",
    "acc_pos1 = position_accuracy(all_ranks, all_scores, 1)\n",
    "acc_pos2 = position_accuracy(all_ranks, all_scores, 2)\n",
    "acc_pos3 = position_accuracy(all_ranks, all_scores, 3)\n",
    "\n",
    "print(f\"[predict] N={len(all_scores)}\")\n",
    "print(f\"  • Top‑1 Acc              : {acc_top1:.3f}   (baseline {base_top1:.3f})\")\n",
    "print(f\"  • Pos1/2/3 Acc           : {acc_pos1:.3f}/{acc_pos2:.3f}/{acc_pos3:.3f} \"\n",
    "      f\"(baseline {base_pos1:.3f}/{base_pos2:.3f}/{base_pos3:.3f})\")\n",
    "print(f\"  • Top‑3 unordered Hit    : {hit_top3_unordered:.3f}   (baseline {base_top3_unord:.3f})\")\n",
    "print(f\"  • Trifecta Hit           : {acc_tri3:.3f}   (baseline {tri123_hit:.3f})\")\n",
    "print(f\"  • Winner MRR             : {mrr_winner:.3f}\")\n",
    "print(f\"  • Spearman ρ             : {rho_spearman:.3f}\")\n",
    "print(f\"  • Score variance (mean/median): {mean_var:.4f} / {median_var:.4f}\")\n",
    "print(f\"  • Avg rank of true trifecta (unordered) : {mean_tri:.2f}\")\n",
    "print(f\"  • Avg rank of true trifecta (strict)    : {mean_tri_order:.2f}\")\n",
    "print(f'gain: pop_rank − model_rank')\n",
    "print(f\"  • Pop vs Model (ordered true trifecta rank): mean pop {pop_tri_rank_mean:.2f}, avg gain {model_vs_pop_avg_gain:.2f}, median gain {model_vs_pop_median_gain:.2f}, beat-rate {model_beats_pop_rate:.3f}\")\n",
    "print(f\"  • TopN cover (ordered): N=1 model {model_top1_ord:.3f} vs pop {pop_top1:.3f} (Δ{diff_top1:.3f}); N=3 model {model_top3_ord:.3f} vs pop {pop_top3:.3f} (Δ{diff_top3:.3f})\")\n",
    "\n",
    "# ---- CSV に追記保存 ----\n",
    "import csv, os\n",
    "os.makedirs(f\"artifacts/{venue}_real\", exist_ok=True)\n",
    "metrics_path = f\"artifacts/{venue}_real/predict_metrics_recent_{venue}.csv\"\n",
    "write_header = not os.path.exists(metrics_path)\n",
    "with open(metrics_path, \"a\", newline=\"\") as f:\n",
    "    w = csv.writer(f)\n",
    "    if write_header:\n",
    "        w.writerow([\"date\", \"n_races\",\n",
    "                    \"top1_acc\", \"pos1_acc\", \"pos2_acc\", \"pos3_acc\",\n",
    "                    \"top3unordered_hit\", \"trifecta_hit\",\n",
    "                    \"baseline123_hit\", \"baseline123_top1\",\n",
    "                    \"baseline123_pos1\", \"baseline123_pos2\", \"baseline123_pos3\",\n",
    "                    \"baseline123_top3unordered\",\n",
    "                    \"winner_mrr\", \"spearman_rho\",\n",
    "                    \"var_mean\", \"var_median\", \"tri_rank_mean\",\n",
    "                    \"tri_rank_order_mean\",\n",
    "                    \"pop_tri_rank_mean\", \"model_vs_pop_avg_gain\", \"model_vs_pop_median_gain\", \"model_beats_pop_rate\",\n",
    "                    \"pop_top1_hit\", \"model_top1_ord_hit\", \"delta_top1\",\n",
    "                    \"pop_top3_hit\", \"model_top3_ord_hit\", \"delta_top3\"])\n",
    "    w.writerow([str(today), len(all_scores),\n",
    "                acc_top1, acc_pos1, acc_pos2, acc_pos3,\n",
    "                hit_top3_unordered, acc_tri3,\n",
    "                tri123_hit, base_top1,\n",
    "                base_pos1, base_pos2, base_pos3,\n",
    "                base_top3_unord,\n",
    "                mrr_winner, rho_spearman,\n",
    "                mean_var, median_var, mean_tri, mean_tri_order,\n",
    "                pop_tri_rank_mean, model_vs_pop_avg_gain, model_vs_pop_median_gain, model_beats_pop_rate,\n",
    "                pop_top1, model_top1_ord, diff_top1,\n",
    "                pop_top3, model_top3_ord, diff_top3])\n",
    "print(f\"[saved] {metrics_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69379950",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cond] 条件別の当たりやすさ分析を開始…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:170: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cond] 上位の条件例 (top_n=1, ROI順 上位10)\n",
      "      condition                             bin  n_races  hit_rate       roi  \\\n",
      "4       gap_bin                (0.0114, 0.0241]    425.0  0.037647  0.705176   \n",
      "8      wind_bin                      [6.0, 8.0)    138.0  0.036232  0.631159   \n",
      "0   pl_prob_bin                  (0.133, 0.342]    423.0  0.047281  0.546099   \n",
      "9      wind_bin                      [4.0, 6.0)    471.0  0.042463  0.279830   \n",
      "5       gap_bin                 (0.0241, 0.195]    423.0  0.047281  0.018203   \n",
      "10     wind_bin                     [-inf, 2.0)    445.0  0.029213  0.007865   \n",
      "1   pl_prob_bin  (0.026199999999999998, 0.0835]    426.0  0.028169 -0.093662   \n",
      "12     wave_bin                     [-inf, 0.5)   1698.0  0.032391 -0.119965   \n",
      "13        venue                             若 松   1698.0  0.032391 -0.119965   \n",
      "2   pl_prob_bin                 (0.0835, 0.104]    425.0  0.030588 -0.260235   \n",
      "\n",
      "    avg_odds_on_hits  top_n  \n",
      "4          45.293750      1  \n",
      "8          45.020000      1  \n",
      "0          32.700000      1  \n",
      "9          30.140000      1  \n",
      "5          21.535000      1  \n",
      "10         34.500000      1  \n",
      "1          32.175000      1  \n",
      "12         27.169091      1  \n",
      "13         27.169091      1  \n",
      "2          24.184615      1  \n",
      "[cond] 上位の条件例 (top_n=2, ROI順 上位10)\n",
      "      condition               bin  n_races  hit_rate       roi  \\\n",
      "14  pl_prob_bin    (0.133, 0.342]    423.0  0.075650  0.501655   \n",
      "18      gap_bin  (0.0114, 0.0241]    425.0  0.087059  0.463647   \n",
      "22     wind_bin        [4.0, 6.0)    471.0  0.076433 -0.017516   \n",
      "19      gap_bin   (0.0241, 0.195]    423.0  0.080378 -0.066548   \n",
      "23     wind_bin        [6.0, 8.0)    138.0  0.050725 -0.090580   \n",
      "26     wave_bin       [-inf, 0.5)   1698.0  0.062426 -0.211366   \n",
      "27        venue               若 松   1698.0  0.062426 -0.211366   \n",
      "24     wind_bin       [-inf, 2.0)    445.0  0.056180 -0.233933   \n",
      "15  pl_prob_bin   (0.0835, 0.104]    425.0  0.065882 -0.332353   \n",
      "25     wind_bin        [2.0, 4.0)    618.0  0.061489 -0.336650   \n",
      "\n",
      "    avg_odds_on_hits  top_n  \n",
      "14         39.700000      2  \n",
      "18         33.624324      2  \n",
      "22         25.708333      2  \n",
      "19         23.226471      2  \n",
      "23         35.857143      2  \n",
      "26         25.266038      2  \n",
      "27         25.266038      2  \n",
      "24         27.272000      2  \n",
      "15         20.267857      2  \n",
      "25         21.576316      2  \n",
      "[cond] 上位の条件例 (top_n=3, ROI順 上位10)\n",
      "      condition               bin  n_races  hit_rate       roi  \\\n",
      "28  pl_prob_bin    (0.133, 0.342]    423.0  0.104019  0.283373   \n",
      "32      gap_bin  (0.0114, 0.0241]    425.0  0.108235  0.110824   \n",
      "36     wind_bin        [6.0, 8.0)    138.0  0.086957 -0.016667   \n",
      "33      gap_bin   (0.0241, 0.195]    423.0  0.113475 -0.044208   \n",
      "37     wind_bin        [4.0, 6.0)    471.0  0.095541 -0.175584   \n",
      "40     wave_bin       [-inf, 0.5)   1698.0  0.085395 -0.297919   \n",
      "41        venue               若 松   1698.0  0.085395 -0.297919   \n",
      "38     wind_bin        [2.0, 4.0)    618.0  0.090615 -0.368015   \n",
      "39     wind_bin       [-inf, 2.0)    445.0  0.071910 -0.376255   \n",
      "29  pl_prob_bin   (0.0835, 0.104]    425.0  0.089412 -0.414902   \n",
      "\n",
      "    avg_odds_on_hits  top_n  \n",
      "28         37.013636      3  \n",
      "32         30.789130      3  \n",
      "36         33.925000      3  \n",
      "33         25.268750      3  \n",
      "37         25.886667      3  \n",
      "40         24.664828      3  \n",
      "41         24.664828      3  \n",
      "38         20.923214      3  \n",
      "39         26.021875      3  \n",
      "29         19.631579      3  \n",
      "[cond] 上位の条件例 (top_n=4, ROI順 上位10)\n",
      "      condition                             bin  n_races  hit_rate       roi  \\\n",
      "42  pl_prob_bin                  (0.133, 0.342]    423.0  0.125296  0.175768   \n",
      "46      gap_bin                (0.0114, 0.0241]    425.0  0.129412 -0.045294   \n",
      "47      gap_bin                 (0.0241, 0.195]    423.0  0.139480 -0.146986   \n",
      "50     wind_bin                      [4.0, 6.0)    471.0  0.118896 -0.184501   \n",
      "51     wind_bin                      [6.0, 8.0)    138.0  0.094203 -0.246377   \n",
      "54     wave_bin                     [-inf, 0.5)   1698.0  0.110718 -0.293154   \n",
      "55        venue                             若 松   1698.0  0.110718 -0.293154   \n",
      "52     wind_bin                      [2.0, 4.0)    618.0  0.114887 -0.322775   \n",
      "43  pl_prob_bin  (0.026199999999999998, 0.0835]    426.0  0.082160 -0.375646   \n",
      "53     wind_bin                     [-inf, 2.0)    445.0  0.101124 -0.377416   \n",
      "\n",
      "    avg_odds_on_hits  top_n  \n",
      "42         37.535849      4  \n",
      "46         29.509091      4  \n",
      "47         24.462712      4  \n",
      "50         27.435714      4  \n",
      "51         32.000000      4  \n",
      "54         25.536702      4  \n",
      "55         25.536702      4  \n",
      "52         23.578873      4  \n",
      "43         30.397143      4  \n",
      "53         24.626667      4  \n",
      "[cond] 上位の条件例 (top_n=5, ROI順 上位10)\n",
      "      condition               bin  n_races  hit_rate       roi  \\\n",
      "56  pl_prob_bin    (0.133, 0.342]    423.0  0.148936  0.145768   \n",
      "60      gap_bin  (0.0114, 0.0241]    425.0  0.148235 -0.083294   \n",
      "64     wind_bin        [6.0, 8.0)    138.0  0.115942 -0.219855   \n",
      "61      gap_bin   (0.0241, 0.195]    423.0  0.156028 -0.222790   \n",
      "65     wind_bin        [4.0, 6.0)    471.0  0.133758 -0.282038   \n",
      "66     wind_bin       [-inf, 2.0)    445.0  0.128090 -0.293303   \n",
      "68     wave_bin       [-inf, 0.5)   1698.0  0.129564 -0.305395   \n",
      "69        venue               若 松   1698.0  0.129564 -0.305395   \n",
      "67     wind_bin        [2.0, 4.0)    618.0  0.131068 -0.343204   \n",
      "57  pl_prob_bin   (0.0835, 0.104]    425.0  0.131765 -0.425224   \n",
      "\n",
      "    avg_odds_on_hits  top_n  \n",
      "56         38.465079      5  \n",
      "60         30.920635      5  \n",
      "64         33.643750      5  \n",
      "61         24.906061      5  \n",
      "65         26.838095      5  \n",
      "66         27.585965      5  \n",
      "68         26.805455      5  \n",
      "69         26.805455      5  \n",
      "67         25.055556      5  \n",
      "57         21.810714      5  \n",
      "[cond] Best-ROI matches (overall) saved to artifacts/若 松_real/cond_best_roi_matches.csv  —  condition=gap_bin, bin=(0.0114, 0.0241], ROI=0.705, top_n=1\n",
      "[cond] Best-ROI matches (per top_n) saved to artifacts/cond_best_roi_matches_by_topn.csv\n",
      "[cond] ウォークフォワードで期待ROIを評価します…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cond] Walk‑forward records saved to artifacts/cond_expected_roi_walkforward.csv (rows=25)\n",
      "[cond] Expected ROI summary saved to artifacts/若 松_real/cond_expected_roi_summary_若 松.csv\n",
      "[audit] true_order_prob のデシル別に ROI/Hit を監査します…\n",
      "[audit] Saved decile audit → artifacts/若 松_real/audit_true_order_prob_deciles_若 松.csv  (rows=40)\n",
      "[audit] TopN=1  D_low (decile=0) vs D_high (decile=9)\n",
      "        n_races 170/170  hit_rate 0.0000/0.2824  roi -1.0000/7.1618  return_share 0.000/0.929\n",
      "[audit] TopN=2  D_low (decile=0) vs D_high (decile=9)\n",
      "        n_races 170/170  hit_rate 0.0000/0.4882  roi -1.0000/5.7259  return_share 0.000/0.854\n",
      "[audit] TopN=3  D_low (decile=0) vs D_high (decile=9)\n",
      "        n_races 170/170  hit_rate 0.0000/0.6706  roi -1.0000/5.0025  return_share 0.000/0.856\n",
      "[audit] TopN=5  D_low (decile=0) vs D_high (decile=9)\n",
      "        n_races 170/170  hit_rate 0.0000/0.8706  roi -1.0000/3.8779  return_share 0.000/0.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:334: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/3493292142.py:579: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  audit_df = audit_df.groupby(\"top_n\", as_index=False).apply(_add_share).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# === 条件別ヒット率/ROI 分析（修正版） =========================\n",
    "# 目的: 「どんな条件のときに当たりやすいか？」を、ヒット率とROIで可視化\n",
    "# 入力: df_score_ranks（race_key, trifecta_odds, true_order_rank を含む）\n",
    "#       df_recent（環境・会場などの特徴）\n",
    "# 依存: analyzer, model, rank_model, device がスコープに存在する想定\n",
    "# 出力: artifacts/cond_base_table.csv, artifacts/cond_hit_roi.csv\n",
    "# 重要: 意思決定に使う条件からは “事後情報” の疑いがあるもの（例: trifecta_odds_bin）を除外\n",
    "# -------------------------------------------------------------\n",
    "import os\n",
    "import math\n",
    "from itertools import permutations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "print(\"[cond] 条件別の当たりやすさ分析を開始…\")\n",
    "# ------------------------------\n",
    "\n",
    "# 0) ベース表の構築（分析に使う列をまとめる）\n",
    "_base = df_score_ranks.copy()\n",
    "_base = _base[_base[\"race_key\"].notna()].copy()\n",
    "_base[\"true_order_rank\"] = pd.to_numeric(_base[\"true_order_rank\"], errors=\"coerce\")\n",
    "_base[\"trifecta_odds\"] = pd.to_numeric(_base[\"trifecta_odds\"], errors=\"coerce\")\n",
    "\n",
    "# df_recent から環境や会場などの列をマージ（存在する列だけ）\n",
    "_cand_cols = [\n",
    "    \"race_key\", \"race_date\", \"venue\", \"air_temp\", \"water_temp\",\n",
    "    \"wind_speed\", \"wave_height\", \"wind_dir_deg\", \"wind_sin\", \"wind_cos\",\n",
    "]\n",
    "_exist_cols = [c for c in _cand_cols if c in df_recent.columns]\n",
    "if _exist_cols:\n",
    "    _env = df_recent[_exist_cols].drop_duplicates(\"race_key\")\n",
    "    _base = _base.merge(_env, on=\"race_key\", how=\"left\")\n",
    "\n",
    "# _df_eval_proc 側に race_date があれば補完\n",
    "if \"race_date\" not in _base.columns and \"race_date\" in _df_eval_proc.columns:\n",
    "    _base = _base.merge(\n",
    "        _df_eval_proc[[\"race_key\", \"race_date\"]].drop_duplicates(\"race_key\"),\n",
    "        on=\"race_key\", how=\"left\"\n",
    "    )\n",
    "\n",
    "# 日付を date 型へ\n",
    "if \"race_date\" in _base.columns:\n",
    "    _base[\"race_date\"] = pd.to_datetime(_base[\"race_date\"]).dt.date\n",
    "\n",
    "# --- trifecta_odds を 100円あたりの『倍率』に正規化（円建てなら /100） ---\n",
    "# if _base[\"trifecta_odds\"].notna().any():\n",
    "#     try:\n",
    "#         q95 = _base[\"trifecta_odds\"].quantile(0.95)\n",
    "#         if q95 > 300:  # 円建ての可能性が高い\n",
    "#             _base[\"trifecta_odds\"] = _base[\"trifecta_odds\"] / 100.0\n",
    "#     except Exception:\n",
    "#         pass\n",
    "\n",
    "# 1) 予測スコア由来の「自信度」特徴を付与（PLのtop1確率・top2とのギャップ等）\n",
    "try:\n",
    "    _scores_mat = all_scores.detach().cpu().numpy()  # (N,6)\n",
    "    _rk_seq = _df_eval_proc[\"race_key\"].to_numpy()\n",
    "except Exception as e:\n",
    "    print(\"[cond] all_scores が見つからない/使えないため再計算します:\", e)\n",
    "    loader_eval, _df_eval_proc, _ = analyzer._create_loader(df_recent)\n",
    "    model.eval(); rank_model.eval()\n",
    "    _sc_list = []\n",
    "    with torch.no_grad():\n",
    "        for ctx, boats, lane_ids, _ranks, _, __ in loader_eval:\n",
    "            ctx, boats, lane_ids = ctx.to(device), boats.to(device), lane_ids.to(device)\n",
    "            _sc = rank_model(ctx, boats, lane_ids)\n",
    "            _sc_list.append(_sc.cpu())\n",
    "    all_scores = torch.cat(_sc_list, dim=0)\n",
    "    _scores_mat = all_scores.detach().cpu().numpy()\n",
    "    _rk_seq = _df_eval_proc[\"race_key\"].to_numpy()\n",
    "\n",
    "_scores_df = pd.DataFrame(_scores_mat, columns=[f\"s{i}\" for i in range(6)])\n",
    "_scores_df[\"race_key\"] = _rk_seq\n",
    "_perms = list(permutations(range(6), 3))\n",
    "\n",
    "def _pl_feats_from_scores(row):\n",
    "    \"\"\"数値安定化したsoftmax + Plackett–Luce近似で top1/top2 確率とギャップ等を算出\"\"\"\n",
    "    s = np.array([row[f\"s{i}\"] for i in range(6)], dtype=float)\n",
    "    # 数値安定化：log-sum-exp（最大値でシフト）\n",
    "    s_ = s - np.max(s)\n",
    "    es = np.exp(s_)\n",
    "    denom0 = es.sum()\n",
    "\n",
    "    # lane softmax のエントロピー（低いほど確信強）\n",
    "    p = es / max(denom0, 1e-12)\n",
    "    entropy = float(-(p * np.log(p + 1e-12)).sum())\n",
    "    var = float(np.var(s))\n",
    "\n",
    "    # 全120通りのPL確率から top1 / top2 とギャップ\n",
    "    best1p, best2p = -1.0, -1.0\n",
    "    best1 = None\n",
    "    for a, b, c in _perms:  # 120通り\n",
    "        d2 = denom0 - es[a]\n",
    "        d3 = d2 - es[b]\n",
    "        if d2 <= 0 or d3 <= 0:\n",
    "            continue\n",
    "        prob = (es[a]/denom0) * (es[b]/d2) * (es[c]/d3)  # Plackett–Luce\n",
    "        if prob > best1p:\n",
    "            best2p = best1p\n",
    "            best1p = float(prob)\n",
    "            best1 = (a, b, c)\n",
    "        elif prob > best2p:\n",
    "            best2p = float(prob)\n",
    "\n",
    "    gap = best1p - best2p if best2p >= 0 else np.nan\n",
    "    top1_str = f\"{best1[0]+1}-{best1[1]+1}-{best1[2]+1}\" if best1 is not None else np.nan\n",
    "    return pd.Series({\n",
    "        \"pl_top1_prob\": best1p,\n",
    "        \"pl_top2_prob\": best2p,\n",
    "        \"pl_gap\": gap,\n",
    "        \"pl_top1\": top1_str,\n",
    "        \"score_entropy\": entropy,\n",
    "        \"score_var\": var,\n",
    "    })\n",
    "\n",
    "_pl_feats = _scores_df.apply(_pl_feats_from_scores, axis=1)\n",
    "_scores_df = pd.concat([_scores_df[[\"race_key\"]], _pl_feats], axis=1)\n",
    "_base = _base.merge(_scores_df, on=\"race_key\", how=\"left\")\n",
    "\n",
    "# 2) 条件のビニング\n",
    "def _safe_qcut(series, q):\n",
    "    try:\n",
    "        return pd.qcut(series, q=q, duplicates=\"drop\")\n",
    "    except Exception:\n",
    "        return pd.Series([np.nan] * len(series), index=series.index)\n",
    "\n",
    "# ※ 意思決定に使う条件からは “事後情報” の trifecta_odds_bin を除外\n",
    "if \"pl_top1_prob\" in _base.columns:\n",
    "    _base[\"pl_prob_bin\"] = _safe_qcut(_base[\"pl_top1_prob\"], 4)\n",
    "if \"pl_gap\" in _base.columns:\n",
    "    _base[\"gap_bin\"] = _safe_qcut(_base[\"pl_gap\"], 4)\n",
    "if \"wind_speed\" in _base.columns:\n",
    "    _base[\"wind_bin\"] = pd.cut(_base[\"wind_speed\"], bins=[-np.inf, 2, 4, 6, 8, np.inf], right=False)\n",
    "if \"wave_height\" in _base.columns:\n",
    "    _base[\"wave_bin\"] = pd.cut(_base[\"wave_height\"], bins=[-np.inf, 0.5, 1.0, 2.0, np.inf], right=False)\n",
    "if \"wind_sin\" in _base.columns:\n",
    "    _base[\"tailwind\"] = _base[\"wind_sin\"] < 0  # True=追い風（sin<0）\n",
    "\n",
    "# 3) 条件ごとのヒット率/ROI を「レース単位」で集計\n",
    "def _summarize_by(col, top_n, min_races=30):\n",
    "    \"\"\"各レース=1票 として評価。コスト= top_n/レース、払戻= 的中レースの trifecta_odds 合計。\"\"\"\n",
    "    if col not in _base.columns:\n",
    "        return pd.DataFrame()\n",
    "    df = _base.dropna(subset=[col, \"true_order_rank\", \"trifecta_odds\", \"race_key\"]).copy()\n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # グループ毎に race_key でユニーク化（複製があっても1レース1回の評価にする）\n",
    "    def _agg_group(g):\n",
    "        rep = g.drop_duplicates(\"race_key\")\n",
    "        n_races = rep[\"race_key\"].nunique()\n",
    "        # 的中判定（「上位top_nに真の順序が入っていたか」）\n",
    "        hits_mask = rep[\"true_order_rank\"] <= top_n\n",
    "        hit_rate = float(hits_mask.mean())\n",
    "        # 払戻（的中レースだけカウント）\n",
    "        total_return = float(rep.loc[hits_mask, \"trifecta_odds\"].sum())\n",
    "        cost = n_races * top_n\n",
    "        roi = (total_return - cost) / cost if cost > 0 else np.nan\n",
    "        avg_odds_on_hits = float(rep.loc[hits_mask, \"trifecta_odds\"].mean()) if hits_mask.any() else np.nan\n",
    "        return pd.Series({\n",
    "            \"n_races\": n_races,\n",
    "            \"hit_rate\": hit_rate,\n",
    "            \"roi\": roi,\n",
    "            \"avg_odds_on_hits\": avg_odds_on_hits,\n",
    "        })\n",
    "\n",
    "    out = df.groupby(col, dropna=False).apply(_agg_group).reset_index()\n",
    "    out = out.rename(columns={col: \"bin\"})\n",
    "    if out.empty:\n",
    "        return out\n",
    "\n",
    "    # 表示互換のため n も付ける（= n_races）\n",
    "    out[\"n\"] = out[\"n_races\"]\n",
    "    out[\"top_n\"] = top_n\n",
    "    out[\"condition\"] = col\n",
    "    out = out[out[\"n_races\"] >= min_races].sort_values([\"roi\", \"hit_rate\"], ascending=False)\n",
    "    return out\n",
    "\n",
    "# 解析対象列（意思決定用の条件のみ）\n",
    "_cols_to_try = [\"pl_prob_bin\", \"gap_bin\", \"wind_bin\", \"wave_bin\", \"tailwind\"]\n",
    "if \"venue\" in _base.columns:\n",
    "    _cols_to_try.append(\"venue\")\n",
    "\n",
    "_tables = []\n",
    "for _n in [1, 2, 3, 4, 5]:\n",
    "    for _c in _cols_to_try:\n",
    "        if _c in _base.columns:\n",
    "            _t = _summarize_by(_c, _n, min_races=30 if _c != \"venue\" else 50)\n",
    "            if not _t.empty:\n",
    "                _tables.append(_t)\n",
    "\n",
    "_cond_result = pd.concat(_tables, ignore_index=True) if _tables else pd.DataFrame()\n",
    "\n",
    "# 4) 保存\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "_base.to_csv(f\"artifacts/{venue}_real/cond_base_table_{venue}.csv\", index=False)\n",
    "# is_hit_trifecta が True の行だけに絞る\n",
    "_base_hits = _base[_base[\"is_hit_trifecta\"] == True].copy()\n",
    "_base_hits.to_csv(f\"artifacts/{venue}_real/cond_base_table_hits_{venue}.csv\", index=False)\n",
    "_cond_result.to_csv(f\"artifacts/{venue}_real/cond_hit_roi_{venue}.csv\", index=False)\n",
    "\n",
    "# 5) コンソールにハイライト表示\n",
    "for _n in [1, 2, 3, 4, 5]:\n",
    "    if not _cond_result.empty:\n",
    "        with pd.option_context(\"display.max_rows\", 20, \"display.max_colwidth\", 60):\n",
    "            print(f\"[cond] 上位の条件例 (top_n={_n}, ROI順 上位10)\")\n",
    "            cols_to_show = [\"condition\", \"n\", \"hit_rate\", \"roi\", \"avg_odds_on_hits\", \"top_n\"]\n",
    "            # 必要に応じて各条件固有のビン列名を追記\n",
    "            extra_cols = []\n",
    "            # 条件ごとのビン列（表示があれば自動で含める）\n",
    "            for c in [\"pl_prob_bin\", \"gap_bin\", \"wind_bin\", \"wave_bin\", \"tailwind\", \"venue\"]:\n",
    "                if c in _cond_result[\"condition\"].unique():\n",
    "                    extra_cols.append(c)\n",
    "            df_view = _cond_result.query(f\"top_n == {_n}\").sort_values(\"roi\", ascending=False)\n",
    "            # 少なくとも代表的なカラムが出るように調整\n",
    "            print(df_view[[\"condition\", \"bin\", \"n_races\", \"hit_rate\", \"roi\", \"avg_odds_on_hits\", \"top_n\"]].head(10))\n",
    "    else:\n",
    "        print(\"[cond] 条件別集計を作成できませんでした（対象列やデータ不足）。\")\n",
    "# ============================================================\n",
    "\n",
    "# 4.5) ROI が最大の条件に一致するレースを CSV に出力\n",
    "#  - 全体で ROI 最大の条件に一致するレース一覧\n",
    "#  - top_n ごとに ROI 最大の条件に一致するレース一覧\n",
    "if not _cond_result.empty:\n",
    "    # 共通: 条件に一致するレースを抽出してメタ情報を付与\n",
    "    def _filter_matches(row):\n",
    "        col = row[\"condition\"]\n",
    "        binv = row[\"bin\"]\n",
    "        topn = int(row[\"top_n\"])\n",
    "        sel = _base.dropna(subset=[\"race_key\"]).copy()\n",
    "        # bin の型差（Categorical/Interval 等）に備えて比較をフォールバック\n",
    "        try:\n",
    "            mask = sel[col] == binv\n",
    "        except Exception:\n",
    "            mask = sel[col].astype(str) == str(binv)\n",
    "        sel = sel.loc[mask].drop_duplicates(\"race_key\").copy()\n",
    "\n",
    "        # 出力に含める代表列（存在するものだけ採用）\n",
    "        cols_pref = [\n",
    "            \"race_key\", \"trifecta_odds\", \"true_order_rank\",\n",
    "            \"pl_top1_prob\", \"pl_top2_prob\", \"pl_gap\", \"pl_top1\",\n",
    "            \"score_entropy\", \"score_var\",\n",
    "            \"venue\", \"air_temp\", \"water_temp\",\n",
    "            \"wind_speed\", \"wave_height\", \"wind_dir_deg\", \"wind_sin\", \"wind_cos\",\n",
    "        ]\n",
    "        cols_exist = [c for c in cols_pref if c in sel.columns]\n",
    "        if cols_exist:\n",
    "            sel = sel[cols_exist]\n",
    "\n",
    "        # メタ情報\n",
    "        sel[\"condition\"] = col\n",
    "        sel[\"bin\"] = binv\n",
    "        sel[\"top_n\"] = topn\n",
    "        sel[\"roi_bin\"] = float(row[\"roi\"])\n",
    "        sel[\"n_races_bin\"] = int(row[\"n_races\"])\n",
    "        sel[\"hit_rate_bin\"] = float(row[\"hit_rate\"])\n",
    "        sel[\"avg_odds_on_hits_bin\"] = (\n",
    "            float(row[\"avg_odds_on_hits\"]) if pd.notna(row[\"avg_odds_on_hits\"]) else np.nan\n",
    "        )\n",
    "        return sel\n",
    "\n",
    "    os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "    # (A) 全体で ROI 最大の条件\n",
    "    _best_overall = _cond_result.sort_values(\"roi\", ascending=False).head(1)\n",
    "    _best_overall_matches = _filter_matches(_best_overall.iloc[0])\n",
    "    _best_overall_path = f\"artifacts/{venue}_real/cond_best_roi_matches.csv\"\n",
    "    _best_overall_matches.to_csv(_best_overall_path, index=False)\n",
    "    print(f\"[cond] Best-ROI matches (overall) saved to {_best_overall_path}  —  \"\n",
    "          f\"condition={_best_overall.iloc[0]['condition']}, bin={_best_overall.iloc[0]['bin']}, \"\n",
    "          f\"ROI={_best_overall.iloc[0]['roi']:.3f}, top_n={int(_best_overall.iloc[0]['top_n'])}\")\n",
    "\n",
    "    # (B) top_n ごとの ROI 最大条件\n",
    "    _best_by_topn = (\n",
    "        _cond_result.sort_values(\"roi\", ascending=False)\n",
    "                    .groupby(\"top_n\", as_index=False)\n",
    "                    .head(1)\n",
    "    )\n",
    "    _dfs = []\n",
    "    for _, r in _best_by_topn.iterrows():\n",
    "        _dfs.append(_filter_matches(r))\n",
    "    if _dfs:\n",
    "        _path2 = \"artifacts/cond_best_roi_matches_by_topn.csv\"\n",
    "        pd.concat(_dfs, ignore_index=True).to_csv(_path2, index=False)\n",
    "        print(f\"[cond] Best-ROI matches (per top_n) saved to {_path2}\")\n",
    "else:\n",
    "#     print(\"[cond] ROI 集計が空のため、best ROI CSV の出力はスキップしました。\")\n",
    "    print(\"[cond] ROI 集計が空のため、best ROI CSV の出力はスキップしました。\")\n",
    "\n",
    "# === 期待ROI（将来利用前提）ウォークフォワード評価 ======================\n",
    "# 目的: 過去で条件選定 → 未来で検証、を時系列で繰り返し、前向きの期待ROIを推定\n",
    "# 出力: artifacts/cond_expected_roi_walkforward.csv, artifacts/cond_expected_roi_summary.csv\n",
    "print(\"[cond] ウォークフォワードで期待ROIを評価します…\")\n",
    "\n",
    "if \"race_date\" in _base.columns and not _base.empty:\n",
    "    import math\n",
    "\n",
    "    def _qcut_edges(series: pd.Series, q: int):\n",
    "        try:\n",
    "            _, bins = pd.qcut(series.dropna(), q=q, duplicates=\"drop\", retbins=True)\n",
    "            return bins\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def _apply_bins(series: pd.Series, bins):\n",
    "        if bins is None or len(bins) < 2:\n",
    "            return pd.Series([pd.NA] * len(series), index=series.index)\n",
    "        return pd.cut(series, bins=bins, include_lowest=True)\n",
    "\n",
    "    def _summarize_on(df: pd.DataFrame, col: str, top_n: int, min_races: int = 30) -> pd.DataFrame:\n",
    "        if col not in df.columns:\n",
    "            return pd.DataFrame()\n",
    "        g = df.dropna(subset=[col, \"true_order_rank\", \"trifecta_odds\", \"race_key\"]).copy()\n",
    "        if g.empty:\n",
    "            return pd.DataFrame()\n",
    "        def _agg(x):\n",
    "            rep = x.drop_duplicates(\"race_key\")\n",
    "            n_races = rep[\"race_key\"].nunique()\n",
    "            hits = rep[\"true_order_rank\"] <= top_n\n",
    "            total_return = float(rep.loc[hits, \"trifecta_odds\"].sum())\n",
    "            cost = n_races * top_n\n",
    "            roi = (total_return - cost) / cost if cost > 0 else math.nan\n",
    "            return pd.Series({\n",
    "                \"n_races\": int(n_races),\n",
    "                \"n_hits\": int(hits.sum()),\n",
    "                \"total_return\": total_return,\n",
    "                \"total_cost\": float(cost),\n",
    "                \"hit_rate\": float(hits.mean()),\n",
    "                \"roi\": roi,\n",
    "            })\n",
    "        out = g.groupby(col, dropna=False).apply(_agg).reset_index().rename(columns={col: \"bin\"})\n",
    "        out[\"top_n\"] = int(top_n)\n",
    "        out[\"condition\"] = col\n",
    "        return out[out[\"n_races\"] >= min_races]\n",
    "\n",
    "    def _apply_choice(df_te: pd.DataFrame, row: pd.Series) -> pd.Series:\n",
    "        col, binv, topn = row[\"condition\"], row[\"bin\"], int(row[\"top_n\"])\n",
    "        sel = df_te.drop_duplicates(\"race_key\").copy()\n",
    "        try:\n",
    "            mask = sel[col] == binv\n",
    "        except Exception:\n",
    "            mask = sel[col].astype(str) == str(binv)\n",
    "        rep = sel.loc[mask]\n",
    "        if rep.empty:\n",
    "            return pd.Series({\n",
    "                \"n_races\": 0, \"n_hits\": 0, \"total_return\": 0.0,\n",
    "                \"total_cost\": 0.0, \"hit_rate\": math.nan, \"roi\": math.nan\n",
    "            })\n",
    "        hits = rep[\"true_order_rank\"] <= topn\n",
    "        n = int(rep[\"race_key\"].nunique())\n",
    "        total_return = float(rep.loc[hits, \"trifecta_odds\"].sum())\n",
    "        cost = float(n * topn)\n",
    "        roi = (total_return - cost) / cost if cost > 0 else math.nan\n",
    "        return pd.Series({\n",
    "            \"n_races\": n, \"n_hits\": int(hits.sum()), \"total_return\": total_return,\n",
    "            \"total_cost\": cost, \"hit_rate\": float(hits.mean()), \"roi\": roi\n",
    "        })\n",
    "\n",
    "    # ウィンドウ設定（必要に応じて調整可）\n",
    "    TUNE_DAYS = 120  # 条件選定に使う過去日数\n",
    "    TEST_DAYS = 30   # その直後の検証日数\n",
    "\n",
    "    df_all = _base.dropna(subset=[\"race_key\", \"race_date\"]).copy()\n",
    "    df_all.sort_values(\"race_date\", inplace=True)\n",
    "\n",
    "    # # --- sanity check: trifecta_odds should already be in \"x倍\" (not yen) ---\n",
    "    # if \"trifecta_odds\" in df_all.columns and df_all[\"trifecta_odds\"].notna().any():\n",
    "    #     q95 = df_all[\"trifecta_odds\"].quantile(0.95)\n",
    "    #     assert q95 < 300, \"trifecta_odds は倍率（x倍）に正規化されている必要があります\"\n",
    "\n",
    "    # 解析対象列（意思決定用の条件のみ）\n",
    "    cols_to_try = [\"pl_prob_bin\", \"gap_bin\", \"wind_bin\", \"wave_bin\", \"tailwind\"]\n",
    "    if \"venue\" in df_all.columns:\n",
    "        cols_to_try.append(\"venue\")\n",
    "\n",
    "    records = []\n",
    "    start_cursor = df_all[\"race_date\"].min() + dt.timedelta(days=TUNE_DAYS)\n",
    "    end_limit = df_all[\"race_date\"].max()\n",
    "\n",
    "    cursor = start_cursor\n",
    "    while cursor <= end_limit:\n",
    "        tune_start = cursor - dt.timedelta(days=TUNE_DAYS)\n",
    "        tune_end   = cursor - dt.timedelta(days=1)\n",
    "        test_end   = min(cursor + dt.timedelta(days=TEST_DAYS - 1), end_limit)\n",
    "\n",
    "        df_tr = df_all[(df_all[\"race_date\"] >= tune_start) & (df_all[\"race_date\"] <= tune_end)].copy()\n",
    "        df_te = df_all[(df_all[\"race_date\"] >= cursor) & (df_all[\"race_date\"] <= test_end)].copy()\n",
    "\n",
    "        n_tr = df_tr[\"race_key\"].nunique()\n",
    "        n_te = df_te[\"race_key\"].nunique()\n",
    "        if n_tr < 50 or n_te < 10:\n",
    "            cursor = cursor + dt.timedelta(days=TEST_DAYS)\n",
    "            continue\n",
    "\n",
    "        # --- tune 側でビン境界を決めて、test 側に適用 ---\n",
    "        bins_prob = _qcut_edges(df_tr[\"pl_top1_prob\"], 4) if \"pl_top1_prob\" in df_tr.columns else None\n",
    "        bins_gap  = _qcut_edges(df_tr[\"pl_gap\"], 4) if \"pl_gap\" in df_tr.columns else None\n",
    "\n",
    "        if \"pl_top1_prob\" in df_tr.columns:\n",
    "            df_tr[\"pl_prob_bin\"] = _apply_bins(df_tr[\"pl_top1_prob\"], bins_prob)\n",
    "            df_te[\"pl_prob_bin\"] = _apply_bins(df_te[\"pl_top1_prob\"], bins_prob)\n",
    "        if \"pl_gap\" in df_tr.columns:\n",
    "            df_tr[\"gap_bin\"] = _apply_bins(df_tr[\"pl_gap\"], bins_gap)\n",
    "            df_te[\"gap_bin\"] = _apply_bins(df_te[\"pl_gap\"], bins_gap)\n",
    "        if \"wind_speed\" in df_tr.columns:\n",
    "            BWS = [-np.inf, 2, 4, 6, 8, np.inf]\n",
    "            df_tr[\"wind_bin\"] = pd.cut(df_tr[\"wind_speed\"], bins=BWS, right=False)\n",
    "            df_te[\"wind_bin\"] = pd.cut(df_te[\"wind_speed\"], bins=BWS, right=False)\n",
    "        if \"wave_height\" in df_tr.columns:\n",
    "            BWH = [-np.inf, 0.5, 1.0, 2.0, np.inf]\n",
    "            df_tr[\"wave_bin\"] = pd.cut(df_tr[\"wave_height\"], bins=BWH, right=False)\n",
    "            df_te[\"wave_bin\"] = pd.cut(df_te[\"wave_height\"], bins=BWH, right=False)\n",
    "        if \"wind_sin\" in df_tr.columns:\n",
    "            df_tr[\"tailwind\"] = df_tr[\"wind_sin\"] < 0\n",
    "            df_te[\"tailwind\"] = df_te[\"wind_sin\"] < 0\n",
    "\n",
    "        # --- 選定（tune） ---\n",
    "        tune_tbl = pd.concat([\n",
    "            _summarize_on(df_tr, c, n, 30 if c != \"venue\" else 50)\n",
    "            for n in [1, 2, 3, 4, 5] for c in cols_to_try\n",
    "        ], ignore_index=True)\n",
    "        if tune_tbl.empty:\n",
    "            cursor = cursor + dt.timedelta(days=TEST_DAYS)\n",
    "            continue\n",
    "\n",
    "        # --- Robust selection on tune side ---\n",
    "        # (a) drop degenerate conditions that only have a single bin in this window\n",
    "        _bin_counts = tune_tbl.groupby([\"top_n\", \"condition\"])[\"bin\"].nunique().reset_index(name=\"n_bins\")\n",
    "        tune_tbl = tune_tbl.merge(_bin_counts, on=[\"top_n\", \"condition\"], how=\"left\")\n",
    "        tune_tbl = tune_tbl[tune_tbl[\"n_bins\"] > 1].copy()\n",
    "\n",
    "        # (b) remove NaN/inf ROI rows\n",
    "        tune_tbl = tune_tbl.dropna(subset=[\"roi\"]).copy()\n",
    "        tune_tbl = tune_tbl[np.isfinite(tune_tbl[\"roi\"])]\n",
    "\n",
    "        # (c) enforce a minimum number of hits to avoid overfitting tiny samples\n",
    "        MIN_HITS = 3\n",
    "        if \"n_hits\" in tune_tbl.columns:\n",
    "            tune_tbl = tune_tbl[tune_tbl[\"n_hits\"] >= MIN_HITS]\n",
    "\n",
    "        if tune_tbl.empty:\n",
    "            cursor = cursor + dt.timedelta(days=TEST_DAYS)\n",
    "            continue\n",
    "\n",
    "        # (d) tie-break: ROI desc → n_races desc → hit_rate desc\n",
    "        tune_tbl = tune_tbl.sort_values([\"roi\", \"n_races\", \"hit_rate\"],\n",
    "                                        ascending=[False, False, False])\n",
    "\n",
    "        best_by_topn = tune_tbl.groupby(\"top_n\", as_index=False).head(1)\n",
    "\n",
    "        # --- 検証（test） ---\n",
    "        for _, r in best_by_topn.iterrows():\n",
    "            applied = _apply_choice(df_te, r)\n",
    "            rec = {\n",
    "                \"tune_start\": str(tune_start), \"tune_end\": str(tune_end),\n",
    "                \"test_start\": str(cursor), \"test_end\": str(test_end),\n",
    "                \"condition\": r[\"condition\"], \"bin\": r[\"bin\"], \"top_n\": int(r[\"top_n\"]),\n",
    "                \"bin_label\": str(r[\"bin\"]),\n",
    "                **applied.to_dict(),\n",
    "            }\n",
    "            # add interval bounds if the bin is an Interval\n",
    "            if isinstance(r[\"bin\"], pd.Interval):\n",
    "                rec[\"bin_low\"] = float(r[\"bin\"].left)\n",
    "                rec[\"bin_high\"] = float(r[\"bin\"].right)\n",
    "            records.append(rec)\n",
    "\n",
    "        cursor = cursor + dt.timedelta(days=TEST_DAYS)\n",
    "\n",
    "    wf_path = \"artifacts/cond_expected_roi_walkforward.csv\"\n",
    "    wf_df = pd.DataFrame.from_records(records)\n",
    "    wf_df.to_csv(wf_path, index=False)\n",
    "    print(f\"[cond] Walk‑forward records saved to {wf_path} (rows={len(wf_df)})\")\n",
    "\n",
    "    # 集約（top_n ごとに前向きROIを一本化）\n",
    "    if not wf_df.empty:\n",
    "        summary = []\n",
    "        for n in sorted(wf_df[\"top_n\"].unique()):\n",
    "            sub = wf_df[wf_df[\"top_n\"] == n]\n",
    "            cost = float(sub[\"total_cost\"].sum())\n",
    "            ret  = float(sub[\"total_return\"].sum())\n",
    "            n_r  = int(sub[\"n_races\"].sum())\n",
    "            n_h  = int(sub[\"n_hits\"].sum())\n",
    "            # ROI is stored as a ratio (e.g., 0.12 = +12%)\n",
    "            roi  = (ret - cost) / cost if cost > 0 else math.nan\n",
    "            hit_rate = (n_h / n_r) if n_r > 0 else math.nan\n",
    "            summary.append({\n",
    "                \"top_n\": int(n), \"n_races\": n_r, \"n_hits\": n_h,\n",
    "                \"expected_roi\": roi, \"hit_rate\": hit_rate,\n",
    "                \"total_return\": ret, \"total_cost\": cost,\n",
    "            })\n",
    "        sum_df = pd.DataFrame(summary).sort_values(\"top_n\")\n",
    "        sum_path = f\"artifacts/{venue}_real/cond_expected_roi_summary_{venue}.csv\"\n",
    "        sum_df.to_csv(sum_path, index=False)\n",
    "        print(f\"[cond] Expected ROI summary saved to {sum_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"[cond] race_date が無いためウォークフォワード評価はスキップしました。\")\n",
    "\n",
    "# === 再現性監査: true_order_prob デシル × ROI/Hit ============================\n",
    "# 目的:\n",
    "#   ・モデルが「実際に起きた完全順序」に与えていた確率(true_order_prob)でデシル分割し、\n",
    "#     TopNごとの ヒット率 / ROI / 払戻シェア を比較。\n",
    "#   ・“低確率（運の一撃）偏重で勝っていないか”を可視化して、持続性を監査。\n",
    "# 出力:\n",
    "#   artifacts/{venue}/audit_true_order_prob_deciles_{venue}.csv\n",
    "# --------------------------------------------------------------------------\n",
    "print(\"[audit] true_order_prob のデシル別に ROI/Hit を監査します…\")\n",
    "try:\n",
    "    required_cols = {\"race_key\", \"true_order_prob\", \"true_order_rank\", \"trifecta_odds\"}\n",
    "    if not required_cols.issubset(set(_base.columns)):\n",
    "        missing = required_cols - set(_base.columns)\n",
    "        print(f\"[audit] 必須列が不足のためスキップ: {missing}\")\n",
    "    else:\n",
    "        _df_a = (_base\n",
    "                 .dropna(subset=list(required_cols))\n",
    "                 .drop_duplicates(\"race_key\")\n",
    "                 .copy())\n",
    "\n",
    "        # 万一、倍率が円建てで混在していたら補正（上で補正済みだが安全策）\n",
    "        # if _df_a[\"trifecta_odds\"].notna().any():\n",
    "        #     try:\n",
    "        #         if _df_a[\"trifecta_odds\"].quantile(0.95) > 300:\n",
    "        #             _df_a[\"trifecta_odds\"] = _df_a[\"trifecta_odds\"] / 100.0\n",
    "        #     except Exception:\n",
    "        #         pass\n",
    "\n",
    "        # デシル作成（0=低確率 … 9=高確率）。重複値で段が崩れる場合は drop を許容\n",
    "        _df_a[\"prob_decile\"] = pd.qcut(_df_a[\"true_order_prob\"],\n",
    "                                       q=10, labels=False, duplicates=\"drop\")\n",
    "\n",
    "        # 念のため整数化\n",
    "        _df_a[\"prob_decile\"] = pd.to_numeric(_df_a[\"prob_decile\"], errors=\"coerce\")\n",
    "\n",
    "        def _agg_decile(df_dec: pd.DataFrame, top_n: int) -> pd.DataFrame:\n",
    "            df_dec = df_dec.copy()\n",
    "            df_dec[\"hit\"] = df_dec[\"true_order_rank\"] <= top_n\n",
    "            # レース単位に揃える（重複保護）\n",
    "            df_dec = df_dec.drop_duplicates(\"race_key\")\n",
    "            g = df_dec.groupby(\"prob_decile\", dropna=False)\n",
    "            rows = []\n",
    "            for k, sub in g:\n",
    "                n = int(sub[\"race_key\"].nunique())\n",
    "                n_hits = int(sub[\"hit\"].sum())\n",
    "                ret = float(sub.loc[sub[\"hit\"], \"trifecta_odds\"].sum())\n",
    "                cost = float(n * top_n)\n",
    "                roi = (ret - cost) / cost if cost > 0 else float(\"nan\")\n",
    "                rows.append({\n",
    "                    \"top_n\": int(top_n),\n",
    "                    \"prob_decile\": (int(k) if pd.notna(k) else -1),\n",
    "                    \"n_races\": n,\n",
    "                    \"n_hits\": n_hits,\n",
    "                    \"hit_rate\": (n_hits / n) if n > 0 else float(\"nan\"),\n",
    "                    \"avg_true_order_prob\": float(sub[\"true_order_prob\"].mean()) if n > 0 else float(\"nan\"),\n",
    "                    \"median_true_order_prob\": float(sub[\"true_order_prob\"].median()) if n > 0 else float(\"nan\"),\n",
    "                    \"total_return\": ret,\n",
    "                    \"total_cost\": cost,\n",
    "                    \"roi\": roi,\n",
    "                })\n",
    "            return pd.DataFrame(rows)\n",
    "\n",
    "        _outs = []\n",
    "        for _N in [1, 2, 3, 5]:\n",
    "            _outs.append(_agg_decile(_df_a, _N))\n",
    "\n",
    "        audit_df = pd.concat(_outs, ignore_index=True) if _outs else pd.DataFrame()\n",
    "        if not audit_df.empty:\n",
    "            # デシル昇順で整列（0=低確率側）\n",
    "            audit_df = audit_df.sort_values([\"top_n\", \"prob_decile\"]).reset_index(drop=True)\n",
    "            # 各 TopN 内で払戻シェアを追加（どのデシルにリターンが偏っているか）\n",
    "            def _add_share(g):\n",
    "                tot_ret = g[\"total_return\"].sum()\n",
    "                g[\"return_share\"] = g[\"total_return\"] / tot_ret if tot_ret > 0 else np.nan\n",
    "                tot_hits = g[\"n_hits\"].sum()\n",
    "                g[\"hit_share\"] = g[\"n_hits\"] / tot_hits if tot_hits > 0 else np.nan\n",
    "                return g\n",
    "            audit_df = audit_df.groupby(\"top_n\", as_index=False).apply(_add_share).reset_index(drop=True)\n",
    "\n",
    "            # 保存\n",
    "            os.makedirs(f\"artifacts/{venue}_real\", exist_ok=True)\n",
    "            audit_path = f\"artifacts/{venue}_real/audit_true_order_prob_deciles_{venue}.csv\"\n",
    "            audit_df.to_csv(audit_path, index=False)\n",
    "            print(f\"[audit] Saved decile audit → {audit_path}  (rows={len(audit_df)})\")\n",
    "\n",
    "            # コンソール要約（各TopNで 低確率デシル vs 高確率デシル をダイジェスト）\n",
    "            with pd.option_context(\"display.max_rows\", 50, \"display.max_colwidth\", 80, \"display.float_format\", \"{:.4f}\".format):\n",
    "                for _N in sorted(audit_df[\"top_n\"].unique()):\n",
    "                    view = audit_df[audit_df[\"top_n\"] == _N].sort_values(\"prob_decile\")\n",
    "                    if view.empty: \n",
    "                        continue\n",
    "                    lo = view.iloc[0]\n",
    "                    hi = view.iloc[-1]\n",
    "                    print(f\"[audit] TopN={_N}  D_low (decile={int(lo['prob_decile'])}) vs D_high (decile={int(hi['prob_decile'])})\")\n",
    "                    print(f\"        n_races {int(lo['n_races'])}/{int(hi['n_races'])}  \"\n",
    "                          f\"hit_rate {lo['hit_rate']:.4f}/{hi['hit_rate']:.4f}  \"\n",
    "                          f\"roi {lo['roi']:.4f}/{hi['roi']:.4f}  \"\n",
    "                          f\"return_share {lo['return_share']:.3f}/{hi['return_share']:.3f}\")\n",
    "        else:\n",
    "            print(\"[audit] デシル監査の結果が空でした（データ不足）。\")\n",
    "except Exception as e:\n",
    "    print(\"[audit] 監査処理で例外が発生しました:\", e)\n",
    "# ======================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24100b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              race_key   race_date venue air_temp  wind_speed  wave_height  \\\n",
      "0     2025-01-13-01-20  2025-01-13   若 松     None         3.0         0.03   \n",
      "1     2025-01-13-02-20  2025-01-13   若 松     None         4.0         0.04   \n",
      "2     2025-01-13-03-20  2025-01-13   若 松     None         6.0         0.06   \n",
      "3     2025-01-13-04-20  2025-01-13   若 松     None         6.0         0.06   \n",
      "4     2025-01-13-05-20  2025-01-13   若 松     None         6.0         0.06   \n",
      "...                ...         ...   ...      ...         ...          ...   \n",
      "1681  2025-09-25-11-20  2025-09-25   若 松     None         4.0         0.04   \n",
      "1682  2025-09-25-12-20  2025-09-25   若 松     None         4.0         0.04   \n",
      "1683  2025-09-29-01-20  2025-09-29   若 松     None         3.0         0.03   \n",
      "1684  2025-09-29-02-20  2025-09-29   若 松     None         3.0         0.03   \n",
      "1685  2025-09-29-05-20  2025-09-29   若 松     None         3.0         0.03   \n",
      "\n",
      "     water_temp weather_txt  wind_dir_deg  lane1_racer_id  ...  lane5_starts  \\\n",
      "0          None           晴         315.0            4474  ...           9.0   \n",
      "1          None           晴           0.0            3868  ...           9.0   \n",
      "2          None           晴         315.0            3305  ...           9.0   \n",
      "3          None           晴         315.0            4865  ...           3.0   \n",
      "4          None           晴         315.0            4136  ...           4.0   \n",
      "...         ...         ...           ...             ...  ...           ...   \n",
      "1681       None           晴         135.0            4155  ...           7.0   \n",
      "1682       None           晴          90.0            4503  ...           2.0   \n",
      "1683       None           晴         112.5            4567  ...           5.0   \n",
      "1684       None           晴         112.5            3233  ...           4.0   \n",
      "1685       None           晴          90.0            4171  ...           9.0   \n",
      "\n",
      "      lane5_firsts  lane5_first_rate  lane5_two_rate  lane5_three_rate  \\\n",
      "0              0.0          0.000000        0.111111          0.222222   \n",
      "1              1.0          0.111111        0.111111          0.222222   \n",
      "2              0.0          0.000000        0.111111          0.222222   \n",
      "3              0.0          0.000000        0.000000          0.000000   \n",
      "4              0.0          0.000000        0.000000          0.000000   \n",
      "...            ...               ...             ...               ...   \n",
      "1681           0.0          0.000000        0.428571          0.571429   \n",
      "1682           0.0          0.000000        0.500000          0.500000   \n",
      "1683           0.0          0.000000        0.200000          0.800000   \n",
      "1684           0.0          0.000000        0.000000          0.000000   \n",
      "1685           0.0          0.000000        0.111111          0.222222   \n",
      "\n",
      "      lane6_starts  lane6_firsts  lane6_first_rate  lane6_two_rate  \\\n",
      "0             11.0           0.0               0.0        0.090909   \n",
      "1              9.0           0.0               0.0        0.111111   \n",
      "2              5.0           0.0               0.0        0.400000   \n",
      "3              4.0           0.0               0.0        0.500000   \n",
      "4              6.0           0.0               0.0        0.000000   \n",
      "...            ...           ...               ...             ...   \n",
      "1681           8.0           0.0               0.0        0.125000   \n",
      "1682           4.0           0.0               0.0        0.000000   \n",
      "1683           8.0           0.0               0.0        0.000000   \n",
      "1684           2.0           0.0               0.0        0.000000   \n",
      "1685           NaN           NaN               NaN             NaN   \n",
      "\n",
      "      lane6_three_rate  \n",
      "0             0.454545  \n",
      "1             0.444444  \n",
      "2             0.600000  \n",
      "3             0.500000  \n",
      "4             0.166667  \n",
      "...                ...  \n",
      "1681          0.250000  \n",
      "1682          0.250000  \n",
      "1683          0.000000  \n",
      "1684          0.000000  \n",
      "1685               NaN  \n",
      "\n",
      "[1686 rows x 75 columns]\n",
      "[predict] Loaded 1686 rows (2025-01-11 – 2025-10-24).\n",
      "columns: race_key, race_date, venue, air_temp, wind_speed, wave_height, water_temp, weather_txt, wind_dir_deg, lane1_racer_id, lane1_exh_time, lane1_fs_flag, lane2_racer_id, lane2_exh_time, lane2_fs_flag, lane3_racer_id, lane3_exh_time, lane3_fs_flag, lane4_racer_id, lane4_exh_time, lane4_fs_flag, lane5_racer_id, lane5_exh_time, lane5_fs_flag, lane6_racer_id, lane6_exh_time, lane6_fs_flag, lane1_starts, lane1_firsts, lane1_first_rate, lane1_two_rate, lane1_three_rate, lane2_starts, lane2_firsts, lane2_first_rate, lane2_two_rate, lane2_three_rate, lane3_starts, lane3_firsts, lane3_first_rate, lane3_two_rate, lane3_three_rate, lane4_starts, lane4_firsts, lane4_first_rate, lane4_two_rate, lane4_three_rate, lane5_starts, lane5_firsts, lane5_first_rate, lane5_two_rate, lane5_three_rate, lane6_starts, lane6_firsts, lane6_first_rate, lane6_two_rate, lane6_three_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/_65_h0_d791gcmmvjcjjkn9r0000gn/T/ipykernel_37755/1461393288.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_recent = pd.read_sql(query, conn)\n",
      "/Users/keiichiro/workspace/boat_racing/model/roi_util.py:63: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[bool_cols] = df[bool_cols].fillna(False).astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[personas] saved: pred_trifecta_topk_personas.csv, pred_persona_votes.csv, pred_persona_disagreement.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# prediction\n",
    "from roi_util import ROIPredictor\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "today = dt.date.today()\n",
    "# 2025年1月1日以降のデータを取得する場合は、以下の行を変更してください。\n",
    "start_date = dt.date(2025, 1, 11)\n",
    "end = dt.date(2025, 8, 12)\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT * FROM pred.features_with_record\n",
    "    WHERE race_date BETWEEN '{start_date}' AND '{today}'\n",
    "    AND venue = '{venue}'\n",
    "\"\"\"\n",
    "\n",
    "with psycopg2.connect(**DB_CONF) as conn:\n",
    "    df_recent = pd.read_sql(query, conn)\n",
    "\n",
    "df_recent['air_temp'] = None\n",
    "df_recent['water_temp'] = None\n",
    "# wave_heightを0.01倍\n",
    "if 'wave_height' in df_recent.columns:\n",
    "    df_recent['wave_height'] = df_recent['wave_height'] * 0.01\n",
    "print(df_recent)\n",
    "df_recent.to_csv(f\"artifacts/{venue}_real/pred_features_recent.csv\", index=False)\n",
    "\n",
    "df_recent.drop(columns=exclude, inplace=True, errors=\"ignore\")\n",
    "\n",
    "if df_recent.empty:\n",
    "    print(\"[predict] No rows fetched for the specified period.\")\n",
    "\n",
    "print(f\"[predict] Loaded {len(df_recent)} rows ({start_date} – {today}).\")\n",
    "print(f\"columns: {', '.join(df_recent.columns)}\")\n",
    "\n",
    "# --- Fill required NUM_COLS to avoid dropna→empty in ROIPredictor ---\n",
    "import numpy as _np\n",
    "\n",
    "# 1) Derive wind_sin/cos from wind_dir_deg if available\n",
    "if \"wind_dir_deg\" in df_recent.columns:\n",
    "    df_recent[\"wind_sin\"] = _np.sin(_np.deg2rad(df_recent[\"wind_dir_deg\"]))\n",
    "    df_recent[\"wind_cos\"] = _np.cos(_np.deg2rad(df_recent[\"wind_dir_deg\"]))\n",
    "else:\n",
    "    # ensure columns exist (filled later)\n",
    "    if \"wind_sin\" not in df_recent.columns:\n",
    "        df_recent[\"wind_sin\"] = _np.nan\n",
    "    if \"wind_cos\" not in df_recent.columns:\n",
    "        df_recent[\"wind_cos\"] = _np.nan\n",
    "\n",
    "# 2) Fill missing required numeric features with training scaler means\n",
    "_mean_map = {col: float(mu) for col, mu in zip(NUM_COLS, scaler.mean_)}\n",
    "for _c in NUM_COLS:\n",
    "    if _c not in df_recent.columns:\n",
    "        df_recent[_c] = _mean_map[_c]\n",
    "    else:\n",
    "        df_recent[_c] = pd.to_numeric(df_recent[_c], errors=\"coerce\").fillna(_mean_map[_c])\n",
    "\n",
    "# ------------------------------\n",
    "# ROIPredictor でスコア＆確率を一括生成\n",
    "# ------------------------------\n",
    "predictor = ROIPredictor(model=rank_model, scaler=scaler,\n",
    "                         num_cols=NUM_COLS, device=device, batch_size=512)\n",
    "\n",
    "# (1) スコア（logits）: lane1_score..lane6_score (+ メタ列) を保存\n",
    "pred_scores_df = predictor.predict_scores(df_recent,\n",
    "                                          include_meta=True,\n",
    "                                          save_to=f\"artifacts/{venue}_real/pred_scores.csv\")\n",
    "\n",
    "# (2) 勝率＆フェアオッズを保存\n",
    "pred_probs_df = predictor.predict_win_probs(scores_df=pred_scores_df,\n",
    "                                            include_meta=True,\n",
    "                                            save_to=f\"artifacts/{venue}_real/pred_win_probs.csv\")\n",
    "\n",
    "# (3) 馬単/三連単の TOP‑K（PL 方式）を保存\n",
    "exa_df, tri_df = predictor.predict_exotics_topk(scores_df=pred_scores_df,\n",
    "                                                K=10,\n",
    "                                                tau=1.0,\n",
    "                                                include_meta=True,\n",
    "                                                save_exacta=f\"artifacts/{venue}_real/pred_exacta_topk.csv\",\n",
    "                                                save_trifecta=f\"artifacts/{venue}_real/pred_trifecta_topk.csv\")\n",
    "\n",
    "# ==============================================================\n",
    "# ② 分裂型（ペルソナ別予想）\n",
    "#    - 既存のスコア(pred_scores_df)を軽量変換して「性格の違うAI」を3体同時に生成\n",
    "#    - safe : 温度低め（堅実）＋内枠バイアス\n",
    "#    - chaos: 温度高め（波乱）＋外枠バイアス＋微小ノイズ\n",
    "#    - trend: 直近勝率(softmax)をさらに強調（人気追従寄り）\n",
    "# ==============================================================\n",
    "\n",
    "import numpy as _np\n",
    "import pandas as _pd\n",
    "\n",
    "def _copy_scores(df: _pd.DataFrame) -> _pd.DataFrame:\n",
    "    cols = [c for c in df.columns if c.startswith(\"lane\") and c.endswith(\"_score\")]\n",
    "    keep = [\"race_key\", \"rno\", \"jcd\", \"hd\", \"venue\", \"race_date\"]\n",
    "    keep = [c for c in keep if c in df.columns]\n",
    "    return df[keep + cols].copy()\n",
    "\n",
    "def _apply_temperature(df_scores: _pd.DataFrame, tau: float) -> _pd.DataFrame:\n",
    "    \"\"\"logit / tau で温度スケーリング（tau<1で尖る／>1で平坦化）\"\"\"\n",
    "    out = df_scores.copy()\n",
    "    lane_cols = [c for c in out.columns if c.startswith(\"lane\") and c.endswith(\"_score\")]\n",
    "    for c in lane_cols:\n",
    "        out[c] = out[c] / float(max(tau, 1e-6))\n",
    "    return out\n",
    "\n",
    "def _apply_lane_bias(df_scores: _pd.DataFrame, inner_boost: float = 0.0, outer_boost: float = 0.0) -> _pd.DataFrame:\n",
    "    \"\"\"\n",
    "    内枠(1-2)・外枠(4-6)に一定のバイアス(ロジット加算)を与える。\n",
    "    正の値で有利化、負の値で不利化。\n",
    "    \"\"\"\n",
    "    out = df_scores.copy()\n",
    "    for i in (1, 2):\n",
    "        col = f\"lane{i}_score\"\n",
    "        if col in out.columns:\n",
    "            out[col] = out[col] + inner_boost\n",
    "    for i in (4, 5, 6):\n",
    "        col = f\"lane{i}_score\"\n",
    "        if col in out.columns:\n",
    "            out[col] = out[col] + outer_boost\n",
    "    return out\n",
    "\n",
    "def _apply_noise(df_scores: _pd.DataFrame, std: float = 0.0, seed: int = 0) -> _pd.DataFrame:\n",
    "    \"\"\"スコアに微小ノイズを加える（波乱味付け）\"\"\"\n",
    "    if std <= 0:\n",
    "        return df_scores\n",
    "    rng = _np.random.default_rng(seed)\n",
    "    out = df_scores.copy()\n",
    "    lane_cols = [c for c in out.columns if c.startswith(\"lane\") and c.endswith(\"_score\")]\n",
    "    noise = rng.normal(loc=0.0, scale=std, size=(len(out), len(lane_cols)))\n",
    "    out[lane_cols] = out[lane_cols].to_numpy() + noise\n",
    "    return out\n",
    "\n",
    "def _emphasize_current_probs(df_scores: _pd.DataFrame, sharpness: float = 1.2) -> _pd.DataFrame:\n",
    "    \"\"\"\n",
    "    現在の lane ログイットをsoftmax→確率を sharpness 乗 → 逆変換でロジット強調。\n",
    "    直感的に「今の強弱をそのまま強める」= 人気追従寄り。\n",
    "    \"\"\"\n",
    "    out = df_scores.copy()\n",
    "    lane_cols = [c for c in out.columns if c.startswith(\"lane\") and c.endswith(\"_score\")]\n",
    "    S = out[lane_cols].to_numpy(dtype=float)\n",
    "    S = S - S.max(axis=1, keepdims=True)  # 数値安定化\n",
    "    P = _np.exp(S); P = P / P.sum(axis=1, keepdims=True)\n",
    "    P = _np.power(P, sharpness)\n",
    "    P = P / P.sum(axis=1, keepdims=True)\n",
    "    # logit = log(p) - log(1-p) ではなく、多クラスのため log(p) 比で十分\n",
    "    # 1列を基準に相対ロジット化してから再中心化\n",
    "    logP = _np.log(_np.clip(P, 1e-12, 1.0))\n",
    "    logP = logP - logP.mean(axis=1, keepdims=True)\n",
    "    out[lane_cols] = logP\n",
    "    return out\n",
    "\n",
    "def _persona_scores(pred_scores_df: _pd.DataFrame, name: str) -> _pd.DataFrame:\n",
    "    base = _copy_scores(pred_scores_df)\n",
    "    if name == \"safe\":\n",
    "        x = _apply_temperature(base, tau=0.8)         # 低温度で尖らせる\n",
    "        x = _apply_lane_bias(x, inner_boost=+0.15)    # 1-2を少し持ち上げ\n",
    "        return x\n",
    "    elif name == \"chaos\":\n",
    "        x = _apply_temperature(base, tau=1.3)         # 高温度で平坦化\n",
    "        x = _apply_lane_bias(x, outer_boost=+0.20)    # 4-6を強気に\n",
    "        x = _apply_noise(x, std=0.07, seed=42)\n",
    "        return x\n",
    "    elif name == \"trend\":\n",
    "        x = _emphasize_current_probs(base, sharpness=1.35)  # 現在の傾向を強調\n",
    "        return x\n",
    "    else:\n",
    "        return base\n",
    "\n",
    "PERSONAS = [\"safe\", \"chaos\", \"trend\"]\n",
    "\n",
    "# ペルソナ別に TOP‑K 三連単を生成して保存\n",
    "persona_tri_list = []\n",
    "for name in PERSONAS:\n",
    "    sd = _persona_scores(pred_scores_df, name)\n",
    "    # 保存先ファイル名\n",
    "    tri_path = f\"artifacts/{venue}_real/pred_trifecta_topk_{name}.csv\"\n",
    "    exa_path = f\"artifacts/{venue}_real/pred_exacta_topk_{name}.csv\"\n",
    "    _exa, _tri = predictor.predict_exotics_topk(scores_df=sd,\n",
    "                                                K=10,\n",
    "                                                tau=1.0,           # ここは PL 計算の温度（必要なら個別変更可）\n",
    "                                                include_meta=True,\n",
    "                                                save_exacta=exa_path,\n",
    "                                                save_trifecta=tri_path)\n",
    "    _tri = _tri.copy()\n",
    "    _tri[\"persona\"] = name\n",
    "    persona_tri_list.append(_tri)\n",
    "\n",
    "# 結合して 1 ファイルにも出しておく\n",
    "if persona_tri_list:\n",
    "    tri_all = _pd.concat(persona_tri_list, ignore_index=True)\n",
    "    tri_all.to_csv(f\"artifacts/{venue}_real/pred_trifecta_topk_personas.csv\", index=False)\n",
    "\n",
    "    # --- 簡易 Vote 集計（各レースで各ペルソナの1位に1票）と不一致度 ---\n",
    "    # tri_df 形式は race_key ごとに 'rank' 列（1始まり）/ 'trifecta' / 'prob' がある前提\n",
    "    first_choices = (tri_all.sort_values([\"race_key\", \"persona\", \"rank\"])\n",
    "                             .query(\"rank == 1\")\n",
    "                             .loc[:, [\"race_key\", \"persona\", \"trifecta\", \"prob\"]]\n",
    "                             .copy())\n",
    "    # 票数\n",
    "    vote = (first_choices.groupby([\"race_key\", \"trifecta\"])\n",
    "                        .size().reset_index(name=\"votes\"))\n",
    "    # 不一致度 = 人数(=len(PERSONAS)) - 最多票\n",
    "    max_votes = vote.groupby(\"race_key\")[\"votes\"].max().rename(\"max_votes\")\n",
    "    disagree = max_votes.to_frame().reset_index()\n",
    "    disagree[\"n_personas\"] = len(PERSONAS)\n",
    "    disagree[\"disagreement\"] = disagree[\"n_personas\"] - disagree[\"max_votes\"]\n",
    "\n",
    "    vote.to_csv(f\"artifacts/{venue}_real/pred_persona_votes.csv\", index=False)\n",
    "    disagree.to_csv(f\"artifacts/{venue}_real/pred_persona_disagreement.csv\", index=False)\n",
    "    print(\"[personas] saved: pred_trifecta_topk_personas.csv, pred_persona_votes.csv, pred_persona_disagreement.csv\")\n",
    "else:\n",
    "    print(\"[personas] persona_tri_list is empty; skipped saving.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b74f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[predict] Prediction completed and saved to artifacts directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"[predict] Prediction completed and saved to artifacts directory.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "boat_racing-zew2npIb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
